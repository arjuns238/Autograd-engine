{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import Value\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "from nn import Linear, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'draw_dot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/asri/Library/CloudStorage/OneDrive-Personal/autograd-engine/Autograd-engine/use_case.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/asri/Library/CloudStorage/OneDrive-Personal/autograd-engine/Autograd-engine/use_case.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m x1w1x2w2b \u001b[39m=\u001b[39m x1w1x2w2 \u001b[39m+\u001b[39m b; x1w1x2w2b\u001b[39m.\u001b[39mlabel \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mx1w1x2w2 + b\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/asri/Library/CloudStorage/OneDrive-Personal/autograd-engine/Autograd-engine/use_case.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m o \u001b[39m=\u001b[39m x1w1x2w2b\u001b[39m.\u001b[39mrelu(); o\u001b[39m.\u001b[39mlabel \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mo\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/asri/Library/CloudStorage/OneDrive-Personal/autograd-engine/Autograd-engine/use_case.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m graph \u001b[39m=\u001b[39m draw_dot(o)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/asri/Library/CloudStorage/OneDrive-Personal/autograd-engine/Autograd-engine/use_case.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m graph\u001b[39m.\u001b[39mview()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'draw_dot' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "x1 = Value(2.0, label = 'x1')\n",
    "x2 = Value(6.0, label = 'x2')\n",
    "\n",
    "w1 = Value(-3.0, label = 'w1')\n",
    "w2 = Value(1.0, label = 'w2')\n",
    "\n",
    "b = Value(0.6, label = 'b')\n",
    "# x1w1 + x2w2 + b\n",
    "x1w1 = x1*w1; x1w1.label = 'x1w1'\n",
    "x2w2 = x2*w2; x2w2.label = 'x2w2'\n",
    "x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\n",
    "x1w1x2w2b = x1w1x2w2 + b; x1w1x2w2b.label = 'x1w1x2w2 + b'\n",
    "o = x1w1x2w2b.relu(); o.label = 'o'\n",
    "\n",
    "graph = draw_dot(o)\n",
    "graph.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import Linear\n",
    "w = Linear(1, 3)\n",
    "x = []\n",
    "t = w(x)\n",
    "print(t)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.nn.Linear(1, 2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2],[3,4]])\n",
    "b = torch.tensor([[1,2], [3,4]])\n",
    "a@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,2], [3,4]]\n",
    "b = [[1,2], [3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import Neuron\n",
    "n = Neuron(2)\n",
    "x = [2.0, 3.0]\n",
    "out = n(x)\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGdCAYAAAAvwBgXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB22ElEQVR4nO3dZ3gUZfv38e/sphfSCamE3nsPoCBI772DIAqigu1WQRH1VlRsoAioSJHeQaogvfcOoSeQhJKE9Lq71/OCv/HJHVQCSSbl/BzHvuCa3ZnfLknm3JmraEophRBCCCGEDgx6BxBCCCFE8SWFiBBCCCF0I4WIEEIIIXQjhYgQQgghdCOFiBBCCCF0I4WIEEIIIXQjhYgQQgghdCOFiBBCCCF0Y6V3gH9isViIiIjA2dkZTdP0jiOEEEKIR6CUIiEhAV9fXwyGf77mUaALkYiICAICAvSOIYQQQojHcPPmTfz9/f/xOQW6EHF2dgYevJESJUronEYIIYQQjyI+Pp6AgIDM8/g/KdCFyJ+3Y0qUKCGFiBBCCFHIPEq3CumsKoQQQgjdSCEihBBCCN1IISKEEEII3UghIoQQQgjdSCEihBBCCN1IISKEEEII3eRbITJ58mQ0TWPcuHH5dUghhBBCFHD5UogcOXKEH3/8kZo1a+bH4YQQQghRSOR5IZKYmMjAgQP56aefcHNzy+vDCSGEEKIQyfNCZMyYMXTs2JHWrVv/63PT0tKIj4/P8hBCFBxKKbZt28aIESPo1asXX3zxBVFRUXrHEkIUYnlaiCxZsoTjx48zefLkR3r+5MmTcXFxyXzIgndCFBwWi4WhQwfz7LPPsn/PYu7f2cTEieOpVKk8R48e1TueEKKQyrNC5ObNm4wdO5YFCxZgZ2f3SK959913iYuLy3zcvHkzr+IJIXJo9uzZLFiwkHnfeXN2lx9bl/tx42gg5Utn0KdPT8xms94RhRCFkKaUUnmx4zVr1tC9e3eMRmNmm9lsRtM0DAYDaWlpWbY9THx8PC4uLsTFxcmid0LorEGDOvh4XGHNXJ8s7YdPpNKkw022bNlCmzZtdEonhChIcnL+zrPVd1u1asWZM2eytD333HNUrlyZt99++1+LECFEwRIaGkqXZ2yztTeobZu5XQghcirPChFnZ2eqV6+epc3R0REPD49s7UKIgq9cufIcOHYhW/uBo6kAlC1bNr8jCSGKAJlZVQjxSEaNGsOmPxKZOS8Wi+XBHd2wWxm8Mj6GihXL0bJlS50TCiEKozzrI5IbpI+IEAWHUopRo0bx448/EuBnh6+3kaOnkvH09GDr1u3UqFFD74hCiAIiJ+dvKUSEEI9MKcWhQ4dYtGgRcXFxNGzYkMGDB8vvpxAiiwLRWVUIUfRomkbjxo1p3Lix3lGEEEWE9BERQgghhG6kEBFCCCGEbqQQEUIIIYRupBARQgghhG6kEBFCCCGEbqQQEUIIIYRupBARQgghhG6kEBFCCCGEbqQQEUIIIYRupBARQgghhG6kEBFCCCGEbqQQEUIIIYRupBARQgghhG6kEBFCCCGEbqQQEUIIIYRupBARQgghhG6kEBFCCCGEbqQQEUIIIYRupBARQgghhG6kEBFCCCGEbqQQEUIIIYRupBARQgghhG6kEBFCCCGEbqQQEUIIIYRupBARQgghhG6kEBFCCCGEbqQQEUIIIYRupBARQgghhG6kEBFCCCGEbqQQEUIIIYRupBARQjzUjh076NSpA97eHlSsWJZJkyYRFxendywhRBEjhYgQIpu5c+fSqlUrIsJ2MXoIPNUgmilTPuHpp5sVqGIkNDSUGTNmMH36dC5duqR3HCHEY9CUUkrvEH8nPj4eFxcX4uLiKFGihN5xhCgWEhIS8PPzoXt7I7O/KYnBoAFw9mIajTuE8/bb7/PBBx/omtFisTBu3DimT5+Opik0DUwmxeDBA/n551+wsbHRNZ8QxV1Ozt9yRUQIkcXGjRtJSEjiw7fcM4sQgOqVbenb1ZHFi3/VMd0DX375Jd9//x2TJ7gTE1KWuMtl+eHzkixdupjx48frHU8IkQNSiAghsvjz1ouPt1W2bf4+VrrfmjGZTHz77Vc8P7AEb77khpOjATs7Ay8OceGtl1yZNWsGCQkJumYUQjw6KUSEEFk0bNgQgLVbErO0WyyKdVtSadiwsR6xMt25c4fIyLt0auOYbVunNo4kJiZz5coVHZIJIR5H9q88QohirXbt2rRu1ZKX3t6HUtCtnRO3Ik1M/DyaMxdS+G7GW7rkslgsXL16laSkJDRNI/SmKdtzbtzMAMDV1TWf0wkhHpd0VhVCZBMTE0O/vr3Zum17ZpuLixPffz+DQYMG5XueX3/9lQ8+eI/r18P+L4sjttbpnNzuj7fXg+9TcfFmWnSPxMm1Jvv2Hcz3jEKIv+Tk/C1XRIQQ2bi7u/P71j84deoUR44cwdXVlfbt2+PomP12SF6bN28ew4YNo2cnJ6Z/4kuGSTH9l3h+35lBhcZhDOzpiLW1xvLfUkjPsGXHwpn5nlEI8fjkiogQosAym82UKRNI4zrxLJ5ZCk17MIrHYlG06RvBhSuOlCjhjFIW2rbtxGuvvUbZsmV1Ti2EkCsiQogi4fz589y8GcGcb/wyixAAg0Fj5KASDBh1m5Mnz+Dt7a1jSiHEk5BRM0KIAuvP4uNh120tlqzPEUIUTlKICCEKrCpVqlC6tD8z5sbx/99FNpsVP/2aQP36dShZsqSOCYUQT0puzQghCiyj0cgnn3zGoEGD6P7cbUYMcCY9XTFjbgJ7DqWwceNkvSMKIZ6QFCJCiAJt4MCBWFlZMXHiBLoNvQpAzZrVWL9+Cm3bttU5nRDiScmoGSFEoaCUIjQ0FKPRiL+/v/QNEaIAk1EzQogiR9M0goKC9I4hhMhl0llVCCGEELqRQkQIIYQQupFCRAghhBC6kUJECCGEELqRQkQIIYQQupFCRAghhBC6kUJECFHkFODpkYQQ/0MKESFEkZCens6nn35KUJA/BoOBoCB/Jk+eTEZGht7RhBD/QCY0E0IUehaLhd69e7Jp00YG93ai4cslOXwigQ8+eI9Dhw6watUaDAb53iVEQSSFiBCi0Pv9999Zt249K3/xoVt7JwBGDnKhQytHeo34jW3bttGmTRudUwohHka+IgghCr3ly5dTpaI9Xds5Zmnv1t6RSuXtWb58uU7JhBD/Jk8LkRkzZlCzZk1KlChBiRIlaNKkCZs2bcrLQwohiqGUlBTcXAzZFsLTNA13VwMpKSk6JRNC/Js8LUT8/f357LPPOHr0KEePHuWZZ56ha9eunDt3Li8PK4QoZp566ikOHkvmWmjWjqlXb6Rz6HgyzZs3Bx50aJWiRIiCJU8Lkc6dO9OhQwcqVqxIxYoV+eSTT3BycuLgwYN5eVghRDEzaNAg/P196TDgNms3J3Lnnom1mxPpOPAOAQF+1KpVi65dO2Nvb4+DgwNNmjRk48aNescWQpCPfUTMZjNLliwhKSmJJk2aPPQ5aWlpxMfHZ3kIIcS/cXJy4o8/duJRsgY9novEt+Z1ejwXiUfJGkyfPpNnn21FyPk/+GqSOz9+VRIbztOpUyeWLFmid3Qhij1N5fHMP2fOnKFJkyakpqbi5OTEokWL6NChw0OfO2nSJD788MNs7XFxcZQoUSIvYwohiojTp09z48YNgoKCqFmzJl26dOLShT84vNkPJ8cH370sFkWfkbc5ctqZ69fDsLKSAYRC5Kb4+HhcXFwe6fyd54VIeno6YWFhxMbGsnLlSn7++Wd27dpF1apVsz03LS2NtLS0zH/Hx8cTEBAghYgQ4rGkp6djb2/P1x968Mrzrlm2HTiaQrPOtzhw4ACNGzfWJ6AQRVROCpE8/xpgY2ND+fLlAahfvz5Hjhxh6tSpzJo1K9tzbW1tsbW1zetIQohiwmw2Y7FYcHTUsm1zdnpwdeT///IjhMh/+T6PiFJKfvGFEPnC3t6ehg3rsXBFUrb1Z+Yvi8fZ2ZF69erplE4IAXl8RWT8+PG0b9+egIAAEhISWLJkCTt37mTz5s15eVghhMj0/vuT6Ny5M/1evMNrL7rg7GRg/rIEvp4Zy8SJH+Dk5KR3RCGKtTwtRO7cucPgwYOJjIzExcWFmjVrsnnzZp599tm8PKwQQmTq1KkTixYt4s03X2NFp1sAODs7MnHiB0ycOFHndEKIPO+s+iRy0tlFCCH+SUZGBkeOHCE9PZ169erh7OysdyQhiqwC1VlVCCEKAmtra4KDg/WOIYT4H7LonRBCCCF0I4WIEKJAS09PZ9asWTRt2pjKlcvRp09v9u3bp3csIUQukUJECFFgZWRk0LVrZ156aTTuTudo/3QMZ09toHnz5syePVvveEKIXCB9RIQQBdbcuXPZsuV3Ni/xo/VTDgBMsShefOsuL7/8Et26dcPDw0PnlEKIJyFXRIQQBdavv86lbUunzCIEwGDQ+ORdDzIyMli5cqWO6YQQuUEKESFEgRUTE0W5IGO2di8PIyWcrYmOjtYhlRAiN0khIoQosGrVqseWHWmYzVmnOzp4LJX7senUrl1bn2BCiFwjhYgQosAaO3Yc10LTGT7uLpF3TCil2HsohaGvRFG1aiXatGmjd0QhxBOSQkQIUWA1bNiQefPmsWpjOgF1ruNW8QZPd7uFnWMQ69dvwmjMfttGCFG4SCEihCjQBg0aRETEbWbP/oWJH0xmy5YtnD59jjJlyugdLVelp6fzxRdfULFiWRwd7alduzo//vgjFotF72hC5ClZa0YIIXRmNpvp3Lkj27ZtpV83J+pUt2H3wTTWbErghRdeYNasWXpHFCJHcnL+lkJECCF0tmLFCnr37s2Ghb60e8Yxs33GvFhefucex44do27dujomFCJncnL+llszQohiLz4+npkzZ/Lqq6/yySefEBYWlq/HX7p0KQ1qO2QpQgBGDnShVElbli5dmq95hMhPUogIIYq1AwcOUKZMIC+//BLbt/7CZ5MnUbZsGX744Yd8y5CUlEhJLy1bu5WVhoebkcTExHzLIkR+k0JECFFsJSUl0aVLR6pWMHHtcGlO7/Al/FRpRg11ZsyYMRw6dOihr1NKceDAARYsWMCuXbueuENpkybBbN+bSlS0OUv7uZA0zoUkExwc/ET7F6Igk0JECFFsLV++nOjo+8yd5oW/rzUATo4Gvv3Yi7Kl7fjhh+nZXnP58mXq1q1FcHAwgwcPpkWLFlSuXIHjx48/do4XXngBe3snOg68ze4DKSQkWtiwLYnuw+5SrlwQvXr1eux9C1HQSSEihCi2QkJCKB1gT5lA6yztBoNG88bWhIScz9KenJzMs88+Q0riFTYv8SXxWjl2r/XHxeE2bdq04u7du4+Vw9vbm61btxOf4kPLHrdwrXCVLoMjcPeqytat27G1tX3s9yhEQSer7wohii1fX1/CI9OIijbj6fHX5GhKKU6fN1OmQmCW5y9ZsoSwsFtc2FuaCmVtAGja0J7fFnhTpkEYs2fP5t13381Rhjt37jBjxgy2bdtCqVKlaNOmPXXq1KFWrVrUrVsXTcved0SIokSuiAghiq3+/ftjNFoz7v17pKU96OehlGLG3DhOnElmxIjnszz/4MGD1KrmmFmE/KmkpxVPN7Hj4MGDOTp+SEgItWpV58svP8HX4ywu9qeYNesHpkz5jICAAClCRLEgV0SEEMWWp6cnc+fOY9CggWzfe4vmja25cMnMuZAUXn75Zdq3b5/l+U5OTtyLNmE2K4zGrEXCnXuKqj5OOTr+Cy+MwNU5iRNbA/D2evDnOORKOk93D+Xtt99mzpw5T/YGhSgE5IqIEKJY69u3L6dPn6Fv/xe5n9yA2vV7sHXrVqZNm5btikS/fv0Ij0xj9qL4LO1rNydy8mwyffv2feTjXr9+nd279zHxDZfMIgSgUnkbXh3hzJIli0hNTX2yNydEISBXRIQQxV6VKlWYOnXqvz6vQYMGjBw5ktH/+YlNf6TQvLEtx06ns3xdAt26daFTp06PfMw7d+4AULWiTbZtVSvZkJqaTnx8PHZ2do/+RoQohOSKiMiRuLg4EhIS9I4hhC40TWPmzJn8+OOP3LwbxEdfJ3M6pBRTpnzFsmUrMBge/U9q+fLlsba24o/dydm2bdudjLe3J+7u7rkZX4gCSQoR8Ug2b95Mg/oNcHV1pUSJEjzV/Cn27Nmjdywh8p3BYGDkyJEcP36a+Pgkzp0L4bXXXsPa2vrfX/z/8fT0ZMCAAXz0dRzrtyailMJkUsxZEsdPCxJ46aVXsLKSi9ai6JNF78S/Wrt2Ld27d8dN86KUpTQKC5GGGyQa4ti2bRtPP/203hGFKJQSEhLo1q0z27fvoqSXLRkZFu7HZjBo0ADmzJknhYgotGT1XZFrlFJUKF+BuOtJ1FJNMzvvWZSF44bdVG5QngMHD+icUojCSynFnj172Lp1K9bW1nTp0oXatWvrHUuIJyKFiMg1Fy5coGrVqtSmGZ5aqSzbIlUo5zjC3bt38fLy0imhEE/ObDazbNkyFiyYz/370dSt25AxY8ZQpUqVx9rf+fPnWbRoEXFxcdSrV48+ffrg4OCQy6mFKLhycv6WPiLiH5lMJgCMGLNtM/xfW0ZGRr5mEiI3mUwmevbszoABA0iM2UN5/4usXP4ztWvX4rfffsvRvpRSTJgwgWrVqjFzxhR2bP2F4cOfo1Kl8ly4cCGP3oEQhZtcERH/KCMjgwD/AAx37aimNchsV0pxWtuPe4USXLh4QWaALMZMJhM7duzgzp07VKtWjTp16ugdKUdmzZrF6NGjWDPPh07PPpiQLC3NQt8X77DnkIHw8MhHvpqxatUqevbsySfvevD6KDdsbDQuX0un14i7ZChfzp+/lKORNUIUVnJFROQaa2trJn04iUhCOa+OEqeiiVVRnOUw91QkH338kRQhxdiuXbsoHViaNm3aMHjwYOrWrUtwk2DCw8P1jvbI5s6dTcdnnTKLEABbWwPffORJbGw869ate+R9TZ8+jacaO/LOq+7Y2Dz4vahQ1oYZX3gQEnKVP/74I9fzC1HYSSEi/tWLL77I999/T5p7IkfYwVF2YihlYt68efTp00fveEInV69epV279qTdMdOQVrSkG7UI5tTRM7Rt0xaz2ax3xEdy504kVStmH3obFGCFvb0xc+KxR3HpUghPNcm+Um6T+nZYWWlcunTpibIKURRJISL+laZpjBkzhojIcA4dOsSRI0cIuxnGkCFD9I4mdPT999+DCWpamlBCc8OoWeGl+VLVVJ9z58+xefNmvSM+kipVqvPH7jT+9y71/iOppKSYc9Rh1c/Pj1Pn07O1X7iUjsmk8PPze+K8QhQ1UoiIR2ZjY0PDhg2pX7++zG8g2Ld3H64mL4xa1p8FFzxwsHbiwIHCMaz71VfHcex0Mu/8N5qExAcr8J4+n8YLb0ZTpUpFWrdujVKKQ4cO8cYbbzB69GgWLlxIWlpatn2NGPEi639PZMX6v2YfTki0MPa9aEqV8qJDhw759r6EKCykEBFCPBZnZ2dMhuzf/i2YybCk4eSUs5Vo9dK2bVumTJnC1zPj8K0VSpkGt6jTKox0c0nWrl2PUorhw5+jcePGLFk0nb075zNo0CBq1KhKaGholn0NHz6c3r170XfkbRq0Dafn8AgC64Zx6ISFxYuXYWOTfV0ZIYo7GTUj8tSVK1fYt28fdnZ2tGvXDhcXF70jiVwye/ZsRj4/kno8javmmdl+TV3gunaeK1euULZsWR0T5szNmzdZsmQJMTEx1K1bl27dumFtbc13333HuHFjmfWlF0P7lMBo1Dh7MY2uQ+7iF1ibvXuzXvmxWCz89ttvLFq0iNjYGOrXb8iLL75IYGCgTu9MiPwnE5oJ3aWkpPDcc8+xdOnSzDZ7O3s++/wzXn31VR2TidySlpZG61atOXDgIN4Wfxxx5r7hHlGW20yYMIH//ve/ekfMFVWqVKB2lbss/ME7S/uaTYn0HB7JqVOnqFmzpk7phCiYZPiu0N3oUaNZuXwVVahLS7rRjA54pPoyduxYVq5cqXc8kQtsbW35fevvfPjRJGxLa0Q4XKNM3QAWLVrExx9/rHe8XHP58jWaNcw+EqZ5I/v/2345vyMJUaTIFRGR6yIiIggICKS8pTqBWoXMdqUUpwz7KF3bn6PHjuiYUIhHFxTkT+umCfz4VdYrItt2J9O274ORZA0bNtQpnRAFk1wREbo6fvw4FouZkmQdqqhpGp4WH44dP4rFYtEpnRA58/zzo/h1RSK/70zKbLtzz8R/PoqhRo2qNGjQ4B9eLYT4NzIGU+S6P6vfNFKxI+vU2Gmk4OjgKLOxikLjzTffZM+eXbTvv40GtR3wcNfYsS+VEiVc2LZtsfwsC/GE5IqIyHXBwcH4+vhyQ7uARf115SNVJXPbKowBAwfIH29RaNjZ2bFhwyZWrFhBmYqdMNo/zaRJ/+X8+RDppCpELpA+IiJPrF+/nm7duuGoOeNh8sFEBneNt/D09uDwkcP4+vrqHVEIIUQekT4iQnedOnVi3759tO78DHFud7D4pDBm7EscPXZUihAhhBCZ5IqIEEIIIXKVXBERQgghRKEghYgQQgghdCOFiBBCCCF0I4WIEEIIIXQjhYgQQgghdCOFiBBCCCF0I4WIEEIUIhaLhcjISGJjY/WOIkSukEJECCEKAaUUP/30ExUqlMXX1xc3NzfatWvD6dOn9Y4mxBORQkQIIQqBL7/8khdeeIH6NWJYMduHGV+UJOz6Hpo3b8qFCxf0jifEY5OZVYUQooCLj4/H17cUzw+w5euPvDLbExIt1G4VTtPmPViwYKGOCYXISmZWFUKIImTnzp0kJaXwyvOuWdqdnQwM6+vAb7+t1SeYELlAChEhhCjgzGYzANZW2bfZWGuYzZZ8TiRE7pFCRAghCrjmzZtja2vN7EXxWdrT0iz8uiKZNm3a6JRMiCf3kPpaiIIlIiKChQsXcufOHapVq0bfvn1xcHDQO5YQ+cbT05Nx417n4y8+Jy7eQp+uTkTFmJnyfRzXQs3MX/hejvYXHh5OXFwcZcuWxc7OLo9SC/Fo8vSKyOTJk2nQoAHOzs6ULFmSbt26ERISkpeHFEXMzz//TGBgaca/M4Efp/3MiOEjKB1YmiNHjugdTRRhaWlpZGRk6B0ji08//ZQPP/yI+SssNO10i65DIolPLcPmzVuoX7/+I+3j1KlTPP10M/z9/alWrRq+vt5MnDgx89aPEHrI01Ez7dq1o1+/fjRo0ACTycSECRM4c+YM58+fx9HR8V9fL6NmirejR4/SsGFDfFUZKlADK82aZJXIBeNRrNw0QsNCsbe31zumKEK2bNnCh5M+5MDBAxgMBjp06MB///tfatWqpXe0TCkpKVy4cAFHR0cqVqyIpmmP9LqrV69Sv34d/EuZ+M/LJQj0s2bt5kSm/RzHyJEvMmPGjDxOLoqTnJy/83X47r179yhZsiS7du3iqaee+tfnSyFSvA0bNoyVC1fTyPRslj+2ySqR/Wxm3rx5DBkyRMeEoihZuXIlvXv3xlXzpJQlADNmIo03MNtksG//PmrXrq13xCcyevRo1qyaw/k9friUMGa2fzvrPm99FMO1a9coXbq0jglFUVJgh+/GxcUB4O7u/tDtaWlpxMfHZ3mI4uvc2XM4m9yzfeNz0Jxwsi7BxYsXdUomihqz2cy4sePwxIe6lqfw08oSqFWgvrklxnQbxo+foHfEJ7Z583r6dbPPUoQAPD/IBaUsbN26VadkorjLt0JEKcXrr79Os2bNqF69+kOfM3nyZFxcXDIfAQEB+RVPFEB+fn6kGhOytaerNFLMSZQqVUqHVCK/JSQk8Nlnn1GzRk3KlinLkCFDOHXqVK4e48SJE9wKv0WgqpCl8DVqVviag9i8eRMpKSm5ekw9WB4yylepBw8h9JJvhcjLL7/M6dOnWbx48d8+59133yUuLi7zcfPmzfyKJwqg4SOGc98cTbi6ntlmURYua6cxGo30799fx3QiP8TGxhLcJJj3JrzPvbNxmG4YWbV4DQ3qN2Djxo25dpy0tDQArLDOts2INUopTCZTrh1PDx07dmXJ2mRi7mftmDpzXixGo4F27drplEwUd/kyfPeVV15h3bp17N69G39//799nq2tLba2tvkRSRQCnTt3ZuTIkfz0009EGm5gZ3Yk3iqaNEsqc3+Zi5eX17/vRBRqn3/+OSEXL9HA0hInzQUAi8nCGcMBnhs2nFvhN7G2zl485FTt2rVxdnImMjEUZ1wz25VS3DGEUat6bZydnZ/4OLnNZDKxfv16Lly4QKlSpejZs+ff3o9/8803WbJkIc26RPD6qBIE+lmxdnMSs+bH8corr/7j32Yh8lKedlZVSvHKK6+wevVqdu7cSYUKFXL0eumsKpRSbNy4kTlz5hAZEUmNmjV46aWXqFmzpt7RRD7w8/HDcNueylqdLO0JKpZDbGPLli25NpnXxx9/zMSJEylNRXwojRkzYVzmDjdZvXo13bp1y5Xj5JazZ8/SpUtHrl8Pw83Vhti4dJycHJk7dz49evR46GvOnz/Pa6+N5ffftwFQsqQHY8e+zjvvvIPBIPNbityTk/N3nl4RGTNmDIsWLWLt2rU4Oztz+/ZtAFxcXGTYpXgkmqbRsWNHOnbsqHcUoYOY2PsE4Jmt3Z4Hw/9jYmJy7VgTJkzAYrEw5YsphCZfAsDL04t5X80rcEVIamoq7du3wb1ELMe2BlK7ui3hkSZemxhFv359OXnyFFWrVs32uqpVq7Jly1aioqKIj4/H398fGxsbHd6BEH/J0ysifze+fc6cOQwbNuxfXy9XRIQo3oKbBHPpyDVqm5tl+XsSqcI4x2EuXLhA5cqVc/WYCQkJHD16FGtraxo1apQrt35y26JFixg4cCDndpemcoW/Com0NAtlG96iR68RTJ8+XceEorgrMFdE8nGKEiFEEfTmW2/Ss2dPLnOaIFUZa2yIIpKrxjO0a90u14sQAGdnZ1q2bJnr+81Np06domxp+yxFCICtrYFWzW04ffqETsmEyDm5KSiEKLB69OjBlClTiLS6wR7Ws8uwllPsp2FwAxYuWqh3PN14eHhw+14GCYnZx+NeuW7GwyP77SwhCqp8nVk1p+TWjBAC4O7du6xdu5bExESCg4Np2LDhI09tXhTdvHmTMmWCeHl4Cb760DPzs1j+WwL9XrjNihUr6Nmzp84pRXFWYKd4zykpRPLPrVu32Lx5M0opWrduTZkyZfSOJIT4B1OnTmXcuHHUqOJAi2Abzl8y8ceeRPr378uCBYtkFIzQVYHpIyIKPovFwhtvvMG0qdOw/F9Nqmnw/PPP88MPP2BlJT8iovhKT09n1apV7Nu3D0dHR/r06UPdunX1jgXA2LFjqVWrFt9/P41t+8/g4+PHr78+T//+/aUIEYWKXBEp5j7//HPefeddylENf8qhoRHOda5oZ3jn3Xf45JNP9I4ohC7CwsJo9Uwrrly9QglrVzJUOimmZEaOHMnMmTPlZC/EP5BbM+KRZGRk4Ovjh220M1W0rN/yLqvTxDhFcvvObRwcHHRKKIR+mjQO5syxs1Q3NcJZc8WiLERwnYucYMaMGYwaNUrviLlGKcWCBQv48ccfMZlMdO/enXHjxskcI+KxSSEiHkloaChBQUHUphmeWtYF5GJVFEfZyenTp6lRo4ZOCQu26Ohofv75Z7Zt+wMbG2u6d+/OwIEDZbK+IuDUqVPUrl2bmgRTUvPNsu0MB3Gv5Mz5C+d1Spe7UlJSqFq1MjduhOFgr6FpkJSscHFx4sSJ09JfTDwW6SMiHkmJEiXQNI1UlZxtWyoP2lxcXPI7VqFw6dIlnmr+NFFRUbhZvFAGC5s2bmL69z+wY+d2XF1d9Y4onsClSw9mVnV7yKyuLsqTK1fP5XekPNOhQwdu3Qrjl6neDOj+YD2dRasTeOGNO7Ro8TShoWE6JxRFndzkLMbc3Nxo27Ydt4xXSFdpme0mlUGY8TJNmgQTGBioY8KC67nnhpMcnUITS1tqa02po5rTgGc4f/Y877//vt7xxBPy8/MDIJG4bNsSicO3lG+29sIoOTmZvXt38eZoN4b2KYG1tYa1tcbQPiV4fZQb4eE3OXnypN4xRREnhUgx9+2332BbwprDVtsIUSe5pE5xyGoryt7EDz/IFNEPc/nyZfbv30eQuTJ22l+3YUpobviayzDnlzmFfsn44q5JkyZUrFCRq8azWYr0aHWHO4YwRr44Usd0uef69euYTIo2LbL3A2vTwgGzGQ4ePKhDMlGcSCFSzFWqVInjJ4/zwksj0QIysPilMvT5IRw/cZzatWvrHa9AioyMBMCJ7LetnHEhKTmJxMTE/I4lcpGmaSxZugSczBwwbOak2scxwy5OsIcWLVrw5ptv6h0xV5QsWRKAS9cysm27dPVBW8WKFfM1kyh+pLOqEDkUHh5OYEAgFVVt/LWyWbZdVMdJ80zg9p3bMryzCLhz5w4//vgje/fuxdHRkX79+tGjR48iNb9OxYrlSU0O5cCGAHy8H7yviNsmgjveJCHZnpiYuGI9i614PNJZVYg85OfnR9duXdm0bjOOZmdc/69D421uEqHdYNKrk6QIKSK8vb2LfJ+fNWvWUb9+Hco3vkGPDk4ArNqYiMWssXbdMilCRJ6TKyJCPIbo6GjatmnHseNHcbIugVmZSTEl0btXbxYuWlggl44X4u+Eh4fz6quvsmvXdpTFQp26Dfjuu++oUqWK3tFEISXziAiRD8xmM5s2bWL79u3Y2NjQrVs3GjVqJN8ghRDFnhQiQgghhNBNTs7fciNbCCGEELqRQkQIIYQQupFCRAghhBC6keG7QvyDkJAQZs2axaVLl/Dz82P48OE0atRI71jiMYWFhbF27VrS0tJo0aIF9evX1zuSEMWeFCJC/I1FixYxZPAQrA02OJlcSbHazY8//siHH37IxIkT9Y4nckApxbvvvsuUL6YAGkbNQIYlgzbPtmHFyhU4OzvrHVGIYktGzQjxEBEREZQuXRovsx9VVF0MmhGlFNe5wDXOs3fvXpo2bap3TPGIZs2axahRoyhHNQKogBEjdwknxHiCHr27s3jxYr0j6sZkMrFv3z4SExOpW7cuPj4+ekcSRYCMmhHiCS1YsADNolFJ1cagGYEH64+UoQpOViX4+eefdU4ocuLLKV/irQVQRquClWaFpml4a/6UMVdh2bLlhIeH6x1RF+vWraNMmUBatGhBp06dCAwM4Pnnnyc1NVXvaKIYkUJEiIe4efMmjkZnrLSsM6RqmoaDqQRhYWE6JRM5lZaWxpWrV/BQ3tm2eeKDxWLm/PnzOiTT1/79++nRozu1qiRwYGMA148E8dkENxYunMuLRWR1YVE4SB8RkSdu3LjBqVOncHd3Jzg4GKPRqHekR3Lp0iXmzJnDgQMHiDfFkq5SsdHsMrdblIVEq/uyImkhYm1tjYO9AykpSdm2JfNglWR3d/f8jqW7L774jCoVbFn1SymsrB7MBvzaKDfs7DReGb+QDz/8mKCgIH1DimJBroiIXBUXF0ePHj0oW7Ys3bp146mnnqJMUBn++OMPvaP9q5kzZ1KlchW+mfItV0+EYlGKcxwhXaUBYFYmLnGKFHMyL774os5p89a9e/cYP3485cqWx8/Xn0GDBnHq1Cm9Yz0Wg8HA4CGDiTTeIFklZrablIkbhgtUqliJunXr6phQH7t376JPF4fMIuRP/bs7o5Ri37593L17l48++oiWLZ+mTZvWzJgxg+TkZJ0Si6JKOquKXPXss23Ys2MPZc3V8MSHFBK5brhAolUsx44fo1q1anpHfKgzZ85Qq1Yt/FRZKlATo2bkrgrnDAcBcLFyJ1klYlIZ/PDDD0W6ELl9+zaNGzUmMjwSL7MfVlgTbRVJupbGho0baN26td4Rc+zu3bsENwkm9EYYnhYfjFgRY3UbzRq2/bGNJk2a6B0x3/n6lqR/1wymfOCVpf16WAblG91g6tSpfPLJRyQmxtKupT2JSYptu5OpWbM627fvws3NTafkojCQzqpCF0ePHmXbtq1UNNfGTyuDrWaHq+ZJTUswVhZrvvrqK70j/q2ffvoJe6MDFamF8f86p9rhgBe+AFgcMujUtSMhISFFuggBmDRpEnci7tLA3IoqWj0qaDVpaGqNs9mNEcNHYLFY9I6YYyVLluTI0SN8+PEkvGu64VjBmudeGMbJUyeLZREC0KtXP+YtSybitimzTSnF59/F4OzsyMKF8/F0S+bKwUCW/+zDpsW+HP09gBvXL/L+++/rmFwUNXJFROSab7/9lrfeeIunLV2zrUAbok5iFWTm2vVrOqX7Z507d+bg+mPU1h4MyY1UYZzjMHY44I43KVoC91UUvXr2YsnSJYWmz0tOKaVwdnKmZHIA5bTqWbbFqiiOspN9+/YRHBysU0KRWyIiImjUqD4ZadG8MNgJ75JGVq1PZvveJN5//30+/vhjlv/sQ4+OTlle9/5nUXz3SzoxMbFYWUk3Q/FwckVE6MLe3h6zsmAiI9s2E+k4OjjqkOrRlC5dmmSrBCzKQoZK5wLHKEUgwbSjqlaPerSgJk1YsXJF5pwTSUlJzJ07l3feeYdp06Zx7949nd/Fk7NYLCQlJ2GHQ7Ztf7bFxsbmcyqRF3x9fTlw4DAdOw/imx9TefmdeyRlVGHVqlU888wzAFSvbJPtddUq25KQkCR9RUSukUJE5JouXbpgMGiEEpKlPUklcM8QQb8B/XRK9u+ef/55kk2JXOEMt7mJwkIFamLQ/voVKan54WHw5pfZv3Dw4EECAwIZ/txwpn89g9dfe50A/wAWLVqk47t4ckajkRrVaxBluJ1t210iMBiM1KpVS4dkIi/4+/sze/Zs4uMTMZvNHDx4hO7du1OhQgUMBgM79qVke82Ovcn4+ZXCycnpIXt8UKBv3LiRdevWER0dnddvQRQBUoiIXOPj48OkSZO4QQintP3cUle5rE5z3LiLcuXLMWbMGL0j/q3atWszdepUwrjMVcNZjFhh+/8N2/2TvcWJiIgIOrTvgIo3Ekw7Gpva0NTSAfcMb4YMHsK5c+d0eAe55+133uaeJYLL6jTpKg2LshCpQrluPEf//v3w8/N7pP2kpaXxxx9/sHHjRjkhFXCapmEw/HU68PPzo0ePbrz/eSzb9yajlMJkUvyyOI45SxJ4+eWxWZ7/p++//x4/v1J07NiRrl274ufnw1tvvYXZbM7PtyMKG1WAxcXFKUDFxcXpHUXkwMKFC1WtmrWUpmnK1cVNjR07VkVFRekd65GcPXtWde7cWQGqEa1Va61X5qMVPZWzlYtqUL+B0jRNNaNDlu3P0EPZWzmoMWPG6P02ntjkyZOVjbWNApSGpgDVtUtXlZiY+Eivnzt3rnJ381CAApSNtY167bXXVEZGRh4nF7klOjpaNWnSUAEqwM9OeXo8+HkYPHjQQ/8fFyxYoAD1wuAS6vye0ur6kSD1wZvuymDQ1Pvvv6/DOxB6ysn5WzqrijyjlMrWabUwMJlMlC9Xnvvh8VQ118dJcyFDpXOFM0RoN+jduzebV2+loalVtteeUQep/FQ5du7amf/Bc1lUVBTr168nNTWV5s2bP/LQ63Xr1tG1a1dKEUhpKmKFNZGEckO7yGuvv8aXX36Zx8lFbrFYLGzdupUdO3ZgY2NDt27dHjrnilKKatUqUT4wkjVzs65V8/bHUfy4IJ3w8Nt/eztHFD05OX9Ll2eRZwpjEQJgZWXFps2baNumLQdvbcXByok0cwoGo4FZ02cRHR3N6pWrMamMLFPAK6VIsUqilE8pHdPnHk9PT4YNG5bj13380cd4GLypZmmQ+TNQlqoopfjmm29xdnbm5ZdfxsPDI5cTi9xmMBho27Ytbdu2/cfn3b9/nwsXLvPeq9l/9vt1c+LLH25y5syZYjtUWvwz6SMixENUqVKFq9eusnz5ct545zW++fYbbt26xciRIxk0aBAWZeEKZ/jzgqJSinCuEW+6z/Dhw3VOr5/09HSOHjtKSYtftkK0FIFYLGY++vAjKlWszJkzZ3RKKXKbra0tmqYRcz97X5ComAdtjo4Fd9Sc0JfcmhHiMfy5rLyTVQmcTW6kGBOJNUfz0ksv8f333xfaq0FPymw2Y2dnR5CpCkFapSzb4lQ0R9hBTZoQagzBp3xJzl84X2w/q6KmbZtnuXZlF0e2BFDC+cE8OxkZig4DIwi/68OFC5fl/7oYkXlEhMhjL774IocPH6bnwO741y9Jyy5PsWHDhmJdhMCD4b/du3cn0uoGGSo9s10pxQ1CsMUeT3woZ67OxZCLHDx4UMe0IjclJCZwIyyD2s+E8ck3MXw98z4N2oaxY28ynTt3L9a/F+KfyRURIUSuCgkJoXGjxmQkmSllCvy/zqphxBNDDRrjrfljUhnsZC1Lliyhb9++ekcWT+jChQtUrVqVKR94cuJMGms3J5JhglbN7bkfq0hXFTl27KTeMUU+kisiQgjdVKpUiUOHD9G1T2eucZ4QTmLESB2a4635AxBLFADlypXTM6rIJWfPngXguX4l+HV6KeKvlicltDzrF/jRr5sTZ8+e1zmhKMikEBFC5LqKFSuycOFCpk6bCoAPpXGnJPBgpt2rVmepU7sO9erV0zOmyCUlSz74vw25mp5tW8jVdLy83PM7kihEpBARQuSZl156iSFDhnCeoxy02sJR4w4O8juupUqwfMVy6TdQgB08eJCBAwdQq1Y1nm39DAsXLvzbGVKbNWtGUFAA4z+5T1LyX6szHzuVyrxlSQwdOiK/YotCSPqICFHMhYaGcv36dQIDAylbtmyu718pxYEDB1i6dClJSUk0bdqUvn374uCQfWE9UTDMnj2bkSNHUr6MHa2a2xByxcSOfUn06dOLRYsevvr07t27ad++LU6OFjo9a8e9aAsbtyVRt24d/vhjJ87Ozjq8E6GXnJy/pRARopiKjIxk+HPD2bxlc2ZbyxYtmTN3DqVLl9YxmdDT3bt3CQjwZ0hvB2Z84YXB8OCq1aoNifR+PpJFixbRv3//h7728uXLfPfdd+zbtwtHRyf69OnP8OHDpegshqQQEUL8o7S0NGrVrMXNa7cIMlXBBQ8SuM91qwt4+Lhx7vw5mY67mPruu+94881xhJ8Mwt3trysfx0+n0mlQJGnpNlStVoMBAwYzYsQI7OyyLw4phIyaEcVWREQEkyZNomPHjgwcOJD169djsVj+/YXFzMqVKwm5FEINUxN8tSAcNWdKaYHUMjXl5q2b/Prrr3pHFDq5d+8enu42WYqQlesTaNzhJra2MLCnNR7O5xg79hXatXuW1NRUHdOKokAKEVFk7Nu3j0oVK/HpfydzeOMJNizdROfOnenfr78sQ/4/tm/fjquVO86aa5Z2B80JN82L7du36xNM6K5mzZpE3E7l7MU0AJKTLbzw5l26tXfk8oEgpn1SkjVzfdixyo/9+/fzww8/6JxYFHZSiIgiISMjg969emOTYk+wuR21tabUNz9DDRqzfPlyZs+erXfEAsXa2hozZh52Z9aimbG2tn7Iq0Rx0KVLF4KCAhg4+h6nzqWxflsSsXEWPn/fCyurv0Y5NW1oT/cOjsyf/4uOaUVRIIWIKBK2bNlC5O1IKlhqYa3ZAA9W//XW/PEy+DJr5iydExYs3bt3J8EURxSRWdrvq3vEmqPp0aOHTsmE3mxsbNiwYTNJaV7UbR3GyDeiMBigtH/2xdorlLEmOjpah5SiKJFCRBQJt27dAjSccMm2zdFSgpthN/M/VAHWunVr2rVrx1nDYULUSW6rm1xWpzlt2E+zps3o2rWr3hFFHjt37hyffvopH330Efv27ctydaxq1aqEhFxh1apV9O07FIsFtu1OzvJ6pRSbt6dSs2btfE4uihopRESRUKFCBUARR/ZvZwmG+1SoWCH/QxVgBoOBNWvW8M67b5Pkdp+zHCK2xB3Gvj6WzVs2y62ZIsxsNjNixAiqV6/O559NYtrUT2jWrBlt27QmISEh83nW1tZ0796dn376iQYN6vLCm9Hs2p+MUoroGDOvTrjHsdPJjBv3uo7vRhQFMnxXFAkWi4VKFStx90Y01c2NcNCcsCgLN7nCZU6zePFi+vXrp3fMPBEaGkp4eDhlypTBx8cnx6+3WCwkJCTg5OT00ImqRNHy2WefMWHCeL771JPh/V2wsoLffk9i6Cv36NFzAHPnzsv2mvDwcDp1as/Jk2dwKWFNUrIZg8HI119/w5gxY3R4F6Kgk3lERLF0/vx5Wj3Tmjt3buNi7UaaSiXFlMzrr7/Ol19+WeSmE79x4wYjho9g+44HI1wMmoHu3bszc9ZMPD09dU4nCiKLxUJAgC8dn0lh5hTvLNu+mXmfdz+N5dat8My1Y/73tdu3b+fo0aO4urrSs2dPvLy88iu6KGSkEBHFVlJSEkuWLOHIkSO4urrSv39/atWqpXesXBcXF0eN6jWIuR1LkKkyzrgSSxQ3rC5SqWoljh47gpVV9s6FoniLjo7G09OTZT+VomenrFOun72YRq2WYezdu5emTZvqlPCfnTp1ihkzZnDx4jl8fPwYPnwErVu3LnJfMoqCnJy/5S+VKFIcHR0ZMWIEI0YU7UW25s2bR3h4OE1UW+w1RwCccMHJ5MrR0zv47bff6N69u84pCw+z2cyePXuIjo6mZs2a/9fnqOhxdnbGzs6GkCsZ2bZdvPJg5dyHXQ0pCObNm8fw4cPxLWVNs0bWnD15jDZtljJ27Fi++eYbKUYKMemsKkQhtHXrVtzwyixC/uSqeVDC2pVt27bplKzw2b59O0Glg2jZsiW9evWiYsWKdGjfgZiYGL2j5TobGxv69RvAtNkJXL6WntkeFW3moy/jaNKkYYEswiIjIxk58nmG9nXiysEAFv7gw8ntfnz7sRdTp05l69atekcUT0AKESEKIWtrayxa9qnrlVKYlUxI9qguXLhAh/YdSInMoAEteYrOVKMBO7bupEuXrg+d8K2w+/zzz3H3CKRmy5v0GhHJ4DG3Kd84jDvRdvz0U8GcnGzhwoVYWSm+/MATa+sHVz40TePlES7UqOLAnDkFM7d4NFKICFEIde3alfuWe8SprN/a7xFBkilB5gF5RN9++y1GixU1LcG4aB7YaLb4aKWpbK7Lvn172b9/P/Bg5t7Zs2fTrFlzKlWsRP/+/Tl48KDO6R9PyZIlOXToKJ988jl346pz5VYFXnn1P5w6dZZq1arpHe+hIiMjCfSzxdUl66guTdOoXtlIZGS4TslEbpBCRIhCqF+/ftStW49Txn1cVWe5q8IJUSc5ZzhChw4daNGihd4RC4VdO3fhbvLGqGU9wXlQChujDXv37iUjI4OuXbsy8vmRXDpwlZTLFjas2ERwcDBz587VJ/gTcnFx4c0332Tv3gMcOnSMTz75BF9fX71j/a1KlSpx+VoKN8Oz9m0xmRR7DqVTqVJVnZKJ3CCFSDFnMpmYNm0alStVxt7ensqVKjNt2jRZJK6As7W1Zfv2Pxg56nnu2IdxmgMkukbz9jv/YdWqVdJx7xE5OTmRoaVnazdjwmQx4+joyPz589m8aTO1aUot1ZRKWm0amlrjo0ozetTov+1LkpaWxvHjxzl37lyhucWTkZHB4sWL6dWrF507d+Krr77i/v37eseif//+uLqWYMjL9zKLkbh4My+9fZeI2xmMHj1a54TiSeRpIbJ79246d+6Mr68vmqaxZs2avDycyCGlFAMHDmTcuHHEXU4mILUicZeTGTduHAMHDiw0fzyLKxcXF77//nvux97n3r173L13l08++QRbW9tszw0LC+O3335j7969habINJlMnDx5kpMnT2IymfLkGP369yNKiyRRxWVpDyUETXuwJs+cOXPxNJTCQyuVuV3TNMpTnfT0dFauXJnltUopvvzyS3xK+VKvXj2qV69OxQoVWb9+fZ68h9ySlJRE69YtGTBgAJFhm0lP3Mn48f+hbNnS1K5dg1q1qvHSSy8REhKS79mcnZ1Zt24DZy9ZUbZhKFWbh+NXO5T5y5P56aefqF27dr5nErknTwuRpKQkatWqxffff5+XhxGPafv27SxbtoxqqiHVaURprSLVaUQ11YClS5eyc+dOvSOKR2BjY4Onp+dD5w1JSEigT58+BAUF0aVLF5o3b06ZoDIFflTNnDlzCPAPoE6dOtSpU4fSgaWZNy/7jJ9P6sUXX6RKlaocN+4iRJ0kTF3hlLaP61zk/Ynv4+fnR9Tde9haHLK91hpbrI02REVFZWn//PPPeeutt3CMdaU+LalDM+5fS6Rr125s3749199Dbvn44485evQQO1f7s2edL5sW+3L5QCCebqmE37xA41q3WL3yF+rWra3L34amTZty48ZNZsyYSYfOL/Lhh5O5cSOU4cOH53sWkbvybUIzTdNYvXo13bp1e+TXyIRmeeuFF15gyZxlNDRlnRBIKcVhq230H96XWbNk1drCrEP7DvyxdTtlzVXxwpcUkrhuuECC8T5Hjx2lRo0aekfMZv78+QwdOpRSBOBHWQBucY073GThwoUMGDAgV48XGxvLZ599xpxf5hBzP4Ya1Wvw5ltv0r9/fzRNo3///mxYsSnb70mciuYIO9iwYQMdOnQAHnz5KuVdCrekUlTSamc+VynFMcNOagRXZfee3bmaPzcopShZ0oOB3RVff5R1ttQ1mxLpOTyS0zsDKRNgTefBtwmN9ODy5WuyJID4Wzk5fxeoPiJpaWnEx8dneYi8k5iYiLWyydafQNM0rJUNiYmJOiUTueHkyZNs2ryJiuba+GvlsNXscdU8qWUJxlrZ8tVXX+kdMRuLxcL7772PN/5UoyFumhdumhfVaUhJzY/3JryHxZJ92PKTcHV15bPPPuPO3TtkZGRw/MRxBgwYkPl7MW7cOBLN8VzgGGkqFaUUcSqai1bHqVC+Am3bts3c1+HDh0lMSsSPMlmOoWkapSyB7Nm7h7S0tFzNnxvS09OJirpP7erZb+vVrfGg7VaECQcHA/99143r18PYt29ffscURVSBKkQmT56Mi4tL5iMgIEDvSEVakyZNiLVEk6qyLu+dqpKJtUQTHBysUzKRG/bs2YNBM1ISvyztBs2Ih6kUO7bv0CnZ37t69SphN8PwIShLgaxpGj6qNNdvXCc0NDRfMzVq1Ig5c+YQY3ubfdpG9lpt4Ag7KBVUkk2bN2W5KvDn7TEL2YslCxY0TcNgKFB/doEHt/f8/X3Yeygl27bdBx+0lS/zYG6aCmVsALLdkhLicRWo34h3332XuLi4zMfNmzf1jlSkDRkyBE9PL04bDxCj7mBSJqLVHU4b9+Pl5cXgwYP1jiiegL29PUpZMJO9o2cGGdjbZ+/3oLc/T+Tqb07kQJ7cDrh//z6rV69m1apVDx0FM3ToUCIiI5g5ayaTPv6ADRs2cOHiBcqVK5fleQ0bNsTdzYObXMnS2duszNw2htKuXfsCOdmcpmm89NIrzFuWyKJV8VgsD7IfO5XKu59E0aaFA+WCHhQgm7YnAVC9enXd8ooiRuUTQK1evTpHr4mLi1OAiouLy5tQQp07d05VqVxFAZmPqlWqqnPnzukdTTyhO3fuKCsrK1Waiqq11ivzEUw7ZW20UZMmTdI7YjYWi0VVqVxFeWjeqhU9MzO3oqdyN5RUNarXUBaLJVeP9+GHHypbW7vMn39bG1v13nvvPfZxfvzxRwUoL81X1aCxqkI95WJ0V3a2durIkSO5lj23ZWRkqD59eilA+fvaqcoVHnwmpbyM6uK+0iojvLxav8BXeXrYqI4d2+sdVxRwOTl/SyEilMViUfv27VMLFy5U+/fvz9U/9EJfn3766YOTosFHVaaOKk0lZWu0U+XKllPR0dF6x3uo9evXK4NmUO6GkqoaDVU1Gih3g5cyaAa1adOmx9pnWFiYGjVqlHJ3c1eODo6qQ4cOau/everbb79VgAqikmpGB9WMDiqIygpQX3zxxWO/h0WLFqmKFSpmFjctnm6hDh48+Nj7yy8Wi0Xt3btXvfbaa2rUqFGqZ8+eStM0ZWtrVK4u1gpQzZo1UVFRUXmexWw2qx9++EFVrVpRGQwG5e9fSk2cOFElJSXl+bHFk8vJ+TtPR80kJiZy5coVAOrUqcPXX39Ny5YtcXd3JzAw8F9fL6NmhHhyixYt4vPPPuf0mdOUcC7BkKFDmDhxIl5eXv/+Yp1s2bKFCeMncOz4MQDq16vPp5M/5dlnn83xvkJDQ2lQvyEJsYl4mwKwwpooYzgJljhKlHDBIc6Fqlr9LK+5oI6T6h5PRGQ4NjY2j/UelFLcvXsXW1tbXF1dH2sfBcHNmzdZvXo1SUlJNGvWjGbNmuXLhHmjR49m1qxZ9OzkRIumdpw5n868ZYk0bNiYrVu3P/b/i8gfOTl/52khsnPnTlq2bJmtfejQoY80NbIUIkLkHqVUoZtxNTo6GgAPD4/H3seQIUNYuXgV9UwtsdXsALAoCyfZQwz3qEOzLJOVAcSouxxnNxcuXKBy5cqP/wbEYzl16hS1a9fmu0+9eOk518z2vYdSeLrbLebPny992Aq4nJy/s8+AlItatGghs3MKUUA8ShGilGLnzp2sX78ei8VC27ZtadOmjW4jPZ6kAIEHw4GXLV2Gn6l8ZhECYNAMBKiKxHCPdLIPp/2zzdHR8YmOLx7PihUr8PSwYeQglyztzRrZ83QTR5YtWyKFSBGSp4WIEKLwSElJoVvXbvy+9XccrZzRNI1vv/2WpsFN2bhpY6G8KmmxWEhLT8OW7PNjOOIMwE3DZUpa/DBqD/4cmpWZW4YrNKjXUKYQ0ElycjIuzkasrbMXz+5uEJec/JBXicKqQA3fFULoZ8KECWz/Ywe1CKaxqQ2NMp6lDs05cugoY8eO1TveY7GysqJunbrcM0Rkuzp7l1sYjUYybNM5YrWda+o819QFjlj9QapNMtOmTdUptWjWrBlXb6Rw5GRqlvboGDNbd6XRrNlTOiUTeUEKESEEqamp/DjrR/wt5fDSHixSqWkaHpo3geaKLFywsECswvo4Jrw3gSjLbS5ynGSVSLpKI0xd5rrhAiNHjuTw4UN06tWBu45h3HG4QYce7Th06CCNGzfWO3qx1blzZ6pXr0KvEXdZ/lsC96JM7NiXTIcBt7GxdeTFF1/UO6LIRXJrRgjBnTt3SEpOoiKe2ba54ckVUwZhYWG4ubnpkO7J9OjRgx9++IH/vPUf9iddB8BgMPLcc8OYOnUqNjY2LF68WOeU4v9nZWXFli3bGDSoP/1e+GttnqpVK7F16yJ8fX11TCdyW74tevc4ZNSM+F9JSUlYW1vL0L1clpiYiLubO6VNlQnSKmXZdktdI0Q7QWRkJN7e3jolfHKJiYn88ccfpKam0rRpU/z9/fWOJB7B+fPnuXjxIr6+vjRq1KjQjfwqrgrtondC/J0lS5ZQvVp1nJyccHBwpE+fPly+fFnvWEWGk5MTffv15ZbxCokqLrM9WSUSZnWJjh07FuoiBB68x65du9K3b18pQgqRqlWr0qNHDxo3bixFSBElV0REgffdd9/x6quv4mXwwcviRwZpRFjdwNbZmqPHjlKmTJl/34n4V/fu3eOp5k8RcikEd0oCGve5S2Dgg1Vj5eQthHhUBWZCsyclhYhITEyklHcpXJO9qUydzG9E6SqNo1bb6T+0Hz///LPOKYuOpKQkFixYwLp161BK0a5dO4YNGya/f0KIHJFCRBQZ69ato2vXrgTTDgfNKcu2K+os90vcJjaucI7mKO7u3LnD999/z9o167BYLHTq3JFXX31VOiIKUQQUmJlVhXhSaWkPZrg0PuRH1Qor0tOzz4opCr7r168T3KQpMVHReJh9AI1vQr7l559ms2//XipVqvSv+xBCFA1SiIgCrVmzZhiNRiLNoQTx18nJoizcNYbzTKtndEwnHtfYsWNJiEqkkflZbDV7ANLNaZyI281Lo1/ij+1/6JxQFCdJSUksXLiQ33//HYPBQKdOnejbty+2ttln5BW5T0bNiALNx8eHF154gWvaOa6qcySpeO6re5zW9pNEPBMmTNA7osih+/fvs2HDBvzN5TKLEAAbzZYAcwW279hORESEjglFcRIZGUn9+nUYPXoUURGbCL+xgaFDhxIc3KjQTuJX2EghIgq8qVOnMnbcWCJsr3OA3znGLpwC7Vi3bh1NmjTRO57IodjYWCwWCw44Zdv2Z1tMTEx+xxLF1Jgxo4m7H8bpHYFsX+XHnnV+HN4cwPVr53nzzTf1jlcsSGdVUWjExsZy8uRJnJycqFu3rm4rwoonk5aWRilvH5zjPKik1c6y7Yo6y137MO7euysr34pMf56mcnsekTt37uDr68t3n3owaqhrlm2ffhvDJ1MTiI6+j4ODQ64etziQCc1EkeTq6kqLFi2oX7++FCGFmK2tLa+8+jLh2jVuqWtYlBmLshChbnDTcJlRo0dJEVJImUwmZsyYQf36tfHz86Zly6dYuXJltgUHH9W5c+fo06c39vZ2WFtb07bts+zduzfX8kZERGCxWKhXyy7btnq1bElNTScqKirXjiceTv6aCyHy3cSJExk8ZDAXOc5uw2/sMf7GeY7Ss2dPPv30U73jicdgNpvp27c3L788Bn+va4zoZ0KlHadXr168//77Od7fqVOnaNKkEcePrOeDN5yZMtGNe5H7admyBZs2bcqVzIGBgVhZGdl/OCXbtn2HU3FycqBkyZK5cizx9+TWjBC57PDhw3z11Vfs37cfFxcXBg0exMsvv4yTU/Y+EYWRUoq4uDiMRiPOzs5PtK8LFy6wceNGLBYL7dq1o0aNGrmUUuS3VatW0bNnT1bN8aFru79+1j/9Nob3P4/mwoULVK5c+ZH316FDO25c3cXBjX44OT74zmwyKToMjOTWnVJcuHA5V27VDBo0kE0bl7N2njfBDexRSrF1VzK9nr/L8OGjmTZt2hMfozjK0flbFWBxcXEKUHFxcXpHEeKRLF++XBkMRuVs5aJKU1GVIlAZDVaqVs3aKj4+Xu94T2zt2rWqVs1aClCAeqblM+rgwYN6xxIFQM+ePVTDOg7KHFkhyyP5Rjnl5mqtJk6c+Mj7SkhIUJqmqemfeWXb3+YlvgpQp0+fzpXcMTExqkGDugpQVSs5qIrl7BWgWrZ8SiUmJubKMYqjnJy/5daMELkkJSWFkc+PxFP50MDUigpaTaprDalvacG5s+f4+uuv9Y74RBYvXkzXrl25dfY21WhIFepybPcJnn7qaQ4fPqx3PKGz2Nj7+PtmP6XY2hoo6WlNbGzsI+8rLS0NpRRursZs29z/ry0lJfvtlMfh5ubG/v2HWLVqFc2eHsQzzw5lw4YNbNu2Q/oq5RO5NSNELlmzZg3du3cnmLY4aFlvWZxXR7EtrXHtxjWd0j0Zk8lE6cDSmCI1avDXKqhmZea4cScNWtRj67at+oYUunrnnXeYNfNrbhwNxNnpr4Lk4uV0qj0Vyq+//sqgQYMeaV9KKapVq0T5wEhWzymV5RbMGx/cY+4yM+Hht7OMZrFYLGzbto2TJ0/i7u5Ojx49cHd3z703KHJERs0IoYM/Jz+yI/u3KDscuRd1D4vFkt+xcsWJEyeIiIwgkApZTgpGzYiPuQzb/thGUlKSjgmF3kaPHk2GyYoez93mXMiDKxp7DqbQ6/m7lC7tT69evR55X5qm8d57k/htSyIvvnmX8yFpXAvN4L3JUUz9KZbXXnszSxESGhpKjeo1aNu2Le+Pn8gLL7yAr48vs2fPzou3KnKZFCJC5JK6desCcI+ss4IqpbhHOIlJifTr2w+z2ZyvuVJTU7l169YTXco2mUwAGMh+qfzPtvx+X6JgKV26NOvXb+T8FQdqtgjDNuAqLbrfQrMKZMuWbdjZZR8i+08GDBjA9OnTWbUJarQIo0LjG0z9OYXx4yfw3nvvZT7PYrHQqWMnQi/fpD4taG7uRDPVEY90X0aOHJmrw31F3pBbM0LkomdaPsOBPQepZK6DJz6kk8Y1zhPONYKoTCgh/PjTjzz//PN5niUpKYnx48cz++fZJCUnYWdnz9ChQ/j8889xcXHJ0b5SUlLwKeWLc7wHlbU6me1KKU4Y9hBUy59jx4/l9lsQhVB6ejqbN28mPDycypUr8/TTTz/RvD8pKSns3buXjIwMgoODcXV1zbL9jz/+oHXr1tTjadw0r8x2pRRHrP7g2S6tWLFyxWMfXzyenJy/pRARIhdFRUXxVPOnuHDxAhoGFBYMGKlITfy1cpzS9lOmnj+HDh/K0xxms5lWz7Ri/779+JnL4YoH8dznlvEq1WtV58CB/djY2ORon19++SVvvfUW/pTFhyAsmAnTLnNPRbB+/Xo6duyYR+9GiL/39ddf8/Zb7/C0pUu24byX1CkMgRlcD72uU7riS/qICKETT09PXhz1IgYMVKAGValPczrir5UDwNHizK1b4XmeY9OmTezavYvq5saU16rjqflQVqtKLXMwx48fY8WKnH9DfOONN5gyZQqJLvc5wnaOsQtbXwNLly6VIkToxsPDA7PFRDqp2balasl4ennqkErkhBQiQuSyypUrY8GCC+74akFYa39deYg3xlC1apU8z/Dbb79RwsoVd7LOCumieeBm9GTdunU53qemabz55ptE3o7g4MGDHDt2jBuhN+jTp09uxRYix7p164advT1XtLNZppKPUXeJIpJhzw3TL5x4JFZ6BxCiqGndujXlypYjJOwk1UwNcdScMSszoYQQY77HK6++kucZLBYLGoaHzjypKe2JRu/Y2dnRqFGjJ4lXbJjNZjZu3MjBgwcpUaIEffr0oUyZMnrHKlJcXFz48cdZDB0ylESrWFxNXqRqyURpkbRs0TJf+mOJJyNXRITIZUajkd/W/4aTlz0H2MJhqz/Yb9zENc4zadIkunTpkucZ2rRpQ5wphjgVk6U9UcVz3xJF27Zt8zxDcXfz5k1qVK9Bly5dmDplGu9PeJ9y5crxwQcfPPYicOLhBg0axP4D++nYqz22ZaFsgwCmT5/Oxk0bsbW11Tue+BfSWVWIPJKSksLy5cs5fvw4rq6uDBgwgIoVK+bLsTMyMmhQvyEh50IINFfK7KwaZhWCX5AvJ0+dlKXN85BSikYNG3H+5AWqmhrgonlgViZCucQ1zrN06VK5pSWKNBk1IwoVi8XyRMP7xMNFR0fz0ksvsXLlSsxmMwbNQKfOnZg5cyY+Pj65eqykpCQWL17M6dOn8fDwYNCgQZQrVy5Xj1GYHDlyhIYNG1KbpnhqWT/rk9peKjQsw/4D+3VKJ0Tek1EzosC7f/8+r7/+Om6u7hiNRqpVrcYvv/wil6xzkYeHB0uXLiUyMpKjR48SHhHO2rVrc70IOXHiBEGly/DCyBeYP3MBn348mQoVKvDFF1/k6nEKk/PnzwNk6ywM4Grx5Ny58/kdSYgCSzqrinyXkJBAs6bNuHLpKj7m0pSiDNEX7zBixAiuXLnCp59+qnfEIsXLywsvL69/f+JjSE9Pp1PHzphiLQTTDnuTI2Zl5jrnefvtt6lbty6tW7fOk2MXZCVLPihAkkjAGdcs25JIwLtk9gJFiOJKroiIfDdr1ixCQkKoa36KClpN/LWy1KAJZanG5599TmhoqN4RxSNav349EZHhVDbXxV57sMaOUTNSjuq4WLnx3Xff6ZxQH61bt6aUdymuGM5gVqbM9vvqHncNtxgxcoSO6Yq3P0cyffDBB0yZMoUbN27oHanYk0JE5LulS5biqXxw0rJOM/5gQTUDq1ev1imZyKmQkBDsrOyz/V9qmkYJkwcXL1zUKZm+rK2tWbhoIUk28Ryw2sJZdZgT2h6Os5tmzZoxduxYvSPmixs3brB69Wp27NiRuV6RniIiIqhXrzYdO3Zk1ozPmTRpPGXLlmXSpEl6RyvWpBAR+S45OQUrZZ2t3YgRo2Z8osXZRP7y8/MjzZRKqkrOti3ZGI+/v78OqQqGZ555hjNnTvPimBcIqO9N7ZbV+Xn2z/y+9fccLwBXUGRkZBAfH/+vfbkSEhLo06cXZcuWpUePHjzzzDOULVuaTZs2AQ9GFa1atYpWrVoQGOhD48YN+Pnnn5944cT4+HhmzpzJmDFjmDRpElevXs2yvW/fXkTfu8zutf6Enwrg9pnSvP+6Gx9++CFLly59omOLJ6AKsLi4OAWouLg4vaOIXDRmzBhlb+WgWtJNtdZ6ZT5qEawAtWfPHr0jikeUkJCgnBydVEnNV7Wku2qt9VKt6Kmq0kABavHixXpHFLkgMjJSDRs2TNna2CpABfgHqKlTpyqz2fzQ53fq1EGVcLZWM74oqSJOl1EHNwWoti0dlY2NtTp+/LgaP368AtRTjR3VhHHuquOzTkrTUP369fnbff6bQ4cOKU9PN2U0aqpmVUflUsJaaZqmpkyZopRS6tixYwpQq+f6KHNkhSyPVk85qeDgRo/9+YjscnL+lkJE5LtLly4pB3sH5WbwUvV4WjWno6pCPWVrtFNPNX9KWSwWvSOKHPjtt9+UjbWNsjPaq5L4KRejuwLUsGHDHvukIgqO6OhoVSaojLKzclBlqaaq01D5aKUVoMaOHZvt+adOnVKAWvBDqSwn+5TQ8qpsaTvVsWNHBahP3vXIsn3xrFIKUL/99luOM6akpKhSpbxUk/oO6sbRIGWOrKASr5VTb41xU4DasWOHmj9/vgJU4rVy2QqRz97zUCVKOObCpyX+lJPzt9yaEfmuQoUKbPl9C26lnTnGLvawgYvacdp2aMOatWseOi25KLg6derEufPnGDPuJao/U4n2vduwceNGfvnlF5kfpgiYPn06N8NuUc/0NGW1KpTSAqlGA8pTg2nTpnH9etaVbffu3YvRqNGrk1OWdhsbjR4d7dm/fxce7ja8Psoty/Y+XZypU8OBhQsX5jjj6tWruX37Hr9860WA34Pbvvb2BiZP8KByBVvGjRuLvb09ABevpGd7/cUrGZQsmTcjy8S/k+G7QhfNmjXj8pXLHDp0iKioKKpXry5rcBRi5cuX58svv9Q7hsgDK5avwMvikzkq6k8BlOO6doF169Zl6Xzr4OCA2ayIjTPj5Zn1FBN934zRYEUpL4WNTfYvHIF+Gvfvx2Rr/zeXLl2iVElbKpazydKuaRpPN7FjzuLTvPTSi3h7e/L2xzGsmVsKB4cHRfL+IyksXp3E++//J8fHFblDvq4I3RgMBpo0aULnzp2lCBGigEpPz8DwkO+sGgYMaGRkZGRp79SpE7a2Nnz23f0s7Veup7NsXTJNgptzLiSJK9ezXpmITzCzY1869erVz3FGPz8/7kalE3E7+8ic0+fTaN7YHt+SKdjZ2bP/qIlyjW8yfNxtOgyI4Kmut2jYsBGvvfZajo8rcocUIkIIIf5Wm7bPEm2MxKSyFhx3CSfDksEzzzyTpd3T05NPPvmUb3+MpW3fSKb/EsvbH0fRuEMEfn6l+eGHH/D1LUWvEXc5eCwFpRTnQ9LoOfwOZosVo0aNynHG3r174+jowCvjo0hJebCytFKKH3+N48DRVEYPc+XLSe6Eht5kzpx59O33IuevlidDq8/MmbPYunW7rL2kpzzvsfIEpLOqEELo6+rVq8rZyVm5GD1ULYJVE9qoCtRU1kYb1aF9h7993bJly1SjRvWV0WhQnp5u6tVXX1V3795VSil19uxZVaFCWQUoa2uDApS3t6fasWPHY+dcu3atsrGxVi4lDKpbe0dVrZKNAtSLQ1yUKaK8un+prIzkykc5OX/LondCCCH+0dGjRxkxfASnz5wGwMrKioEDBzJ9+nQcHR3/5dUPZ7FY2LZtG5cuXcLf358OHTpgY2Pz7y/8B1euXKFx44ZYG+Np1dyBwb2daf2UA5qmsXl7Eh0HRnD48GEaNGjwRMcR/05W3xVCCJGrlFKcO3eO6OhoqlSpkrmeTkEzffp0XnnlZWZ/683gXs4YDBqXr6XTZcgdnF0rceTIiScamaeUYtOmTfz6669ER9+jVq06jBo1qlivNv0wUogIIYQolsxmM8OGDWXBgoUE+Nrg6WHk5NkUAgP92bp1OxUqVHjsfVssFkaMGMHcuXOpWdWeckEGdh1IJylZY+XKVXTs2DEX30nhlpPztwzfFUIIUWRcunSJ/fv3AnAv2sStyHSsra344IOPnqgIAVi2bBlz587ll6neDOntjKZpJCdb6D/6DgMH9ufWrQicnJz+fUciCxk1I4QQokhIT0+nQ4e22Fvf5ejvASTdKMetk2Xo1cmekSOf58SJE0+0/9k//0iLYEeG9imReXvHwcHAtP96Eh+fwKpVq3LjbRQ7UogI8QSSk5O5fv06iYmJekcRothbt24dN27cZMEPXtSp8WBhwVIlrZgz1Rt/Xxu+++67J9p/eMRNalbNvmBn6QBrXF1sCA8Pf6L9F1dSiAjxGBITExkzZgyeHp6ULVsWD3cPnnvuOWJicj4rpBAid5w6dQrfUnbUrGqbpd3KSqNVcxvOnHmyKyIVK1Zhz6H0bKsPn7mQxv3YdCpVqvRE+y+upBARIofMZjMd2nfgp1k/45Nahjo0JzCjIot/XULLFs+Qmpqqd0QhiiVPT0+iYtK5H2vOtu3qdTOenk820mfMmFc4cSaZ9yZHZ06cduNmBiPGRREQ4Evnzp2faP/FlRQiQuTQpk2b2LN3D9XNjSirVcVD8yZIq0wtc1NOnznFsmXLdMt248YNvvjiCyZMmMDatWsxmbJPeS1EUdWvXz+UMjD+0ygslr+uWqzemMiuA0kMGTLsifb/7LPPMnnyZD7/Pha/2mHUbBFO+UY3uHXHgbVr12Ntnf22jfh3MmpGiBzasGEDJaxccTdl/XZVQnPDTfNk/fr1DBkyJN9z/fe//2XixIkYNStsjbYkZSRSsUJFft/6O6VLl873PELkN29vb77/fjovvvgiuw9m8EwzG0KumPhjTxK9evWgT58+T3yMd955h169erFgwQKio6MZ92Yt+vfv/9gTuwkpRITIsQf3h7WHToqkYcBiseR7ptWrV/P+++9ThsoEqcoYlRVxxHDh+hG6de3O8RPHnmgSJyEKixdeeIHq1aszbdpUdh8+RUnvUsyfP4IBAwZgNBpz5Rjly5dn0qRJubIvIYWIEDnWtm1bZs2aRSxRuGqeme2JKo776h7t2rXL90zffvMt7saSlLNUz2xz0dypYKrFiVN7OXDgAMHBwfmeSwg9BAcHy897ISJ9RITIoc6dO1O/Xn3OGA8Sqi4Rp6K5qa5wymofFSpUYMCAAfme6dzZc7iaPbO1u+MNwPnz5/M7khBCPBIpRITIISsrK7Zu20qfAb25YXWBI+zgiuEMHbq0Z9fuXbosJ17SuyTJWkK29iTiH2wvoOuCCCGEFCJCPAZXV1fmz5/Pnbt3OHXqFLfv3GbFyhWUKlVKlzwjnh/BXcKJUXcz28zKzBXDGTw9vHS5XSREYWGxWFizZg3du3eladPGjBo1ijNnzugdq9iQRe+EKALS0tLo2KEjf2z/Aw+DNzYWO2Kt7mExmFn32zratGmTLznMZjNbtmxh48aNALRv35527drlWidBIXKbxWLhueeGMX/+rzSs40DFckZ27Evn9t0MFixYSL9+/fSOWCjJ6rtCFEMZGRksWrSIBQsWEHs/libBTXj55ZepWLFivhw/ISGBDu07sHffXpytXR60ZcTRNLgpmzZvwtnZOV9y/Ck1NZXVq1dz9epVAgMD6dmzpwyxFNksW7aMvn37Mv97bwb2fHCeychQPDf2Dms2pxMeHombm5vOKQufAleI/PDDD0yZMoXIyEiqVavGt99+S/Pmzf/1dVKICFF4vPDCC8z7ZR7VzY1w40GflPvc46zxEEOeG8xPP/2Ub1n2799P1y5diYqOwt7KgRRTMi4lXFi+YjnPPvtsvuUQBV/79m1JvL+PXWt8s7TfuWcisG4o3303nVGjRumUrvDKyfk7z/uILF26lHHjxjFhwgROnDhB8+bNad++PWFhYXl9aCFEPklISGD+/F/xN1fAXfNG0x7Ms+KulSTAXJ5f5/9KQkL2zrR5ISYmhvbt2mO5r9GEtjQ1d6Ap7bFOdKBLl67cunUrX3KIwuH27QiqVsx+69DbywpPd2tu376tQ6riJc8Lka+//poRI0bw/PPPU6VKFb799lsCAgKYMWNGXh9aCJFPIiIiSEtLxY3sQ4hd8SQtPS3fViadP38+SUlJVLM0wlF7cDvIXnOkuqUh5gxzvl6ZEQVf1ao12Lk/I8uU8ADnQ9K4fTeNqlWr6pSs+MjTQiQ9PZ1jx45l6yjXpk0b9u/fn+35aWlpxMfHZ3kIIQo+b29vjEYj8dzPti2BWIxGI97e3vmS5dSpU7gY3LHV7LK0W2nWlLC4c/r06XzJIQqHMWNe5tLVFF6dcI+4+AeL5V26ms7QV6Pw9/ehW7du+gYsBvK0EImKisJsNmf7A+Tt7f3Qy12TJ0/GxcUl8xEQEJCX8YQQucTV1ZXevXtz0+oKiSousz1RxRFmvEyvXr3yrcOfl5cXKSRhUVmn2ldKkWZMxtMz+1UbUXwFBwczY8YMflqQiF/tUMo3ukWVZqHcjnJm/fpN2NjY6B2xyMuXeUT+d40LpdRD17149913iYuLy3zcvHkzP+IJIXLB1KlTCSoXyCG2cVzbzXFtN4fYRulyAUybNi3fcgwePJgUUzI3uMj/3xf/JldJNMUzdOjQfMsiCodRo0YRGhrGRx99Ru9+rzB//nyuXr1BrVq19I5WLOTpWjOenp4YjcZsVz/u3r370Mu0tra22Nra5mUkIUQeKVmyJMeOH2PRokVs2LABgA4dOjBw4MB8nW22Ro0afPDBB3z44YfEGO/gZHYlyRjHfXMUr7zyCk2bNs23LKLw8PX15c0339Q7RrGU58N3GzVqRL169fjhhx8y26pWrUrXrl2ZPHnyP75Whu8KIR7Xli1bmD59OpcvXSaoTBAvvvgiXbt2lVWIRZ4ym82sXLmSX3+dR3T0PWrVqsfLL79MtWrV9I6WrwrUPCJLly5l8ODBzJw5kyZNmvDjjz/y008/ce7cOUqXLv2Pr5VCRAghRGFhNpvp168PK1asolkjR8oEGvhjTzr3os0sWbKUHj166B0x3+Tk/J2nt2YA+vbtS3R0NB999BGRkZFUr16djRs3/msRIoQQQhQmv/76KytWrGLFbB+6d3ACID1dMWjMHYYNG8Kzzz6b7zMMFwYyxbsQQgiRC1q0aI4NJ9m8xCdL+62IDILq32DOnLnFprN0gZpZVQghhCgOHszSmv1Gg7+vNSWcrblz544OqQo+KUSEEEKIXFC1ag22703nf280HD2ZSlx8hszS+jeKXSGSmprKggULePXVV3nvvfc4e/as3pGEEEIUAa+8MpYzF5J5fWIU8QkPZmk9F5LG8HFRlCsXRPv27XVOWDAVqz4ily9fpnWr1oTdDMPF2o00lUqqKYU33niDKVOmyLA+IQRms5nffvuNZcuWkZSURNOmTRkxYgQeHh56RxOFwNSpU3njjdexsdEo6WlD6M0USpf2Z9Om36lSpYre8fJNgRq++yRysxBRSlGjeg3CLt2iuqkRjloJLMrCTS5zmTMsXLiQAQMG5FJyIURhlJ6eTteuXdm8eTOuRneMFmtitWhcXV3YsXMHNWrU0DuiKARu3brFkiVLiI6Opnbt2nTv3r3YTRUvhchD7Nmzh6eeeoq6PIW7VjLLtpPaXsrVL83BQwef6BhCFDT3799n48aNpKam8tRTT1GhQgW9IxVon3/+ORPGT6CGpTGe2oORD2kqldPG/fiUL8n5C+flyqkosFJTU1m/fj3h4eGUL1+etm3bYmWV57N0PFSBmkekoLh06RIAbnhl2+Zi8SAkJCS/IwmRp7766ismjJ9AWnpaZlvv3r2ZN28e9vb2OiYruGb+MBNvS0BmEQJgq9lRzlyN4yF7OHToEI0bN9YxoRAPt2PHDvr1683du9HY2xtJSTFTtmxpVq9eR82aNbM9/9y5c0yfPp3Tp0/g6enF4MFD6d69OwZD/ncdLTadVf38/IAHS5L/r0QtLnO7EEXB4sWLefPNNymZHkBzOtGS7lShHmtWrmHMmDF6xyuwwiPDccY1W7szD1YOloU4RUF08+ZNOnfuSI1KqZzbXZrEa2U5vDkAF8d7tG3bmsTExCzPX7lyJbVr12LNql8IKnWO2zf/oFevXgwePBCLxfI3R8k7xaYQad26Nb4+vlwxnMakMjLb76kI7hHBCy++oGM6IXLXZ5M/w8vgQyWtNraaHUbNiJ9WhjKWqsyfPz/bQpTigbJlyhKnRWdrjyUKgHLlyuV3JFHEmM1mpk2bRtWqFbG1taFChTJMmTKFjIyMf3/x35g1axZGg4kVs72pXOFBX5R6texY/nNJ7t6NYvHixZnPjY+PZ9iwIXRr78C1wwHM/74U+zf4sXhWKRYtWpLlufml2BQiVlZWLFu+jDS7ZPYbN3FK7eeoYSen2E+Hjh0YPXq03hGFyBUmk4nTZ07jafHJts0LX8xmMydOnNAhWcH38isvc0fdIkLdyJwLIknFc9XqLPXr1adOnTo6JxSFmVKKoUMH89pr46hV+Q5TJroSXDeG8ePfoVevHo99NeL48WM81cSGEs7GLO1lAq2pUcWB48ePZ7atWLGC5OQUvvnIExubv/o79eniTMumjsyZ8/PjvbknUGz6iAA0bdqUiyEXmTVrFgcOHMTV1YX+/fvTrVs3jEbjv+9AiELAaDRib+9AakpKtm1pPGhzcXHJ71iFwujRozly5Ajz588n1Ooi1tgQa4qhtG9pli5bKh1VxRPZu3cvCxcuZu40bwb3/qsDZ7f2jvR4bj2bNm2iY8eOOd6vm5s7Z05YUEpl+RlNT1eE387Azc0ts+327du4uVrjWyr76b9aZSu2HwjP8fGfVLG5IvInf39/Pv74Y7Zt28qKFSvo2bOnFCGiSNE0jf79+xFpDCVVJWe2W5SF64aLBAYE0qhRIx0TFlxGo5G5c+dy4MABRr78PL2f68ncuXO5cPECZcuW1TueKOSWLVtGUKAdg3plXfiuS1tHalRxYOnSpY+130GDBnHmQgqLViVkaf965n2iotMZOHBgZlvVqlWJjknn9Pm0LM9VSrFjbzpVq+b/EPVidUVEiOLi448/5vctv3Pk9na8zH5YYU20VSSpJLPwp9+k+P4HmqbRuHFjGR0jcl1SUhIeroZsV9Y0TcPL48H2x9GuXTsGDx7IkJcXsmBFEnVrWLPnUDr7Dicxfvx4qlWrlvncjh07EhQUwLBXo1g804tK5W2ITzDzwRcxnAtJYfqsV5/oPT6OYndFRIjiwNfXl6PHjvLKay9j8M8gySOaDj3bceDgAdq2bat3PCGKncuXLxMeHs6x08n0HRnJvsN/3ToNjzSx51AqTZs2fax9a5rG3LnzmTt3LsmmGiz5zQGHEo1YvXo1n3zySZbnWltb89tvG4mOc6Fq81AqNL6FX+0wps+JZ9q0aTz99NNP9D4fK39xmdBMCCHyk8ViITo6GkdHRxwcHPSOI3S0fPlyBgzoj0sJI8ENrDl1No2wcBO9OjkyYmAJ/vNRLPfuO3H+fEiW/hx5KTU1lZUrV3L69Gk8PT3p378//v7+ubZ/mVlVCCF0opRi6tSpfDnlS8IjwjEajfTo0YMvvviCoKAgveOJfHbv3j0CAwPo2s6G2V+XxN7egMWi+PKH+7z7STSaBtWqVWHJkuVZbqEUdjk5f8utGSGEyEX/+c9/eO2117BEWFGDxpQ1V2PD6k00aRxMZGSk3vFEPlu0aBEWSwbT/uuFvf2DU67BoPHWGDeqVLTGYNB45plni1QRklNSiAghRC65desWX3/1NeWoRjWtAd6aP6W1itQzPU1MVAxTp07VO6LIZ7du3aK0vx2eHlk7iGuaRt0advj7GPnll59JTk7+mz0UfVKICCFELtmwYQNKKQIon6XdVrPHy+zLyhWrdEom9FKuXDmuhaYQHmnK0m42K/YfSaFyBRsSE5OL9dUyKUSEECKXmEwmNE3D8JA/rQaMZGSk65BK6Kl///44Ojoy9JXb3I16UIwkJ1t4c1IU18NMVC5vjZWVEU9PT52T6kfmERFCiFzSqlUrLMpCJGH4USaz3aQyiLKKYEj7wTqmE3pwcXFhzZp1tGv3LIF1rlO9ii3XwzKIT7AwYZwbsxcl07Nnz2I927GMmhFCiFzUv39/li9bQWlLRbzwJYUkQo2XMNmmcuLkCSpUqKB3RKGDM2fO0KLF08TG3qdsaWt8vK04cDSNsmXLsGvXXkqVKqV3xFwlo2aEEEInc+fOZfRLowi3vcYhtnGaA5StEciOnTukCCnGatSowbVr1/nqq28oW+Fp7Es05euvv+Xo0RNFrgjJKbkiIoQQeSA2NpaLFy/i5uZGpUqVHvl1FouF+/fv4+zsjI2NTR4mFCLvyBURIYTQmaurK40bN37kIsRsNvPZZ5/h6+OLp6cnJZxL8Nxzz3H37t08TiqEvqQQEUKIAuCFF15g/PjxWN11oAaN8U8vz5IFS2ka3JS4uDi94wmRZ6QQEUIInZ07d45ffvmFSqo2VbR6eGv+lNGqUNf0FNevX+enn37SO6IQeUYKESGE0Nm6deuwMdrg+/8N+QVw0JzxsJRi1UqZCE0UXVKICCGEzjIyMtA0Axpatm0GjKSny0RoouiSQkQIIXTWqlUr0kyp3CPrNN/pKo0Y4x3atmurUzIh8p4UIkIIobPg4GBaPdOKi8ajhKpLJKo47qhbnDTuwamEI2PGjNE7ohB5RgoRIYTQmaZprF6zmn4D+3Hd6jwH2coZDlK5biV27d6Fr6+v3hGFyDMyoZkQT+Du3btMmzaNVStWkWEy0a59W1577TXKli2rdzRRSN27d49Lly5RsmRJmYlVFFo5OX9LISLEY7p58yZNGjfh3p17eJh9MWIg2uo2VnZGdu7aSd26dfWOKIQQusjJ+VtW3xXiMf3nP//h/t1YGppbY6c5AGAyZXAiZQ8jR77AsWNHdU4ohBAFn/QREeIxpKSksGLFCvxMZTOLEAArzZrS5kocP36MS5cu6ZhQCCEKB7kiIsRjSExMxGQyYY9Ttm32OAIQExOT37GEEDoIDw9n1qxZHD58CBcXV/r370/nzp0xGo16RysU5IqIEI/Bw8MDXx9fov5n3geAKCKxtbHN0YqrQojCaf/+/VStWplvvp6MDfu4enE93bt3p3fvnphMJr3jFQpSiAjxGAwGA2+8+QaRhHJDhWBWJizKQoS6QajhEs8Nfw43Nze9Ywoh8pDJZKJfv97UrKIIPRbImrm+HN7ix6o5Pqxdu46ZM2fqHbFQkFEzQjwmi8XCa6+9xnfffYeGAU3TMFtM9OjRg4ULF2JnZ6d3RCFEHtq0aRMdOnTgyJYA6tbM+vveZ+Rtrt4qzYkTZ3RKpy8ZNSNEPjAYDEydOpXXXnuNDRs2kJGRQevWralevbre0YQQ+SA8PByAWtVss22rXc2GXQdv5XekQkkKESGeUFBQkEzBLUQxVLFiRQD2HEqhRbBDlm27D6ZRsWI1PWIVOtJHRAghhHgMzZs3p3r1Kox5J4aQKw9WSM7IUHw98z5bdyUyZsyrOicsHOSKiBBCCPEYNE1j5co1tGnTiqrNQ6lWyYE7USaiotN5/fXX6d+/v94RCwUpRIQQQojHVLFiRS5cuMTy5cs5dOgQLi4u9O/fnxo1augdrdCQUTNCCCGEyFUyakYIIYQQfys0NJSffvqJCxcu4OPjw3PPPUe9evV0ySKdVYUQQohiZO3atVSsWIHvv/uChOgtrFszm/r16/PRRx/pkkcKESGEEKKYiI6OZsCAfnRsbcfNE4FsXuLL1UP+THrLnQ8++IBdu3bleyYpRIQQQohiYtGiRWRkpDPjc08cHR6UAEajxnuvuVOpvD0//fRjvmeSQkQIIYQoJkJDQwkKsMPLM2sXUU3TqF/LitDQ6/meSQoRIYQQopgoW7Ys18NSuX0368rAFovi4LEMypYtn++ZpBARQgghiokBAwZgb2/P86/f436sGYC0NAvjP43m6o1URo0ane+ZZPiuEEIIUUy4urqyfPlKevToRkDdUOpUt+PStQyiotOZMmUKTZo0yfdMUogIIYQQxUjbtm25evU6c+bM4eLFizRrWYphw4ZRpUoVXfLIzKpCCCGEyFU5OX9LHxEhhBBC6EYKESGEEELoRgoRIYQQQugmTwuRTz75hODgYBwcHHB1dc3LQwkhhBCiEMrTQiQ9PZ3evXszenT+j0sWQgghRMGXp8N3P/zwQwDmzp2bl4cRQgghRCElfUSEEEIIoZsCNaFZWloaaWlpmf+Oj4/XMY0QQggh8lqOr4hMmjQJTdP+8XH06NHHCjN58mRcXFwyHwEBAY+1HyGEEEIUDjmeWTUqKoqoqKh/fE5QUBB2dnaZ/547dy7jxo0jNjb2H1/3sCsiAQEBMrOqEEIIUYjkZGbVHN+a8fT0xNPT87HD/RNbW1tsbW0z//1njSS3aIQQQojC48/z9qNc68jTPiJhYWHExMQQFhaG2Wzm5MmTAJQvXx4nJ6d/fX1CQgKA3KIRQgghCqGEhARcXFz+8Tl5uujdsGHDmDdvXrb2HTt20KJFi399vcViISIiAmdnZxISEggICODmzZtym+Yf/Hk7Sz6nfyaf06ORz+nRyOf06OSzejSF/XNSSpGQkICvry8Gwz93Ry3Qq+/+/2Ql3kcjn9Ojkc/p0cjn9Gjkc3p08lk9muL0Ock8IkIIIYTQjRQiQgghhNBNoSlEbG1t+eCDD7KMqhHZyef0aORzejTyOT0a+ZwenXxWj6Y4fU6Fpo+IEEIIIYqeQnNFRAghhBBFjxQiQgghhNCNFCJCCCGE0I0UIkIIIYTQTaEuRNLS0qhduzaapmVOHy/+0qVLFwIDA7Gzs8PHx4fBgwcTERGhd6wC5caNG4wYMYIyZcpgb29PuXLl+OCDD0hPT9c7WoHzySefEBwcjIODA66urnrHKVB++OEHypQpg52dHfXq1WPPnj16Rypwdu/eTefOnfH19UXTNNasWaN3pAJn8uTJNGjQAGdnZ0qWLEm3bt0ICQnRO1aeK9SFyH/+8x98fX31jlFgtWzZkmXLlhESEsLKlSu5evUqvXr10jtWgXLx4kUsFguzZs3i3LlzfPPNN8ycOZPx48frHa3ASU9Pp3fv3owePVrvKAXK0qVLGTduHBMmTODEiRM0b96c9u3bExYWpne0AiUpKYlatWrx/fff6x2lwNq1axdjxozh4MGDbN26FZPJRJs2bUhKStI7Wt5ShdTGjRtV5cqV1blz5xSgTpw4oXekAm/t2rVK0zSVnp6ud5QC7YsvvlBlypTRO0aBNWfOHOXi4qJ3jAKjYcOGatSoUVnaKleurN555x2dEhV8gFq9erXeMQq8u3fvKkDt2rVL7yh5qlBeEblz5w4jR47k119/xcHBQe84hUJMTAwLFy4kODgYa2trveMUaHFxcbi7u+sdQxQC6enpHDt2jDZt2mRpb9OmDfv379cplSgq4uLiAIr836NCV4gopRg2bBijRo2ifv36escp8N5++20cHR3x8PAgLCyMtWvX6h2pQLt69Srfffcdo0aN0juKKASioqIwm814e3tnaff29ub27ds6pRJFgVKK119/nWbNmlG9enW94+SpAlOITJo0CU3T/vFx9OhRvvvuO+Lj43n33Xf1jqyLR/2c/vTWW29x4sQJfv/9d4xGI0OGDEEVg8l0c/o5AURERNCuXTt69+7N888/r1Py/PU4n5PITtO0LP9WSmVrEyInXn75ZU6fPs3ixYv1jpLnCswU71FRUURFRf3jc4KCgujXrx+//fZbll9ys9mM0Whk4MCBzJs3L6+j6upRPyc7O7ts7bdu3SIgIID9+/fTpEmTvIpYIOT0c4qIiKBly5Y0atSIuXPnYjAUmBo9Tz3Oz9PcuXMZN24csbGxeZyu4EtPT8fBwYHly5fTvXv3zPaxY8dy8uRJdu3apWO6gkvTNFavXk23bt30jlIgvfLKK6xZs4bdu3dTpkwZvePkOSu9A/zJ09MTT0/Pf33etGnT+O9//5v574iICNq2bcvSpUtp1KhRXkYsEB71c3qYP2vOtLS03IxUIOXkcwoPD6dly5bUq1ePOXPmFJsiBJ7s50mAjY0N9erVY+vWrVkKka1bt9K1a1cdk4nCSCnFK6+8wurVq9m5c2exKEKgABUijyowMDDLv52cnAAoV64c/v7+ekQqkA4fPszhw4dp1qwZbm5uXLt2jYkTJ1KuXLkifzUkJyIiImjRogWBgYF8+eWX3Lt3L3NbqVKldExW8ISFhRETE0NYWBhmszlz7p7y5ctn/h4WR6+//jqDBw+mfv36NGnShB9//JGwsDDpZ/Q/EhMTuXLlSua/r1+/zsmTJ3F3d8/2d724GjNmDIsWLWLt2rU4Oztn9jNycXHB3t5e53R5SL8BO7nj+vXrMnz3IU6fPq1atmyp3N3dla2trQoKClKjRo1St27d0jtagTJnzhwFPPQhsho6dOhDP6cdO3boHU1306dPV6VLl1Y2Njaqbt26RX645ePYsWPHQ39+hg4dqne0AuPv/hbNmTNH72h5qsD0ERFCCCFE8VN8boYLIYQQosCRQkQIIYQQupFCRAghhBC6kUJECCGEELqRQkQIIYQQupFCRAghhBC6kUJECCGEELqRQkQIIYQQupFCRAghhBC6kUJECCGEELqRQkQIIYQQupFCRAghhBC6+X84UouauNzBAQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 100x2 * 2x4\n",
    "from sklearn.datasets import make_classification\n",
    "X1, Y1 = make_classification(\n",
    "    n_features=2, n_redundant=0, n_informative=2, n_clusters_per_class=1, random_state = 15\n",
    ")\n",
    "plt.scatter(X1[:, 0], X1[:, 1], marker=\"o\", c=Y1, s=25, edgecolor=\"k\")\n",
    "print(len(X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.fc1 = Linear(input_size, hidden_size, activation='relu')\n",
    "        self.fc2 = Linear(hidden_size, hidden_size, activation='relu')\n",
    "        self.fc3 = Linear(hidden_size, hidden_size, activation='relu')\n",
    "        self.fc4 = Linear(hidden_size, output_size, activation='sigmoid')\n",
    "        self.layers = [self.fc1, self.fc2, self.fc3, self.fc4]\n",
    "    def __call__(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x[0] if len(x) == 1 else x\n",
    "    def parameters(self):\n",
    "        p = []\n",
    "        for l in self.layers:\n",
    "            p.extend(l.parameters())\n",
    "        return p\n",
    "network = SimpleNN(2, 3, 1)\n",
    "\n",
    "# n = MLP(3, [4,4,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "    [2.0,3.0,-1.0],\n",
    "    [3.0,-1.0,0.5],\n",
    "    [0.5,1.0,1.0],\n",
    "    [1.0,1.0,-1.0]\n",
    "]\n",
    "ys = [1.0, 0.0, 0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.46477390502062976\n",
      "1 0.45939429841540735\n",
      "2 0.4531672737367294\n",
      "3 0.4481020328600036\n",
      "4 0.4426094269270683\n",
      "5 0.4378016713356342\n",
      "6 0.4329017120317162\n",
      "7 0.42844320672114233\n",
      "8 0.42387027714763603\n",
      "9 0.4196919173273592\n",
      "10 0.41531011858835865\n",
      "11 0.41133504814451816\n",
      "12 0.4071249261190557\n",
      "13 0.4031140452058288\n",
      "14 0.39911983619625124\n",
      "15 0.39504541994173364\n",
      "16 0.3910770524820401\n",
      "17 0.38706351192762556\n",
      "18 0.38297873729032655\n",
      "19 0.3788967740300912\n",
      "20 0.3748144573294907\n",
      "21 0.3706156753917179\n",
      "22 0.3663781261717759\n",
      "23 0.36207777319303547\n",
      "24 0.35770490057975324\n",
      "25 0.3532514402907405\n",
      "26 0.348709907964307\n",
      "27 0.34407328210460325\n",
      "28 0.33933497627423903\n",
      "29 0.334488833525474\n",
      "30 0.32952913519883126\n",
      "31 0.3244506223054555\n",
      "32 0.3192485287214253\n",
      "33 0.3139186257298277\n",
      "34 0.30845727754964575\n",
      "35 0.30286150747896934\n",
      "36 0.297129074171785\n",
      "37 0.2912585573628289\n",
      "38 0.285249452049558\n",
      "39 0.2791022697304595\n",
      "40 0.2730721561576309\n",
      "41 0.2670746885904515\n",
      "42 0.26099068367258127\n",
      "43 0.2548116162932179\n",
      "44 0.2485458156196513\n",
      "45 0.2422027032934696\n",
      "46 0.23579271290211196\n",
      "47 0.22932720938994688\n",
      "48 0.22281839070069676\n",
      "49 0.2162791759259305\n",
      "50 0.209723084316914\n",
      "51 0.2031641087907536\n",
      "52 0.19661658618963918\n",
      "53 0.1904303999769477\n",
      "54 0.1846905690139306\n",
      "55 0.17824222704308995\n",
      "56 0.17188393402106844\n",
      "57 0.16560813266934604\n",
      "58 0.1594255299969315\n",
      "59 0.15334864832726244\n",
      "60 0.14738974758130924\n",
      "61 0.14156033757908018\n",
      "62 0.1358709103855928\n",
      "63 0.13033078625161182\n",
      "64 0.12494801182019437\n",
      "65 0.11972930854819255\n",
      "66 0.11468005617051982\n",
      "67 0.10980430716223732\n",
      "68 0.10510482592865027\n",
      "69 0.10067761813863224\n",
      "70 0.09721737022330018\n",
      "71 0.09293717312904978\n",
      "72 0.08888750430904704\n",
      "73 0.08502906201901483\n",
      "74 0.08134693489114059\n",
      "75 0.077833653519487\n",
      "76 0.07586725754397361\n",
      "77 0.08515755025462682\n",
      "78 0.0789741547494738\n",
      "79 0.07954692305713319\n",
      "80 0.07368333591069925\n",
      "81 0.0739728464229349\n",
      "82 0.06927408592924389\n",
      "83 0.06814578544522616\n",
      "84 0.06531903850174628\n",
      "85 0.06456290378278406\n",
      "86 0.06253143821453065\n",
      "87 0.059549985429130654\n",
      "88 0.0586674582603388\n",
      "89 0.05570996194888239\n",
      "90 0.05558137294408974\n",
      "91 0.05208111757301677\n",
      "92 0.052772838330214025\n",
      "93 0.04874068040457166\n",
      "94 0.05020513732560107\n",
      "95 0.04567407852782309\n",
      "96 0.047844139902626474\n",
      "97 0.04286333346396026\n",
      "98 0.04566576985105277\n",
      "99 0.04028772496333936\n",
      "100 0.043650515928949245\n",
      "101 0.03792640399755728\n",
      "102 0.04178178693469273\n",
      "103 0.035869044766480895\n",
      "104 0.03931843087340209\n",
      "105 0.039115729408025664\n",
      "106 0.03367839822049423\n",
      "107 0.036811012205210145\n",
      "108 0.036644103404647264\n",
      "109 0.03186214180932055\n",
      "110 0.03451044880109827\n",
      "111 0.034390192738777026\n",
      "112 0.030094482184852462\n",
      "113 0.032279964027152865\n",
      "114 0.032261230610388096\n",
      "115 0.02844468718839766\n",
      "116 0.030294573750893998\n",
      "117 0.03034334590604725\n",
      "118 0.026943314875203593\n",
      "119 0.02844897883299556\n",
      "120 0.028600510655724\n",
      "121 0.02556313820457338\n",
      "122 0.026750884002330857\n",
      "123 0.027009438381732073\n",
      "124 0.02428772999979053\n",
      "125 0.02519423882054831\n",
      "126 0.025551928751961155\n",
      "127 0.02310528595349367\n",
      "128 0.023768568124211988\n",
      "129 0.024212939113188985\n",
      "130 0.022006481526275642\n",
      "131 0.02246225081152827\n",
      "132 0.022979702018063503\n",
      "133 0.020983528931079538\n",
      "134 0.02128383485641894\n",
      "135 0.02185379806155943\n",
      "136 0.020058410892486944\n",
      "137 0.020177696719787763\n",
      "138 0.020818077813734105\n",
      "139 0.019166230410033114\n",
      "140 0.019163942477150232\n",
      "141 0.019836716640572027\n",
      "142 0.01832644075010883\n",
      "143 0.018238461768592146\n",
      "144 0.018924801908278208\n",
      "145 0.017541588174108134\n",
      "146 0.017380926998217375\n",
      "147 0.018103112079402416\n",
      "148 0.016836516039018992\n",
      "149 0.016614666460193106\n",
      "150 0.01732281056132557\n",
      "151 0.016154085820948058\n",
      "152 0.015859437021516893\n",
      "153 0.01658283791802844\n",
      "154 0.015500718225301196\n",
      "155 0.015179831109756165\n",
      "156 0.015888438924795353\n",
      "157 0.014887069869713917\n",
      "158 0.014546058512857852\n",
      "159 0.015239118624350881\n",
      "160 0.014311040901278875\n",
      "161 0.013952339843425844\n",
      "162 0.014631212396420819\n",
      "163 0.013769500842401004\n",
      "164 0.013395673842679092\n",
      "165 0.01406112677302711\n",
      "166 0.013259582881394883\n",
      "167 0.01287342052646472\n",
      "168 0.013525656644814397\n",
      "169 0.012787133842660958\n",
      "170 0.012404074735661052\n",
      "171 0.013037321393336396\n",
      "172 0.012342181139225703\n",
      "173 0.011928686135035558\n",
      "174 0.01256374276498437\n",
      "175 0.011911092263743362\n",
      "176 0.011496779485844886\n",
      "177 0.012114031105280818\n",
      "178 0.011502081178180476\n",
      "179 0.011091984791159665\n",
      "180 0.01168912688179334\n",
      "181 0.011114881368176083\n",
      "182 0.010709929519811777\n",
      "183 0.011287667794017497\n",
      "184 0.01074813675283891\n",
      "185 0.010358895313316146\n",
      "186 0.010835006618968062\n",
      "187 0.010642307838332326\n",
      "188 0.010185861398584285\n",
      "189 0.010118364713165564\n",
      "190 0.010374137881950164\n",
      "191 0.00991296495432317\n",
      "192 0.009697220274424465\n",
      "193 0.010064624039669607\n",
      "194 0.009620836592667218\n",
      "195 0.00936358199384219\n",
      "196 0.009755004942172733\n",
      "197 0.009333444901468394\n",
      "198 0.009064686320701013\n",
      "199 0.009465655163952416\n",
      "200 0.009066032201703269\n",
      "201 0.008796326467949353\n",
      "202 0.009181005170675806\n",
      "203 0.008803762311926488\n",
      "204 0.008528111172829114\n",
      "205 0.008909084847138815\n",
      "206 0.008550438943537393\n",
      "207 0.008278843519700678\n",
      "208 0.008648493643111993\n",
      "209 0.008307834965980778\n",
      "210 0.008046895509984714\n",
      "211 0.008360394088939495\n",
      "212 0.008206863809432977\n",
      "213 0.007914670366547468\n",
      "214 0.007914415532084659\n",
      "215 0.008029121565736194\n",
      "216 0.007734173878553041\n",
      "217 0.007627498036191373\n",
      "218 0.007827447013236967\n",
      "219 0.007545565625227759\n",
      "220 0.007404891039953349\n",
      "221 0.007628889593818298\n",
      "222 0.007354429151601092\n",
      "223 0.007194645335954057\n",
      "224 0.0074298395306746905\n",
      "225 0.0071666583258182745\n",
      "226 0.007002825184312774\n",
      "227 0.007236605366957163\n",
      "228 0.006984912633643873\n",
      "229 0.006822531227741162\n",
      "230 0.007050540887238793\n",
      "231 0.00680995938400831\n",
      "232 0.006651046890763368\n",
      "233 0.006871852267563093\n",
      "234 0.006641828371310835\n",
      "235 0.006487129409134167\n",
      "236 0.00670371513138372\n",
      "237 0.00648569371636282\n",
      "238 0.0063355828576823125\n",
      "239 0.006541552690703673\n",
      "240 0.006331404919392152\n",
      "241 0.006182573440950721\n",
      "242 0.006383731998136479\n",
      "243 0.006181955378784418\n",
      "244 0.0060377695766788714\n",
      "245 0.0062314590574507065\n",
      "246 0.006037823812688617\n",
      "247 0.005899355042905531\n",
      "248 0.0060848666460402425\n",
      "249 0.005899018242384574\n",
      "250 0.0057664655004490825\n",
      "251 0.005943821615460181\n",
      "252 0.005765373250315748\n",
      "253 0.005638616448905171\n",
      "254 0.00580809800911515\n",
      "255 0.00563774794995685\n",
      "256 0.005520100315395421\n",
      "257 0.005681403030301066\n",
      "258 0.005517100105100089\n",
      "259 0.005399250361972309\n",
      "260 0.005555967430881657\n",
      "261 0.005397593670149181\n",
      "262 0.0052843582994546974\n",
      "263 0.005434573380736534\n",
      "264 0.005281999802658227\n",
      "265 0.005174165142731117\n",
      "266 0.00531733544491101\n",
      "267 0.005170345704353211\n",
      "268 0.005068036423420569\n",
      "269 0.005204184088387823\n",
      "270 0.005062533267645844\n",
      "271 0.0049656100088533855\n",
      "272 0.005097091082966541\n",
      "273 0.004961904927996907\n",
      "274 0.004870199750777616\n",
      "275 0.004993245623619275\n",
      "276 0.0048618451464838165\n",
      "277 0.004773145248480712\n",
      "278 0.004891631260416152\n",
      "279 0.004764601915084698\n",
      "280 0.004680310475558554\n",
      "281 0.004793106505342786\n",
      "282 0.004670351945585352\n",
      "283 0.004590919484812819\n",
      "284 0.0046977262739466424\n",
      "285 0.004579099548381108\n",
      "286 0.004504553282255248\n",
      "287 0.004605437205199391\n",
      "288 0.004490773111382658\n",
      "289 0.004420960821021526\n",
      "290 0.004516712982033159\n",
      "291 0.00440822470940273\n",
      "292 0.004342731576975267\n",
      "293 0.0044328000132072935\n",
      "294 0.004325792090192038\n",
      "295 0.004263227308365997\n",
      "296 0.004349283011326732\n",
      "297 0.004245571681773487\n",
      "298 0.00418684320919658\n",
      "299 0.004268151909232981\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-1\n",
    "for k in range(300):\n",
    "    ypred = [network(x) for x in xs]\n",
    "    loss = sum((yout - ygt) ** 2 for ygt, yout in zip(ys, ypred))\n",
    "    for p in network.parameters():\n",
    "        p.grad = 0.0\n",
    "    # Backprop\n",
    "    loss.backward()\n",
    "\n",
    "    for p in network.parameters():\n",
    "        p.data = p.data-lr*p.grad\n",
    "    \n",
    "    print(k, loss.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=0.9999999999323461 label = ),\n",
       " Value(data=0.007681267956200524 label = ),\n",
       " Value(data=0.056075510273722096 label = ),\n",
       " Value(data=0.9689484016393609 label = )]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = [network(x) for x in xs]\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss =  0.6631603066552487\n",
      "Training loss =  0.7265617571875226\n",
      "Training loss =  0.7238980753006568\n",
      "Training loss =  0.7212476824499631\n",
      "Training loss =  0.6683161606295991\n",
      "Training loss =  0.6659432575684909\n",
      "Training loss =  0.7236129532705645\n",
      "Training loss =  0.6660832571522886\n",
      "Training loss =  0.7234650550539061\n",
      "Training loss =  0.6662225787440696\n",
      "Training loss =  0.7233179152458618\n",
      "Training loss =  0.7206704170733832\n",
      "Training loss =  0.7180361296292956\n",
      "Training loss =  0.7154149887821263\n",
      "Training loss =  0.7128069305265742\n",
      "Training loss =  0.676368795251337\n",
      "Training loss =  0.673955698399478\n",
      "Training loss =  0.715216259658861\n",
      "Training loss =  0.6740567180912297\n",
      "Training loss =  0.6716551631254176\n",
      "Training loss =  0.7176130784151284\n",
      "Training loss =  0.7149940489897841\n",
      "Training loss =  0.7123880918592953\n",
      "Training loss =  0.7097951431690455\n",
      "Training loss =  0.6792743869824319\n",
      "Training loss =  0.7097176889676265\n",
      "Training loss =  0.7071380716860834\n",
      "Training loss =  0.681852065988744\n",
      "Training loss =  0.6794115930936171\n",
      "Training loss =  0.7095766253231368\n",
      "Training loss =  0.7069977123036223\n",
      "Training loss =  0.7044316750515119\n",
      "Training loss =  0.6844914866590329\n",
      "Training loss =  0.6820378346646202\n",
      "Training loss =  0.7068840749603561\n",
      "Training loss =  0.704318605087597\n",
      "Training loss =  0.6846020651566395\n",
      "Training loss =  0.7042688319561388\n",
      "Training loss =  0.6846507493704047\n",
      "Training loss =  0.6821963021260442\n",
      "Training loss =  0.679754110441997\n",
      "Training loss =  0.6773241124231422\n",
      "Training loss =  0.6749062463444442\n",
      "Training loss =  0.7142292010381226\n",
      "Training loss =  0.7116270617458913\n",
      "Training loss =  0.6775050194426245\n",
      "Training loss =  0.7115403172725371\n",
      "Training loss =  0.708951600782868\n",
      "Training loss =  0.7063758082426742\n",
      "Training loss =  0.6825940426196226\n",
      "Training loss =  0.6801498649793577\n",
      "Training loss =  0.6777178910438788\n",
      "Training loss =  0.7113206920427494\n",
      "Training loss =  0.6778004858340839\n",
      "Training loss =  0.6753802415001695\n",
      "Training loss =  0.6729720796311283\n",
      "Training loss =  0.6705759388147666\n",
      "Training loss =  0.6681917578156193\n",
      "Training loss =  0.7212427213177902\n",
      "Training loss =  0.7186055779791771\n",
      "Training loss =  0.715981595117265\n",
      "Training loss =  0.7133707086991407\n",
      "Training loss =  0.6758267974957417\n",
      "Training loss =  0.7132751074575971\n",
      "Training loss =  0.6759186632998833\n",
      "Training loss =  0.7131799921732751\n",
      "Training loss =  0.676010079182593\n",
      "Training loss =  0.7130853603351569\n",
      "Training loss =  0.6761010473019513\n",
      "Training loss =  0.7129912094455907\n",
      "Training loss =  0.7103952499926858\n",
      "Training loss =  0.6786940707011291\n",
      "Training loss =  0.7103147541353881\n",
      "Training loss =  0.707732156032901\n",
      "Training loss =  0.7051624518209795\n",
      "Training loss =  0.6837774067926502\n",
      "Training loss =  0.705108422594881\n",
      "Training loss =  0.6838301663318358\n",
      "Training loss =  0.6813798164966712\n",
      "Training loss =  0.6789417015444339\n",
      "Training loss =  0.6765157596364996\n",
      "Training loss =  0.6741019291051434\n",
      "Training loss =  0.6717001484559411\n",
      "Training loss =  0.7175661025340723\n",
      "Training loss =  0.6718121773615787\n",
      "Training loss =  0.6694218261079352\n",
      "Training loss =  0.6670434051315016\n",
      "Training loss =  0.7224518800448881\n",
      "Training loss =  0.6671780739062353\n",
      "Training loss =  0.7223099331950054\n",
      "Training loss =  0.6673120896667956\n",
      "Training loss =  0.6649441972268227\n",
      "Training loss =  0.6625881201810084\n",
      "Training loss =  0.7271701380414726\n",
      "Training loss =  0.7245034212621727\n",
      "Training loss =  0.7218500081723448\n",
      "Training loss =  0.6677465704870332\n",
      "Training loss =  0.6653765098881671\n",
      "Training loss =  0.7242121106486215\n",
      "Training loss =  0.6655192529858773\n",
      "Training loss =  0.6631603066552483\n",
      "Training loss =  0.7265617571875234\n",
      "Training loss =  0.7238980753006573\n",
      "Training loss =  0.721247682449964\n",
      "Training loss =  0.6683161606295988\n",
      "Training loss =  0.6659432575684905\n",
      "Training loss =  0.7236129532705652\n",
      "Training loss =  0.6660832571522882\n",
      "Training loss =  0.7234650550539067\n",
      "Training loss =  0.666222578744069\n",
      "Training loss =  0.7233179152458624\n",
      "Training loss =  0.7206704170733838\n",
      "Training loss =  0.7180361296292965\n",
      "Training loss =  0.7154149887821268\n",
      "Training loss =  0.7128069305265746\n",
      "Training loss =  0.6763687952513361\n",
      "Training loss =  0.6739556983994776\n",
      "Training loss =  0.7152162596588615\n",
      "Training loss =  0.6740567180912292\n",
      "Training loss =  0.6716551631254172\n",
      "Training loss =  0.7176130784151288\n",
      "Training loss =  0.7149940489897846\n",
      "Training loss =  0.712388091859296\n",
      "Training loss =  0.7097951431690459\n",
      "Training loss =  0.6792743869824313\n",
      "Training loss =  0.7097176889676272\n",
      "Training loss =  0.7071380716860841\n",
      "Training loss =  0.6818520659887432\n",
      "Training loss =  0.6794115930936162\n",
      "Training loss =  0.7095766253231374\n",
      "Training loss =  0.7069977123036227\n",
      "Training loss =  0.7044316750515124\n",
      "Training loss =  0.6844914866590325\n",
      "Training loss =  0.6820378346646198\n",
      "Training loss =  0.7068840749603565\n",
      "Training loss =  0.7043186050875975\n",
      "Training loss =  0.684602065156639\n",
      "Training loss =  0.7042688319561395\n",
      "Training loss =  0.684650749370404\n",
      "Training loss =  0.6821963021260435\n",
      "Training loss =  0.6797541104419963\n",
      "Training loss =  0.6773241124231413\n",
      "Training loss =  0.6749062463444435\n",
      "Training loss =  0.714229201038123\n",
      "Training loss =  0.7116270617458916\n",
      "Training loss =  0.6775050194426241\n",
      "Training loss =  0.7115403172725377\n",
      "Training loss =  0.7089516007828686\n",
      "Training loss =  0.7063758082426749\n",
      "Training loss =  0.6825940426196222\n",
      "Training loss =  0.6801498649793573\n",
      "Training loss =  0.6777178910438784\n",
      "Training loss =  0.7113206920427498\n",
      "Training loss =  0.6778004858340833\n",
      "Training loss =  0.6753802415001686\n",
      "Training loss =  0.6729720796311278\n",
      "Training loss =  0.6705759388147662\n",
      "Training loss =  0.6681917578156189\n",
      "Training loss =  0.7212427213177909\n",
      "Training loss =  0.7186055779791775\n",
      "Training loss =  0.7159815951172657\n",
      "Training loss =  0.7133707086991411\n",
      "Training loss =  0.6758267974957415\n",
      "Training loss =  0.7132751074575977\n",
      "Training loss =  0.6759186632998828\n",
      "Training loss =  0.7131799921732754\n",
      "Training loss =  0.6760100791825926\n",
      "Training loss =  0.7130853603351573\n",
      "Training loss =  0.6761010473019509\n",
      "Training loss =  0.7129912094455914\n",
      "Training loss =  0.7103952499926862\n",
      "Training loss =  0.6786940707011284\n",
      "Training loss =  0.7103147541353887\n",
      "Training loss =  0.7077321560329014\n",
      "Training loss =  0.7051624518209801\n",
      "Training loss =  0.6837774067926498\n",
      "Training loss =  0.7051084225948815\n",
      "Training loss =  0.6838301663318354\n",
      "Training loss =  0.6813798164966708\n",
      "Training loss =  0.6789417015444335\n",
      "Training loss =  0.6765157596364991\n",
      "Training loss =  0.674101929105143\n",
      "Training loss =  0.6717001484559406\n",
      "Training loss =  0.717566102534073\n",
      "Training loss =  0.6718121773615783\n",
      "Training loss =  0.6694218261079348\n",
      "Training loss =  0.6670434051315008\n",
      "Training loss =  0.7224518800448886\n",
      "Training loss =  0.667178073906235\n",
      "Training loss =  0.7223099331950058\n",
      "Training loss =  0.6673120896667949\n",
      "Training loss =  0.6649441972268223\n",
      "Training loss =  0.662588120181008\n",
      "Training loss =  0.727170138041473\n",
      "Training loss =  0.724503421262173\n",
      "Training loss =  0.7218500081723451\n",
      "Training loss =  0.6677465704870328\n",
      "Training loss =  0.6653765098881667\n",
      "Training loss =  0.7242121106486219\n",
      "Training loss =  0.6655192529858769\n",
      "Training loss =  0.6631603066552478\n",
      "Training loss =  0.7265617571875238\n",
      "Training loss =  0.7238980753006578\n",
      "Training loss =  0.7212476824499643\n",
      "Training loss =  0.6683161606295983\n",
      "Training loss =  0.66594325756849\n",
      "Training loss =  0.7236129532705656\n",
      "Training loss =  0.6660832571522878\n",
      "Training loss =  0.7234650550539073\n",
      "Training loss =  0.6662225787440685\n",
      "Training loss =  0.7233179152458631\n",
      "Training loss =  0.7206704170733842\n",
      "Training loss =  0.7180361296292971\n",
      "Training loss =  0.7154149887821273\n",
      "Training loss =  0.7128069305265751\n",
      "Training loss =  0.6763687952513358\n",
      "Training loss =  0.6739556983994771\n",
      "Training loss =  0.7152162596588623\n",
      "Training loss =  0.6740567180912288\n",
      "Training loss =  0.6716551631254168\n",
      "Training loss =  0.7176130784151294\n",
      "Training loss =  0.714994048989785\n",
      "Training loss =  0.7123880918592964\n",
      "Training loss =  0.7097951431690463\n",
      "Training loss =  0.6792743869824308\n",
      "Training loss =  0.7097176889676277\n",
      "Training loss =  0.7071380716860846\n",
      "Training loss =  0.6818520659887427\n",
      "Training loss =  0.6794115930936158\n",
      "Training loss =  0.7095766253231378\n",
      "Training loss =  0.7069977123036233\n",
      "Training loss =  0.7044316750515128\n",
      "Training loss =  0.684491486659032\n",
      "Training loss =  0.6820378346646193\n",
      "Training loss =  0.706884074960357\n",
      "Training loss =  0.7043186050875979\n",
      "Training loss =  0.6846020651566388\n",
      "Training loss =  0.7042688319561399\n",
      "Training loss =  0.6846507493704036\n",
      "Training loss =  0.6821963021260431\n",
      "Training loss =  0.6797541104419959\n",
      "Training loss =  0.6773241124231408\n",
      "Training loss =  0.6749062463444431\n",
      "Training loss =  0.7142292010381236\n",
      "Training loss =  0.7116270617458921\n",
      "Training loss =  0.6775050194426236\n",
      "Training loss =  0.7115403172725384\n",
      "Training loss =  0.708951600782869\n",
      "Training loss =  0.7063758082426753\n",
      "Training loss =  0.6825940426196218\n",
      "Training loss =  0.6801498649793568\n",
      "Training loss =  0.6777178910438779\n",
      "Training loss =  0.7113206920427503\n",
      "Training loss =  0.6778004858340828\n",
      "Training loss =  0.6753802415001682\n",
      "Training loss =  0.6729720796311274\n",
      "Training loss =  0.6705759388147658\n",
      "Training loss =  0.6681917578156185\n",
      "Training loss =  0.7212427213177912\n",
      "Training loss =  0.7186055779791779\n",
      "Training loss =  0.7159815951172661\n",
      "Training loss =  0.7133707086991415\n",
      "Training loss =  0.675826797495741\n",
      "Training loss =  0.7132751074575981\n",
      "Training loss =  0.6759186632998824\n",
      "Training loss =  0.7131799921732759\n",
      "Training loss =  0.6760100791825921\n",
      "Training loss =  0.7130853603351577\n",
      "Training loss =  0.6761010473019505\n",
      "Training loss =  0.7129912094455917\n",
      "Training loss =  0.7103952499926867\n",
      "Training loss =  0.678694070701128\n",
      "Training loss =  0.7103147541353891\n",
      "Training loss =  0.7077321560329017\n",
      "Training loss =  0.7051624518209806\n",
      "Training loss =  0.6837774067926493\n",
      "Training loss =  0.7051084225948819\n",
      "Training loss =  0.6838301663318349\n",
      "Training loss =  0.6813798164966703\n",
      "Training loss =  0.678941701544433\n",
      "Training loss =  0.6765157596364987\n",
      "Training loss =  0.6741019291051425\n",
      "Training loss =  0.6717001484559402\n",
      "Training loss =  0.7175661025340735\n",
      "Training loss =  0.6718121773615778\n",
      "Training loss =  0.6694218261079343\n",
      "Training loss =  0.6670434051315004\n",
      "Training loss =  0.722451880044889\n",
      "Training loss =  0.6671780739062345\n",
      "Training loss =  0.7223099331950062\n",
      "Training loss =  0.6673120896667945\n",
      "Training loss =  0.6649441972268221\n",
      "Training loss =  0.6625881201810075\n",
      "Training loss =  0.7271701380414733\n",
      "Training loss =  0.7245034212621735\n",
      "Training loss =  0.7218500081723456\n",
      "Training loss =  0.6677465704870323\n",
      "Training loss =  0.6653765098881662\n",
      "Training loss =  0.7242121106486223\n",
      "Training loss =  0.6655192529858764\n",
      "Training loss =  0.6631603066552474\n",
      "Training loss =  0.7265617571875242\n",
      "Training loss =  0.7238980753006582\n",
      "Training loss =  0.7212476824499647\n",
      "Training loss =  0.6683161606295979\n",
      "Training loss =  0.6659432575684896\n",
      "Training loss =  0.7236129532705661\n",
      "Training loss =  0.6660832571522873\n",
      "Training loss =  0.7234650550539077\n",
      "Training loss =  0.6662225787440683\n",
      "Training loss =  0.7233179152458633\n",
      "Training loss =  0.7206704170733846\n",
      "Training loss =  0.7180361296292975\n",
      "Training loss =  0.7154149887821277\n",
      "Training loss =  0.7128069305265755\n",
      "Training loss =  0.6763687952513355\n",
      "Training loss =  0.6739556983994769\n",
      "Training loss =  0.7152162596588624\n",
      "Training loss =  0.6740567180912284\n",
      "Training loss =  0.6716551631254164\n",
      "Training loss =  0.7176130784151297\n",
      "Training loss =  0.7149940489897855\n",
      "Training loss =  0.7123880918592969\n",
      "Training loss =  0.7097951431690469\n",
      "Training loss =  0.6792743869824306\n",
      "Training loss =  0.7097176889676281\n",
      "Training loss =  0.707138071686085\n",
      "Training loss =  0.6818520659887427\n",
      "Training loss =  0.6794115930936158\n",
      "Training loss =  0.7095766253231384\n",
      "Training loss =  0.7069977123036235\n",
      "Training loss =  0.7044316750515133\n",
      "Training loss =  0.6844914866590316\n",
      "Training loss =  0.6820378346646189\n",
      "Training loss =  0.7068840749603574\n",
      "Training loss =  0.7043186050875984\n",
      "Training loss =  0.6846020651566384\n",
      "Training loss =  0.7042688319561403\n",
      "Training loss =  0.6846507493704034\n",
      "Training loss =  0.6821963021260431\n",
      "Training loss =  0.6797541104419956\n",
      "Training loss =  0.6773241124231408\n",
      "Training loss =  0.6749062463444429\n",
      "Training loss =  0.714229201038124\n",
      "Training loss =  0.7116270617458925\n",
      "Training loss =  0.6775050194426232\n",
      "Training loss =  0.7115403172725386\n",
      "Training loss =  0.7089516007828693\n",
      "Training loss =  0.7063758082426755\n",
      "Training loss =  0.6825940426196213\n",
      "Training loss =  0.6801498649793564\n",
      "Training loss =  0.6777178910438775\n",
      "Training loss =  0.7113206920427507\n",
      "Training loss =  0.6778004858340828\n",
      "Training loss =  0.6753802415001682\n",
      "Training loss =  0.672972079631127\n",
      "Training loss =  0.6705759388147654\n",
      "Training loss =  0.668191757815618\n",
      "Training loss =  0.7212427213177914\n",
      "Training loss =  0.7186055779791783\n",
      "Training loss =  0.7159815951172663\n",
      "Training loss =  0.713370708699142\n",
      "Training loss =  0.6758267974957406\n",
      "Training loss =  0.7132751074575984\n",
      "Training loss =  0.6759186632998821\n",
      "Training loss =  0.7131799921732763\n",
      "Training loss =  0.6760100791825917\n",
      "Training loss =  0.7130853603351581\n",
      "Training loss =  0.6761010473019501\n",
      "Training loss =  0.7129912094455919\n",
      "Training loss =  0.710395249992687\n",
      "Training loss =  0.6786940707011277\n",
      "Training loss =  0.7103147541353896\n",
      "Training loss =  0.7077321560329022\n",
      "Training loss =  0.7051624518209808\n",
      "Training loss =  0.6837774067926489\n",
      "Training loss =  0.7051084225948824\n",
      "Training loss =  0.6838301663318349\n",
      "Training loss =  0.6813798164966699\n",
      "Training loss =  0.6789417015444326\n",
      "Training loss =  0.6765157596364982\n",
      "Training loss =  0.6741019291051421\n",
      "Training loss =  0.67170014845594\n",
      "Training loss =  0.7175661025340737\n",
      "Training loss =  0.6718121773615774\n",
      "Training loss =  0.6694218261079339\n",
      "Training loss =  0.6670434051315004\n",
      "Training loss =  0.7224518800448895\n",
      "Training loss =  0.6671780739062341\n",
      "Training loss =  0.7223099331950065\n",
      "Training loss =  0.6673120896667945\n",
      "Training loss =  0.6649441972268216\n",
      "Training loss =  0.6625881201810071\n",
      "Training loss =  0.7271701380414738\n",
      "Training loss =  0.724503421262174\n",
      "Training loss =  0.721850008172346\n",
      "Training loss =  0.6677465704870319\n",
      "Training loss =  0.6653765098881658\n",
      "Training loss =  0.7242121106486227\n",
      "Training loss =  0.6655192529858762\n",
      "Training loss =  0.663160306655247\n",
      "Training loss =  0.7265617571875244\n",
      "Training loss =  0.7238980753006584\n",
      "Training loss =  0.7212476824499647\n",
      "Training loss =  0.6683161606295974\n",
      "Training loss =  0.6659432575684892\n",
      "Training loss =  0.7236129532705663\n",
      "Training loss =  0.6660832571522869\n",
      "Training loss =  0.7234650550539079\n",
      "Training loss =  0.6662225787440679\n",
      "Training loss =  0.7233179152458634\n",
      "Training loss =  0.7206704170733849\n",
      "Training loss =  0.7180361296292977\n",
      "Training loss =  0.715414988782128\n",
      "Training loss =  0.712806930526576\n",
      "Training loss =  0.6763687952513353\n",
      "Training loss =  0.6739556983994764\n",
      "Training loss =  0.7152162596588628\n",
      "Training loss =  0.6740567180912279\n",
      "Training loss =  0.671655163125416\n",
      "Training loss =  0.7176130784151301\n",
      "Training loss =  0.7149940489897859\n",
      "Training loss =  0.7123880918592971\n",
      "Training loss =  0.7097951431690473\n",
      "Training loss =  0.6792743869824301\n",
      "Training loss =  0.7097176889676281\n",
      "Training loss =  0.707138071686085\n",
      "Training loss =  0.6818520659887423\n",
      "Training loss =  0.6794115930936153\n",
      "Training loss =  0.7095766253231384\n",
      "Training loss =  0.706997712303624\n",
      "Training loss =  0.7044316750515135\n",
      "Training loss =  0.6844914866590311\n",
      "Training loss =  0.6820378346646184\n",
      "Training loss =  0.7068840749603579\n",
      "Training loss =  0.7043186050875986\n",
      "Training loss =  0.684602065156638\n",
      "Training loss =  0.7042688319561403\n",
      "Training loss =  0.6846507493704032\n",
      "Training loss =  0.6821963021260427\n",
      "Training loss =  0.6797541104419953\n",
      "Training loss =  0.6773241124231405\n",
      "Training loss =  0.6749062463444426\n",
      "Training loss =  0.7142292010381243\n",
      "Training loss =  0.711627061745893\n",
      "Training loss =  0.6775050194426232\n",
      "Training loss =  0.7115403172725389\n",
      "Training loss =  0.7089516007828696\n",
      "Training loss =  0.706375808242676\n",
      "Training loss =  0.6825940426196213\n",
      "Training loss =  0.6801498649793559\n",
      "Training loss =  0.6777178910438775\n",
      "Training loss =  0.7113206920427507\n",
      "Training loss =  0.6778004858340824\n",
      "Training loss =  0.6753802415001677\n",
      "Training loss =  0.6729720796311268\n",
      "Training loss =  0.6705759388147654\n",
      "Training loss =  0.668191757815618\n",
      "Training loss =  0.7212427213177917\n",
      "Training loss =  0.7186055779791783\n",
      "Training loss =  0.7159815951172667\n",
      "Training loss =  0.713370708699142\n",
      "Training loss =  0.6758267974957406\n",
      "Training loss =  0.7132751074575988\n",
      "Training loss =  0.6759186632998817\n",
      "Training loss =  0.7131799921732763\n",
      "Training loss =  0.6760100791825917\n",
      "Training loss =  0.7130853603351583\n",
      "Training loss =  0.6761010473019501\n",
      "Training loss =  0.7129912094455921\n",
      "Training loss =  0.710395249992687\n",
      "Training loss =  0.6786940707011275\n",
      "Training loss =  0.7103147541353896\n",
      "Training loss =  0.7077321560329024\n",
      "Training loss =  0.705162451820981\n",
      "Training loss =  0.6837774067926489\n",
      "Training loss =  0.7051084225948824\n",
      "Training loss =  0.6838301663318345\n",
      "Training loss =  0.6813798164966697\n",
      "Training loss =  0.6789417015444326\n",
      "Training loss =  0.6765157596364982\n",
      "Training loss =  0.6741019291051419\n",
      "Training loss =  0.67170014845594\n",
      "Training loss =  0.7175661025340739\n",
      "Training loss =  0.6718121773615772\n",
      "Training loss =  0.6694218261079339\n",
      "Training loss =  0.6670434051315\n",
      "Training loss =  0.7224518800448896\n",
      "Training loss =  0.6671780739062341\n",
      "Training loss =  0.7223099331950069\n",
      "Training loss =  0.6673120896667942\n",
      "Training loss =  0.6649441972268216\n",
      "Training loss =  0.6625881201810069\n",
      "Training loss =  0.7271701380414738\n",
      "Training loss =  0.724503421262174\n",
      "Training loss =  0.721850008172346\n",
      "Training loss =  0.6677465704870317\n",
      "Training loss =  0.6653765098881658\n",
      "Training loss =  0.7242121106486227\n",
      "Training loss =  0.6655192529858758\n",
      "Training loss =  0.663160306655247\n",
      "Training loss =  0.7265617571875246\n",
      "Training loss =  0.723898075300659\n",
      "Training loss =  0.7212476824499652\n",
      "Training loss =  0.6683161606295974\n",
      "Training loss =  0.6659432575684892\n",
      "Training loss =  0.7236129532705664\n",
      "Training loss =  0.6660832571522864\n",
      "Training loss =  0.7234650550539081\n",
      "Training loss =  0.6662225787440679\n",
      "Training loss =  0.723317915245864\n",
      "Training loss =  0.7206704170733851\n",
      "Training loss =  0.7180361296292979\n",
      "Training loss =  0.7154149887821282\n",
      "Training loss =  0.712806930526576\n",
      "Training loss =  0.6763687952513351\n",
      "Training loss =  0.6739556983994764\n",
      "Training loss =  0.715216259658863\n",
      "Training loss =  0.6740567180912279\n",
      "Training loss =  0.671655163125416\n",
      "Training loss =  0.7176130784151303\n",
      "Training loss =  0.7149940489897859\n",
      "Training loss =  0.7123880918592973\n",
      "Training loss =  0.7097951431690473\n",
      "Training loss =  0.6792743869824299\n",
      "Training loss =  0.7097176889676285\n",
      "Training loss =  0.7071380716860856\n",
      "Training loss =  0.6818520659887423\n",
      "Training loss =  0.6794115930936153\n",
      "Training loss =  0.7095766253231388\n",
      "Training loss =  0.706997712303624\n",
      "Training loss =  0.7044316750515137\n",
      "Training loss =  0.6844914866590311\n",
      "Training loss =  0.6820378346646184\n",
      "Training loss =  0.7068840749603579\n",
      "Training loss =  0.7043186050875988\n",
      "Training loss =  0.684602065156638\n",
      "Training loss =  0.7042688319561408\n",
      "Training loss =  0.6846507493704029\n",
      "Training loss =  0.6821963021260427\n",
      "Training loss =  0.6797541104419953\n",
      "Training loss =  0.6773241124231405\n",
      "Training loss =  0.6749062463444426\n",
      "Training loss =  0.7142292010381245\n",
      "Training loss =  0.711627061745893\n",
      "Training loss =  0.6775050194426228\n",
      "Training loss =  0.7115403172725391\n",
      "Training loss =  0.7089516007828698\n",
      "Training loss =  0.706375808242676\n",
      "Training loss =  0.6825940426196209\n",
      "Training loss =  0.6801498649793559\n",
      "Training loss =  0.677717891043877\n",
      "Training loss =  0.7113206920427512\n",
      "Training loss =  0.6778004858340824\n",
      "Training loss =  0.6753802415001677\n",
      "Training loss =  0.6729720796311266\n",
      "Training loss =  0.670575938814765\n",
      "Training loss =  0.6681917578156176\n",
      "Training loss =  0.7212427213177919\n",
      "Training loss =  0.7186055779791788\n",
      "Training loss =  0.7159815951172667\n",
      "Training loss =  0.7133707086991424\n",
      "Training loss =  0.6758267974957402\n",
      "Training loss =  0.7132751074575988\n",
      "Training loss =  0.6759186632998817\n",
      "Training loss =  0.7131799921732768\n",
      "Training loss =  0.6760100791825913\n",
      "Training loss =  0.7130853603351586\n",
      "Training loss =  0.6761010473019496\n",
      "Training loss =  0.7129912094455924\n",
      "Training loss =  0.7103952499926874\n",
      "Training loss =  0.6786940707011275\n",
      "Training loss =  0.71031475413539\n",
      "Training loss =  0.7077321560329026\n",
      "Training loss =  0.705162451820981\n",
      "Training loss =  0.6837774067926486\n",
      "Training loss =  0.7051084225948828\n",
      "Training loss =  0.6838301663318345\n",
      "Training loss =  0.6813798164966697\n",
      "Training loss =  0.6789417015444321\n",
      "Training loss =  0.676515759636498\n",
      "Training loss =  0.6741019291051417\n",
      "Training loss =  0.6717001484559395\n",
      "Training loss =  0.7175661025340739\n",
      "Training loss =  0.671812177361577\n",
      "Training loss =  0.6694218261079339\n",
      "Training loss =  0.6670434051315\n",
      "Training loss =  0.7224518800448898\n",
      "Training loss =  0.6671780739062336\n",
      "Training loss =  0.7223099331950069\n",
      "Training loss =  0.6673120896667942\n",
      "Training loss =  0.6649441972268214\n",
      "Training loss =  0.6625881201810067\n",
      "Training loss =  0.7271701380414742\n",
      "Training loss =  0.7245034212621743\n",
      "Training loss =  0.7218500081723465\n",
      "Training loss =  0.6677465704870317\n",
      "Training loss =  0.6653765098881658\n",
      "Training loss =  0.7242121106486229\n",
      "Training loss =  0.6655192529858758\n",
      "Training loss =  0.6631603066552465\n",
      "Training loss =  0.7265617571875248\n",
      "Training loss =  0.723898075300659\n",
      "Training loss =  0.7212476824499652\n",
      "Training loss =  0.668316160629597\n",
      "Training loss =  0.6659432575684887\n",
      "Training loss =  0.7236129532705666\n",
      "Training loss =  0.6660832571522864\n",
      "Training loss =  0.7234650550539083\n",
      "Training loss =  0.6662225787440674\n",
      "Training loss =  0.723317915245864\n",
      "Training loss =  0.7206704170733851\n",
      "Training loss =  0.7180361296292979\n",
      "Training loss =  0.7154149887821282\n",
      "Training loss =  0.7128069305265764\n",
      "Training loss =  0.6763687952513351\n",
      "Training loss =  0.673955698399476\n",
      "Training loss =  0.7152162596588633\n",
      "Training loss =  0.6740567180912277\n",
      "Training loss =  0.6716551631254157\n",
      "Training loss =  0.7176130784151306\n",
      "Training loss =  0.7149940489897861\n",
      "Training loss =  0.7123880918592973\n",
      "Training loss =  0.7097951431690476\n",
      "Training loss =  0.6792743869824297\n",
      "Training loss =  0.7097176889676285\n",
      "Training loss =  0.7071380716860856\n",
      "Training loss =  0.6818520659887418\n",
      "Training loss =  0.6794115930936151\n",
      "Training loss =  0.7095766253231388\n",
      "Training loss =  0.7069977123036244\n",
      "Training loss =  0.7044316750515137\n",
      "Training loss =  0.6844914866590311\n",
      "Training loss =  0.6820378346646184\n",
      "Training loss =  0.7068840749603581\n",
      "Training loss =  0.7043186050875988\n",
      "Training loss =  0.684602065156638\n",
      "Training loss =  0.7042688319561408\n",
      "Training loss =  0.6846507493704027\n",
      "Training loss =  0.6821963021260423\n",
      "Training loss =  0.6797541104419949\n",
      "Training loss =  0.6773241124231401\n",
      "Training loss =  0.6749062463444422\n",
      "Training loss =  0.7142292010381245\n",
      "Training loss =  0.7116270617458932\n",
      "Training loss =  0.6775050194426228\n",
      "Training loss =  0.7115403172725392\n",
      "Training loss =  0.7089516007828698\n",
      "Training loss =  0.7063758082426764\n",
      "Training loss =  0.6825940426196209\n",
      "Training loss =  0.6801498649793557\n",
      "Training loss =  0.677717891043877\n",
      "Training loss =  0.7113206920427512\n",
      "Training loss =  0.6778004858340819\n",
      "Training loss =  0.6753802415001673\n",
      "Training loss =  0.6729720796311266\n",
      "Training loss =  0.670575938814765\n",
      "Training loss =  0.6681917578156176\n",
      "Training loss =  0.7212427213177921\n",
      "Training loss =  0.7186055779791788\n",
      "Training loss =  0.7159815951172669\n",
      "Training loss =  0.7133707086991424\n",
      "Training loss =  0.6758267974957402\n",
      "Training loss =  0.7132751074575993\n",
      "Training loss =  0.6759186632998815\n",
      "Training loss =  0.7131799921732768\n",
      "Training loss =  0.6760100791825913\n",
      "Training loss =  0.7130853603351586\n",
      "Training loss =  0.6761010473019496\n",
      "Training loss =  0.7129912094455926\n",
      "Training loss =  0.7103952499926874\n",
      "Training loss =  0.6786940707011271\n",
      "Training loss =  0.71031475413539\n",
      "Training loss =  0.7077321560329026\n",
      "Training loss =  0.7051624518209815\n",
      "Training loss =  0.6837774067926486\n",
      "Training loss =  0.7051084225948828\n",
      "Training loss =  0.683830166331834\n",
      "Training loss =  0.6813798164966695\n",
      "Training loss =  0.6789417015444321\n",
      "Training loss =  0.6765157596364978\n",
      "Training loss =  0.6741019291051417\n",
      "Training loss =  0.6717001484559395\n",
      "Training loss =  0.7175661025340743\n",
      "Training loss =  0.671812177361577\n",
      "Training loss =  0.6694218261079334\n",
      "Training loss =  0.6670434051314997\n",
      "Training loss =  0.7224518800448898\n",
      "Training loss =  0.6671780739062336\n",
      "Training loss =  0.7223099331950071\n",
      "Training loss =  0.6673120896667938\n",
      "Training loss =  0.6649441972268212\n",
      "Training loss =  0.6625881201810067\n",
      "Training loss =  0.7271701380414742\n",
      "Training loss =  0.7245034212621745\n",
      "Training loss =  0.7218500081723465\n",
      "Training loss =  0.6677465704870317\n",
      "Training loss =  0.6653765098881653\n",
      "Training loss =  0.7242121106486231\n",
      "Training loss =  0.6655192529858756\n",
      "Training loss =  0.6631603066552465\n",
      "Training loss =  0.726561757187525\n",
      "Training loss =  0.7238980753006592\n",
      "Training loss =  0.7212476824499654\n",
      "Training loss =  0.668316160629597\n",
      "Training loss =  0.6659432575684887\n",
      "Training loss =  0.7236129532705668\n",
      "Training loss =  0.6660832571522864\n",
      "Training loss =  0.7234650550539083\n",
      "Training loss =  0.6662225787440674\n",
      "Training loss =  0.7233179152458642\n",
      "Training loss =  0.7206704170733856\n",
      "Training loss =  0.7180361296292981\n",
      "Training loss =  0.7154149887821286\n",
      "Training loss =  0.7128069305265764\n",
      "Training loss =  0.6763687952513346\n",
      "Training loss =  0.673955698399476\n",
      "Training loss =  0.7152162596588633\n",
      "Training loss =  0.6740567180912275\n",
      "Training loss =  0.6716551631254155\n",
      "Training loss =  0.7176130784151306\n",
      "Training loss =  0.7149940489897864\n",
      "Training loss =  0.7123880918592975\n",
      "Training loss =  0.7097951431690478\n",
      "Training loss =  0.6792743869824297\n",
      "Training loss =  0.7097176889676288\n",
      "Training loss =  0.7071380716860858\n",
      "Training loss =  0.6818520659887418\n",
      "Training loss =  0.6794115930936151\n",
      "Training loss =  0.709576625323139\n",
      "Training loss =  0.7069977123036244\n",
      "Training loss =  0.7044316750515139\n",
      "Training loss =  0.6844914866590307\n",
      "Training loss =  0.682037834664618\n",
      "Training loss =  0.7068840749603583\n",
      "Training loss =  0.704318605087599\n",
      "Training loss =  0.6846020651566376\n",
      "Training loss =  0.7042688319561408\n",
      "Training loss =  0.6846507493704027\n",
      "Training loss =  0.6821963021260423\n",
      "Training loss =  0.6797541104419949\n",
      "Training loss =  0.6773241124231401\n",
      "Training loss =  0.6749062463444422\n",
      "Training loss =  0.7142292010381249\n",
      "Training loss =  0.7116270617458934\n",
      "Training loss =  0.6775050194426228\n",
      "Training loss =  0.7115403172725392\n",
      "Training loss =  0.70895160078287\n",
      "Training loss =  0.7063758082426764\n",
      "Training loss =  0.6825940426196209\n",
      "Training loss =  0.6801498649793555\n",
      "Training loss =  0.6777178910438768\n",
      "Training loss =  0.7113206920427512\n",
      "Training loss =  0.6778004858340819\n",
      "Training loss =  0.6753802415001673\n",
      "Training loss =  0.6729720796311266\n",
      "Training loss =  0.670575938814765\n",
      "Training loss =  0.6681917578156176\n",
      "Training loss =  0.7212427213177921\n",
      "Training loss =  0.718605577979179\n",
      "Training loss =  0.7159815951172671\n",
      "Training loss =  0.7133707086991427\n",
      "Training loss =  0.6758267974957397\n",
      "Training loss =  0.7132751074575993\n",
      "Training loss =  0.6759186632998813\n",
      "Training loss =  0.7131799921732768\n",
      "Training loss =  0.6760100791825913\n",
      "Training loss =  0.7130853603351588\n",
      "Training loss =  0.6761010473019496\n",
      "Training loss =  0.7129912094455926\n",
      "Training loss =  0.7103952499926874\n",
      "Training loss =  0.6786940707011271\n",
      "Training loss =  0.71031475413539\n",
      "Training loss =  0.7077321560329028\n",
      "Training loss =  0.7051624518209815\n",
      "Training loss =  0.6837774067926484\n",
      "Training loss =  0.7051084225948828\n",
      "Training loss =  0.683830166331834\n",
      "Training loss =  0.6813798164966692\n",
      "Training loss =  0.6789417015444321\n",
      "Training loss =  0.6765157596364978\n",
      "Training loss =  0.6741019291051414\n",
      "Training loss =  0.6717001484559395\n",
      "Training loss =  0.7175661025340743\n",
      "Training loss =  0.6718121773615767\n",
      "Training loss =  0.6694218261079334\n",
      "Training loss =  0.6670434051314995\n",
      "Training loss =  0.72245188004489\n",
      "Training loss =  0.6671780739062336\n",
      "Training loss =  0.7223099331950074\n",
      "Training loss =  0.6673120896667938\n",
      "Training loss =  0.6649441972268212\n",
      "Training loss =  0.6625881201810064\n",
      "Training loss =  0.7271701380414742\n",
      "Training loss =  0.7245034212621745\n",
      "Training loss =  0.7218500081723465\n",
      "Training loss =  0.6677465704870312\n",
      "Training loss =  0.6653765098881653\n",
      "Training loss =  0.7242121106486231\n",
      "Training loss =  0.6655192529858753\n",
      "Training loss =  0.6631603066552465\n",
      "Training loss =  0.726561757187525\n",
      "Training loss =  0.7238980753006593\n",
      "Training loss =  0.7212476824499656\n",
      "Training loss =  0.668316160629597\n",
      "Training loss =  0.6659432575684887\n",
      "Training loss =  0.7236129532705668\n",
      "Training loss =  0.6660832571522862\n",
      "Training loss =  0.7234650550539086\n",
      "Training loss =  0.6662225787440674\n",
      "Training loss =  0.7233179152458644\n",
      "Training loss =  0.7206704170733856\n",
      "Training loss =  0.7180361296292983\n",
      "Training loss =  0.7154149887821286\n",
      "Training loss =  0.7128069305265764\n",
      "Training loss =  0.6763687952513346\n",
      "Training loss =  0.673955698399476\n",
      "Training loss =  0.7152162596588633\n",
      "Training loss =  0.6740567180912275\n",
      "Training loss =  0.6716551631254155\n",
      "Training loss =  0.7176130784151308\n",
      "Training loss =  0.7149940489897864\n",
      "Training loss =  0.7123880918592977\n",
      "Training loss =  0.7097951431690478\n",
      "Training loss =  0.6792743869824297\n",
      "Training loss =  0.709717688967629\n",
      "Training loss =  0.707138071686086\n",
      "Training loss =  0.6818520659887418\n",
      "Training loss =  0.6794115930936149\n",
      "Training loss =  0.7095766253231393\n",
      "Training loss =  0.7069977123036244\n",
      "Training loss =  0.7044316750515142\n",
      "Training loss =  0.6844914866590307\n",
      "Training loss =  0.682037834664618\n",
      "Training loss =  0.7068840749603583\n",
      "Training loss =  0.7043186050875992\n",
      "Training loss =  0.6846020651566376\n",
      "Training loss =  0.704268831956141\n",
      "Training loss =  0.6846507493704025\n",
      "Training loss =  0.6821963021260423\n",
      "Training loss =  0.6797541104419949\n",
      "Training loss =  0.6773241124231401\n",
      "Training loss =  0.6749062463444422\n",
      "Training loss =  0.7142292010381249\n",
      "Training loss =  0.7116270617458934\n",
      "Training loss =  0.6775050194426223\n",
      "Training loss =  0.7115403172725392\n",
      "Training loss =  0.7089516007828702\n",
      "Training loss =  0.7063758082426764\n",
      "Training loss =  0.6825940426196206\n",
      "Training loss =  0.6801498649793555\n",
      "Training loss =  0.6777178910438766\n",
      "Training loss =  0.7113206920427513\n",
      "Training loss =  0.6778004858340819\n",
      "Training loss =  0.6753802415001673\n",
      "Training loss =  0.6729720796311262\n",
      "Training loss =  0.6705759388147647\n",
      "Training loss =  0.6681917578156173\n",
      "Training loss =  0.7212427213177923\n",
      "Training loss =  0.7186055779791792\n",
      "Training loss =  0.7159815951172671\n",
      "Training loss =  0.7133707086991427\n",
      "Training loss =  0.6758267974957397\n",
      "Training loss =  0.7132751074575993\n",
      "Training loss =  0.6759186632998813\n",
      "Training loss =  0.713179992173277\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.713085360335159\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.7129912094455926\n",
      "Training loss =  0.7103952499926877\n",
      "Training loss =  0.6786940707011271\n",
      "Training loss =  0.7103147541353902\n",
      "Training loss =  0.7077321560329031\n",
      "Training loss =  0.7051624518209815\n",
      "Training loss =  0.6837774067926484\n",
      "Training loss =  0.705108422594883\n",
      "Training loss =  0.683830166331834\n",
      "Training loss =  0.6813798164966692\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364976\n",
      "Training loss =  0.6741019291051414\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340743\n",
      "Training loss =  0.6718121773615765\n",
      "Training loss =  0.6694218261079334\n",
      "Training loss =  0.6670434051314995\n",
      "Training loss =  0.7224518800448902\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950074\n",
      "Training loss =  0.6673120896667938\n",
      "Training loss =  0.664944197226821\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414745\n",
      "Training loss =  0.7245034212621746\n",
      "Training loss =  0.7218500081723467\n",
      "Training loss =  0.6677465704870312\n",
      "Training loss =  0.6653765098881653\n",
      "Training loss =  0.7242121106486231\n",
      "Training loss =  0.6655192529858753\n",
      "Training loss =  0.6631603066552463\n",
      "Training loss =  0.726561757187525\n",
      "Training loss =  0.7238980753006593\n",
      "Training loss =  0.7212476824499656\n",
      "Training loss =  0.668316160629597\n",
      "Training loss =  0.6659432575684887\n",
      "Training loss =  0.7236129532705668\n",
      "Training loss =  0.6660832571522862\n",
      "Training loss =  0.7234650550539088\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458644\n",
      "Training loss =  0.7206704170733856\n",
      "Training loss =  0.7180361296292983\n",
      "Training loss =  0.7154149887821286\n",
      "Training loss =  0.7128069305265765\n",
      "Training loss =  0.6763687952513346\n",
      "Training loss =  0.673955698399476\n",
      "Training loss =  0.7152162596588635\n",
      "Training loss =  0.6740567180912275\n",
      "Training loss =  0.6716551631254155\n",
      "Training loss =  0.7176130784151308\n",
      "Training loss =  0.7149940489897864\n",
      "Training loss =  0.7123880918592977\n",
      "Training loss =  0.7097951431690478\n",
      "Training loss =  0.6792743869824295\n",
      "Training loss =  0.709717688967629\n",
      "Training loss =  0.707138071686086\n",
      "Training loss =  0.6818520659887416\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231393\n",
      "Training loss =  0.7069977123036246\n",
      "Training loss =  0.7044316750515142\n",
      "Training loss =  0.6844914866590307\n",
      "Training loss =  0.682037834664618\n",
      "Training loss =  0.7068840749603583\n",
      "Training loss =  0.7043186050875992\n",
      "Training loss =  0.6846020651566376\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260423\n",
      "Training loss =  0.6797541104419949\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381249\n",
      "Training loss =  0.7116270617458934\n",
      "Training loss =  0.6775050194426223\n",
      "Training loss =  0.7115403172725394\n",
      "Training loss =  0.7089516007828702\n",
      "Training loss =  0.7063758082426767\n",
      "Training loss =  0.6825940426196206\n",
      "Training loss =  0.6801498649793555\n",
      "Training loss =  0.6777178910438766\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340819\n",
      "Training loss =  0.6753802415001673\n",
      "Training loss =  0.6729720796311262\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156173\n",
      "Training loss =  0.7212427213177923\n",
      "Training loss =  0.7186055779791792\n",
      "Training loss =  0.7159815951172671\n",
      "Training loss =  0.7133707086991429\n",
      "Training loss =  0.6758267974957397\n",
      "Training loss =  0.7132751074575995\n",
      "Training loss =  0.6759186632998813\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.713085360335159\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.7129912094455928\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011271\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329031\n",
      "Training loss =  0.7051624518209815\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.683830166331834\n",
      "Training loss =  0.6813798164966692\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364976\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340743\n",
      "Training loss =  0.6718121773615765\n",
      "Training loss =  0.6694218261079334\n",
      "Training loss =  0.6670434051314995\n",
      "Training loss =  0.7224518800448902\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950074\n",
      "Training loss =  0.6673120896667938\n",
      "Training loss =  0.664944197226821\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621746\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870312\n",
      "Training loss =  0.6653765098881653\n",
      "Training loss =  0.7242121106486233\n",
      "Training loss =  0.6655192529858753\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875254\n",
      "Training loss =  0.7238980753006593\n",
      "Training loss =  0.7212476824499656\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705671\n",
      "Training loss =  0.6660832571522862\n",
      "Training loss =  0.7234650550539088\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458644\n",
      "Training loss =  0.7206704170733856\n",
      "Training loss =  0.7180361296292983\n",
      "Training loss =  0.7154149887821286\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513346\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.6740567180912275\n",
      "Training loss =  0.6716551631254153\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897866\n",
      "Training loss =  0.7123880918592977\n",
      "Training loss =  0.709795143169048\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.709717688967629\n",
      "Training loss =  0.707138071686086\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231393\n",
      "Training loss =  0.7069977123036246\n",
      "Training loss =  0.7044316750515142\n",
      "Training loss =  0.6844914866590307\n",
      "Training loss =  0.682037834664618\n",
      "Training loss =  0.7068840749603583\n",
      "Training loss =  0.7043186050875992\n",
      "Training loss =  0.6846020651566376\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419949\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381249\n",
      "Training loss =  0.7116270617458934\n",
      "Training loss =  0.6775050194426223\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828702\n",
      "Training loss =  0.7063758082426767\n",
      "Training loss =  0.6825940426196206\n",
      "Training loss =  0.6801498649793555\n",
      "Training loss =  0.6777178910438766\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311262\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791792\n",
      "Training loss =  0.7159815951172673\n",
      "Training loss =  0.7133707086991429\n",
      "Training loss =  0.6758267974957397\n",
      "Training loss =  0.7132751074575995\n",
      "Training loss =  0.6759186632998813\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.713085360335159\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.7129912094455928\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011271\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329031\n",
      "Training loss =  0.7051624518209817\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966692\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340745\n",
      "Training loss =  0.6718121773615765\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314995\n",
      "Training loss =  0.7224518800448902\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950074\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870312\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858753\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875254\n",
      "Training loss =  0.7238980753006593\n",
      "Training loss =  0.7212476824499658\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705671\n",
      "Training loss =  0.6660832571522862\n",
      "Training loss =  0.7234650550539088\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458644\n",
      "Training loss =  0.7206704170733859\n",
      "Training loss =  0.7180361296292983\n",
      "Training loss =  0.7154149887821288\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513344\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.6740567180912272\n",
      "Training loss =  0.6716551631254153\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897866\n",
      "Training loss =  0.7123880918592977\n",
      "Training loss =  0.709795143169048\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.709717688967629\n",
      "Training loss =  0.707138071686086\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231393\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515142\n",
      "Training loss =  0.6844914866590307\n",
      "Training loss =  0.682037834664618\n",
      "Training loss =  0.7068840749603585\n",
      "Training loss =  0.7043186050875992\n",
      "Training loss =  0.6846020651566376\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381249\n",
      "Training loss =  0.7116270617458936\n",
      "Training loss =  0.6775050194426223\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828702\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196206\n",
      "Training loss =  0.6801498649793555\n",
      "Training loss =  0.6777178910438766\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311262\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791792\n",
      "Training loss =  0.7159815951172673\n",
      "Training loss =  0.7133707086991429\n",
      "Training loss =  0.6758267974957397\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.675918663299881\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.713085360335159\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329031\n",
      "Training loss =  0.7051624518209817\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.681379816496669\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615765\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314995\n",
      "Training loss =  0.7224518800448902\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950075\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870312\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858753\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006593\n",
      "Training loss =  0.7212476824499658\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.6660832571522862\n",
      "Training loss =  0.7234650550539088\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458644\n",
      "Training loss =  0.7206704170733859\n",
      "Training loss =  0.7180361296292985\n",
      "Training loss =  0.7154149887821288\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513344\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.6740567180912272\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.712388091859298\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.709717688967629\n",
      "Training loss =  0.707138071686086\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231393\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515144\n",
      "Training loss =  0.6844914866590307\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603585\n",
      "Training loss =  0.7043186050875992\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381251\n",
      "Training loss =  0.7116270617458936\n",
      "Training loss =  0.6775050194426223\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828702\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196206\n",
      "Training loss =  0.6801498649793553\n",
      "Training loss =  0.6777178910438766\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311262\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791792\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991429\n",
      "Training loss =  0.6758267974957397\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.675918663299881\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.713085360335159\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329031\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.681379816496669\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615765\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314993\n",
      "Training loss =  0.7224518800448902\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950075\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870312\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858751\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499658\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.6660832571522862\n",
      "Training loss =  0.7234650550539088\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458646\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292985\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513344\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.712388091859298\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.709717688967629\n",
      "Training loss =  0.707138071686086\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515144\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381251\n",
      "Training loss =  0.7116270617458936\n",
      "Training loss =  0.6775050194426223\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828702\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.6801498649793553\n",
      "Training loss =  0.6777178910438766\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311262\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791792\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991429\n",
      "Training loss =  0.6758267974957397\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.713085360335159\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329031\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.681379816496669\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615765\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314993\n",
      "Training loss =  0.7224518800448902\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950075\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870312\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858751\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.7234650550539088\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458646\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.712388091859298\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.707138071686086\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515144\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426223\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438766\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311262\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791792\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991429\n",
      "Training loss =  0.6758267974957397\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.713085360335159\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.681379816496669\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314993\n",
      "Training loss =  0.7224518800448902\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858751\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458646\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.712388091859298\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515144\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426223\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311262\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991429\n",
      "Training loss =  0.6758267974957397\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314993\n",
      "Training loss =  0.7224518800448902\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458646\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515144\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311262\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991429\n",
      "Training loss =  0.6758267974957397\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314993\n",
      "Training loss =  0.7224518800448902\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n",
      "Training loss =  0.6631603066552461\n",
      "Training loss =  0.7265617571875256\n",
      "Training loss =  0.7238980753006595\n",
      "Training loss =  0.7212476824499661\n",
      "Training loss =  0.6683161606295965\n",
      "Training loss =  0.6659432575684883\n",
      "Training loss =  0.7236129532705673\n",
      "Training loss =  0.666083257152286\n",
      "Training loss =  0.723465055053909\n",
      "Training loss =  0.6662225787440671\n",
      "Training loss =  0.7233179152458649\n",
      "Training loss =  0.720670417073386\n",
      "Training loss =  0.7180361296292987\n",
      "Training loss =  0.715414988782129\n",
      "Training loss =  0.7128069305265767\n",
      "Training loss =  0.6763687952513342\n",
      "Training loss =  0.6739556983994756\n",
      "Training loss =  0.7152162596588637\n",
      "Training loss =  0.674056718091227\n",
      "Training loss =  0.6716551631254151\n",
      "Training loss =  0.7176130784151309\n",
      "Training loss =  0.7149940489897868\n",
      "Training loss =  0.7123880918592982\n",
      "Training loss =  0.7097951431690482\n",
      "Training loss =  0.6792743869824293\n",
      "Training loss =  0.7097176889676291\n",
      "Training loss =  0.7071380716860862\n",
      "Training loss =  0.6818520659887414\n",
      "Training loss =  0.6794115930936147\n",
      "Training loss =  0.7095766253231395\n",
      "Training loss =  0.7069977123036248\n",
      "Training loss =  0.7044316750515146\n",
      "Training loss =  0.6844914866590303\n",
      "Training loss =  0.6820378346646176\n",
      "Training loss =  0.7068840749603588\n",
      "Training loss =  0.7043186050875994\n",
      "Training loss =  0.6846020651566371\n",
      "Training loss =  0.7042688319561412\n",
      "Training loss =  0.6846507493704023\n",
      "Training loss =  0.6821963021260419\n",
      "Training loss =  0.6797541104419944\n",
      "Training loss =  0.6773241124231398\n",
      "Training loss =  0.6749062463444417\n",
      "Training loss =  0.7142292010381253\n",
      "Training loss =  0.7116270617458939\n",
      "Training loss =  0.6775050194426221\n",
      "Training loss =  0.7115403172725396\n",
      "Training loss =  0.7089516007828705\n",
      "Training loss =  0.7063758082426769\n",
      "Training loss =  0.6825940426196204\n",
      "Training loss =  0.680149864979355\n",
      "Training loss =  0.6777178910438764\n",
      "Training loss =  0.7113206920427515\n",
      "Training loss =  0.6778004858340815\n",
      "Training loss =  0.6753802415001668\n",
      "Training loss =  0.6729720796311257\n",
      "Training loss =  0.6705759388147645\n",
      "Training loss =  0.6681917578156171\n",
      "Training loss =  0.7212427213177925\n",
      "Training loss =  0.7186055779791793\n",
      "Training loss =  0.7159815951172676\n",
      "Training loss =  0.7133707086991431\n",
      "Training loss =  0.6758267974957394\n",
      "Training loss =  0.7132751074575997\n",
      "Training loss =  0.6759186632998808\n",
      "Training loss =  0.7131799921732772\n",
      "Training loss =  0.6760100791825908\n",
      "Training loss =  0.7130853603351592\n",
      "Training loss =  0.6761010473019492\n",
      "Training loss =  0.712991209445593\n",
      "Training loss =  0.7103952499926879\n",
      "Training loss =  0.6786940707011266\n",
      "Training loss =  0.7103147541353904\n",
      "Training loss =  0.7077321560329033\n",
      "Training loss =  0.7051624518209818\n",
      "Training loss =  0.6837774067926482\n",
      "Training loss =  0.7051084225948833\n",
      "Training loss =  0.6838301663318336\n",
      "Training loss =  0.6813798164966688\n",
      "Training loss =  0.6789417015444317\n",
      "Training loss =  0.6765157596364973\n",
      "Training loss =  0.6741019291051412\n",
      "Training loss =  0.6717001484559391\n",
      "Training loss =  0.7175661025340747\n",
      "Training loss =  0.6718121773615763\n",
      "Training loss =  0.669421826107933\n",
      "Training loss =  0.6670434051314991\n",
      "Training loss =  0.7224518800448905\n",
      "Training loss =  0.6671780739062332\n",
      "Training loss =  0.7223099331950077\n",
      "Training loss =  0.6673120896667933\n",
      "Training loss =  0.6649441972268207\n",
      "Training loss =  0.6625881201810062\n",
      "Training loss =  0.7271701380414747\n",
      "Training loss =  0.7245034212621748\n",
      "Training loss =  0.7218500081723469\n",
      "Training loss =  0.6677465704870308\n",
      "Training loss =  0.6653765098881649\n",
      "Training loss =  0.7242121106486236\n",
      "Training loss =  0.6655192529858749\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "lr = 1e-2\n",
    "# Training loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(X1)):\n",
    "        x = X1[i]\n",
    "        y = Y1[i]\n",
    "\n",
    "        # Forward prop\n",
    "        y_hat = network(x)\n",
    "        # print(\"y_hat = \", y_hat)\n",
    "        # Calculate loss\n",
    "        loss = -1.0 * (y * y_hat.log() + (1-y) * (1-y_hat).log())\n",
    "        print(\"Training loss = \", loss.data)\n",
    "        # Setting grads to zero\n",
    "        for p in network.parameters():\n",
    "            p.grad = 0.0\n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        # Updating weights\n",
    "        for p in network.parameters():\n",
    "            p.data = p.data-lr*p.grad\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Value(data=-0.9235279291500622 label = ), Value(data=0.2638207592953241 label = ), Value(data=-0.7261690546896737 label = ), Value(data=-0.5631476939593063 label = ), Value(data=-0.6155505875915814 label = ), Value(data=0.5027835923573305 label = ), Value(data=-0.1977449675525027 label = ), Value(data=0.6897684764904062 label = ), Value(data=0.7840232733501777 label = ), Value(data=-0.43033009356724716 label = ), Value(data=0.6635828068305183 label = ), Value(data=0.5805929278676747 label = ), Value(data=0.7452610142202645 label = ), Value(data=0.4473875503273641 label = ), Value(data=-0.9079511180171245 label = ), Value(data=-0.1745658788878477 label = ), Value(data=0.4414496452245298 label = ), Value(data=0.5525592671382336 label = ), Value(data=0.6873973464350884 label = ), Value(data=0.27252592393485897 label = ), Value(data=0.8937442209354518 label = ), Value(data=-0.01196377909556312 label = ), Value(data=-0.4557307546292191 label = ), Value(data=-0.5439744795851955 label = ), Value(data=-0.39042909320101304 label = ), Value(data=0.7369534784919953 label = ), Value(data=0.48629451712119587 label = ), Value(data=-0.8432843207913698 label = ), Value(data=-0.8367912838237541 label = ), Value(data=0.6918206892696976 label = ), Value(data=-0.0143820892614277 label = ), Value(data=-0.5332833006269471 label = ), Value(data=0.9933203002426605 label = ), Value(data=0.09388233826157588 label = ), Value(data=0.43977347103519215 label = ), Value(data=-0.6412399131125084 label = ), Value(data=-0.6198687815238295 label = ), Value(data=-0.7104085078631344 label = ), Value(data=0.21347295301350466 label = ), Value(data=-0.26227995744415034 label = ), Value(data=0.10123281617743896 label = ), Value(data=0.7034609120948803 label = ), Value(data=-0.12337769871113591 label = ), Value(data=0.4398847219646531 label = ), Value(data=0.11232369683262311 label = ), Value(data=0.12484523003086734 label = ), Value(data=0.6054971635783988 label = ), Value(data=0.6055767627248956 label = ), Value(data=0.31580371005690644 label = ), Value(data=0.8004792090077402 label = ), Value(data=0.7635347267553769 label = ), Value(data=-0.9635774519724387 label = ), Value(data=-0.8796044937060439 label = ), Value(data=0.3474991655081745 label = ), Value(data=0.12041116291505216 label = ), Value(data=-0.02287395279003701 label = ), Value(data=0.5093565412447629 label = ), Value(data=-0.2320480394753872 label = ), Value(data=-0.3745181304462406 label = ), Value(data=0.6172748290667458 label = ), Value(data=-0.014386517306210767 label = ), Value(data=0.05174124863103313 label = ), Value(data=0.8150932875289421 label = ), Value(data=0.8553629484866114 label = ), Value(data=-0.37472913307967426 label = ), Value(data=-0.6368776495585688 label = ), Value(data=-0.8911770698447772 label = ), Value(data=-0.7236591002662087 label = ), Value(data=0.6107136224031919 label = ), Value(data=0.34754415851913656 label = ), Value(data=0.7465563266424133 label = ), Value(data=0.9539766622565078 label = ), Value(data=0.047032864485931025 label = ), Value(data=-0.2602031089471164 label = ), Value(data=0.4313849054546386 label = ), Value(data=0.5141010828333465 label = ), Value(data=-0.3068446512544556 label = ), Value(data=-0.45085845048708895 label = ), Value(data=0.8563237218696351 label = ), Value(data=0.9239321345262042 label = ), Value(data=-0.1367498363918651 label = ), Value(data=0.07178171586638205 label = ), Value(data=-0.6485992486486623 label = ), Value(data=-0.10412959364711627 label = ), Value(data=0.37467642535448986 label = ), Value(data=-0.013445539128904338 label = ), Value(data=-0.09079482991345866 label = ), Value(data=-0.3150693781860425 label = ), Value(data=0.39687146489357383 label = ), Value(data=0.5825434066072419 label = ), Value(data=0.5077385566450912 label = ), Value(data=-0.5159768331286845 label = ), Value(data=0.8202797869721803 label = ), Value(data=0.878677513656839 label = ), Value(data=-0.17894030697658225 label = ), Value(data=0.13077745873614433 label = ), Value(data=-0.05456524655381001 label = ), Value(data=-0.8676605790319329 label = ), Value(data=0.6916096551182509 label = ), Value(data=0.133975043582508 label = ), Value(data=0.6406971798858305 label = ), Value(data=-0.21530534671106882 label = ), Value(data=-0.49166308123401037 label = ), Value(data=-0.39825225956886423 label = ), Value(data=-0.1880045078516961 label = ), Value(data=-0.676959744987051 label = ), Value(data=-0.952057777051758 label = ), Value(data=-0.5473932659365757 label = ), Value(data=0.5156556277030508 label = ), Value(data=0.8467413674995445 label = ), Value(data=0.265582104692605 label = ), Value(data=-0.665807067098318 label = ), Value(data=-0.5239503729973198 label = ), Value(data=-0.6183900994756499 label = ), Value(data=0.4939387422886672 label = ), Value(data=0.7120930988471963 label = ), Value(data=0.42434156420434754 label = ), Value(data=0.27048252178180654 label = ), Value(data=0.2884241345950058 label = ), Value(data=0.48996970234386295 label = ), Value(data=0.406677212895854 label = ), Value(data=-0.00629555256723302 label = ), Value(data=-0.2580160035962038 label = ), Value(data=0.3980233856329587 label = ), Value(data=0.26322394879952093 label = ), Value(data=0.6786564931261629 label = ), Value(data=0.14062825125116163 label = ), Value(data=-0.6808674848148313 label = ), Value(data=0.3824292839055694 label = ), Value(data=-0.43343878461676066 label = ), Value(data=0.1120845500279124 label = ), Value(data=0.29873644039578173 label = ), Value(data=-0.30950160869843013 label = ), Value(data=0.7563269595385218 label = ), Value(data=-0.4035472765003909 label = ), Value(data=-0.631530204584414 label = ), Value(data=-0.9639152698172986 label = ), Value(data=-0.9629636762476532 label = ), Value(data=0.38300302343753234 label = ), Value(data=0.6569422804798746 label = ), Value(data=-0.6970724773232064 label = ), Value(data=0.8951499702937922 label = ), Value(data=-0.38373592359596476 label = ), Value(data=0.4383031974646714 label = ), Value(data=-0.6023262183382272 label = ), Value(data=0.03139662291824408 label = ), Value(data=-0.26768350883331604 label = ), Value(data=-0.845584527660306 label = ), Value(data=0.8555420299804506 label = ), Value(data=-0.4095863608151724 label = ), Value(data=-0.1543969533933025 label = ), Value(data=-0.8180920906919655 label = ), Value(data=0.1716899823345941 label = ), Value(data=0.8805560716612439 label = ), Value(data=0.3709573569572773 label = ), Value(data=0.7026338066400606 label = ), Value(data=0.0037212903522061413 label = ), Value(data=-0.9535223629308658 label = ), Value(data=-0.6582415952526508 label = ), Value(data=0.6949771203911586 label = ), Value(data=0.9566306597047085 label = ), Value(data=0.13352243618027737 label = ), Value(data=-0.37928998501239697 label = ), Value(data=-0.8136602456390101 label = ), Value(data=0.15100803045049482 label = ), Value(data=-0.8428984035408305 label = ), Value(data=0.3454437912412429 label = ), Value(data=0.33524124399458777 label = ), Value(data=0.5652057116562879 label = ), Value(data=-0.7407994599503125 label = ), Value(data=0.3980182493466222 label = ), Value(data=0.7579220473877448 label = ), Value(data=0.4997546598607534 label = ), Value(data=-0.03446857082673804 label = ), Value(data=0.4253452764656076 label = ), Value(data=0.4761142986592013 label = ), Value(data=-0.29249726892140515 label = ), Value(data=0.25833665712082055 label = ), Value(data=0.11882066417718518 label = ), Value(data=-0.1257131587155047 label = ), Value(data=0.7896822358013476 label = ), Value(data=-0.8613065969851834 label = ), Value(data=-0.7453504041485925 label = ), Value(data=0.9105881602252397 label = ), Value(data=-0.35280108708340285 label = ), Value(data=-0.15076380010039547 label = ), Value(data=0.17080791043049492 label = ), Value(data=0.45978857572528486 label = ), Value(data=0.4695240607644662 label = ), Value(data=0.05178088179119644 label = ), Value(data=0.9050503168548101 label = ), Value(data=0.8996899962093983 label = ), Value(data=-0.8356179178828298 label = ), Value(data=0.1101843227918935 label = ), Value(data=-0.9695504561306529 label = ), Value(data=0.5071763565285665 label = ), Value(data=-0.4610880916842295 label = ), Value(data=0.12490410007560193 label = ), Value(data=0.021168528771449147 label = ), Value(data=-0.266771979824612 label = ), Value(data=0.657517977914216 label = ), Value(data=-0.7211852372833105 label = ), Value(data=0.9876523989372503 label = ), Value(data=-0.666609266225892 label = ), Value(data=0.21467317102762795 label = ), Value(data=-0.9975780437398856 label = ), Value(data=0.592653478310603 label = ), Value(data=0.3832639575626329 label = ), Value(data=-0.7176624186148375 label = ), Value(data=-0.02036355382375077 label = ), Value(data=-0.3388262863104785 label = ), Value(data=0.35195784095579064 label = ), Value(data=0.731075361879125 label = ), Value(data=0.6987928845124387 label = ), Value(data=-0.5187506149143188 label = ), Value(data=0.02922818844868247 label = ), Value(data=-0.34258959610739725 label = ), Value(data=0.9934183715826663 label = ), Value(data=-0.8871277949057701 label = ), Value(data=-0.950622765637311 label = ), Value(data=-0.6729807738676883 label = ), Value(data=0.5519184309482945 label = ), Value(data=-0.6123284715354624 label = ), Value(data=-0.7921877054181559 label = ), Value(data=0.3217720014964969 label = ), Value(data=-0.09730827997373903 label = ), Value(data=-0.04402354137755338 label = ), Value(data=0.9545079916000334 label = ), Value(data=-0.7752387319884892 label = ), Value(data=0.9663661596005724 label = ), Value(data=-0.39113559259394926 label = ), Value(data=-0.41154660813775945 label = ), Value(data=-0.49647536285742033 label = ), Value(data=-0.22358588693652703 label = ), Value(data=0.23273033853255942 label = ), Value(data=0.4310131406844031 label = ), Value(data=-0.37716225494427125 label = ), Value(data=0.6413580068471105 label = ), Value(data=0.932408221666414 label = ), Value(data=0.8240832090866368 label = ), Value(data=0.12613953758028607 label = ), Value(data=-0.7526047961801741 label = ), Value(data=-0.5990823324827974 label = ), Value(data=-0.7699937214413648 label = ), Value(data=0.9113503549375717 label = ), Value(data=0.02360084201255952 label = ), Value(data=0.3440720340617831 label = ), Value(data=0.18087340844797195 label = ), Value(data=-0.8307454992366572 label = ), Value(data=0.7265500312162214 label = ), Value(data=-0.7211920537737146 label = ), Value(data=0.08185746591504661 label = ), Value(data=-0.6944227480773857 label = ), Value(data=-0.7164163756845761 label = ), Value(data=-0.4846216620222519 label = ), Value(data=-0.9802733407470676 label = ), Value(data=0.014043458245651674 label = ), Value(data=-0.5569769170947814 label = ), Value(data=-0.991085645403017 label = ), Value(data=-0.9917021536132766 label = ), Value(data=0.6786238690750215 label = ), Value(data=-0.9531661870843902 label = ), Value(data=-0.9109617801206666 label = ), Value(data=-0.08580775060393364 label = ), Value(data=0.2747439762671897 label = ), Value(data=-0.07008048136312417 label = ), Value(data=-0.0795489533001259 label = ), Value(data=0.7844971872948365 label = ), Value(data=0.7036056185785378 label = ), Value(data=-0.9820474680440028 label = ), Value(data=0.7660309559957874 label = ), Value(data=-0.04373836132358111 label = ), Value(data=-0.7917530494963778 label = ), Value(data=-0.9533933490218784 label = ), Value(data=-0.5847160348256024 label = ), Value(data=-0.11894849534942309 label = ), Value(data=0.25559852520549087 label = ), Value(data=0.8219625953337584 label = ), Value(data=0.10192473600417062 label = ), Value(data=0.7796891516961191 label = ), Value(data=-0.8393565509964875 label = ), Value(data=-0.8447385653399853 label = ), Value(data=0.268102877969419 label = ), Value(data=-0.2897109173620098 label = ), Value(data=-0.5090276164039758 label = ), Value(data=0.46614407936493607 label = ), Value(data=-0.6443532183591896 label = ), Value(data=-0.8577269296864398 label = ), Value(data=-0.9644531690905562 label = ), Value(data=0.201251714134828 label = ), Value(data=0.7230392521544096 label = ), Value(data=0.028544732549016905 label = ), Value(data=-0.08197378334374794 label = ), Value(data=-0.7767939725366251 label = ), Value(data=-0.8342939321974672 label = ), Value(data=0.8433919308426723 label = ), Value(data=0.21516155585862684 label = ), Value(data=0.07437730849269819 label = ), Value(data=-0.9975501691642437 label = ), Value(data=0.695611669522183 label = ), Value(data=-0.5610557231769713 label = ), Value(data=-0.3656384391773906 label = ), Value(data=-0.3621743275258611 label = ), Value(data=-0.10671664339930587 label = ), Value(data=0.3201146082164197 label = ), Value(data=0.6194986462527039 label = ), Value(data=-0.29369344603834513 label = ), Value(data=0.7982866668382196 label = ), Value(data=0.33821474552100383 label = ), Value(data=0.3361137179520466 label = ), Value(data=-0.9606957729930048 label = ), Value(data=0.2152432308035952 label = ), Value(data=-0.6347455325501545 label = ), Value(data=-0.6974723161879177 label = ), Value(data=-0.6116263782200384 label = ), Value(data=0.14132563854397828 label = ), Value(data=-0.35765157374413326 label = ), Value(data=-0.15041611243416586 label = ), Value(data=-0.38482106528455406 label = ), Value(data=0.11018242951678592 label = ), Value(data=-0.7560332629809212 label = ), Value(data=-0.056870674973870106 label = ), Value(data=0.5964582493388484 label = ), Value(data=0.4417981951632417 label = ), Value(data=0.379447156486721 label = ), Value(data=-0.5423964745295218 label = ), Value(data=0.8596623928175606 label = ), Value(data=-0.9783223337574607 label = ), Value(data=-0.010858764401632026 label = ), Value(data=-0.9195798605699639 label = ), Value(data=-0.6646508830185156 label = ), Value(data=-0.4185732423645212 label = ), Value(data=-0.5314219099519788 label = ), Value(data=-0.7116445643788474 label = ), Value(data=-0.21203517112341497 label = ), Value(data=-0.3144505594980751 label = ), Value(data=-0.5326799860690119 label = ), Value(data=-0.3148640790768864 label = ), Value(data=-0.22285469957010262 label = ), Value(data=-0.5704419690820584 label = ), Value(data=-0.8001077556008633 label = ), Value(data=0.7763008079393627 label = ), Value(data=0.3715808990153149 label = ), Value(data=-0.6157166053634258 label = ), Value(data=-0.05281198328729331 label = ), Value(data=-0.9804306632236048 label = ), Value(data=-0.32184661793241487 label = ), Value(data=0.7255288245888447 label = ), Value(data=0.12953539447557594 label = ), Value(data=0.1536634507241723 label = ), Value(data=-0.9105074768664243 label = ), Value(data=-0.5565212623071278 label = ), Value(data=-0.5804978631518396 label = ), Value(data=0.7703934832315782 label = ), Value(data=-0.3946432717342139 label = ), Value(data=0.46548266244147585 label = ), Value(data=0.48605023081190635 label = ), Value(data=0.13088622098593916 label = ), Value(data=-0.251270908544045 label = ), Value(data=0.695901092377176 label = ), Value(data=-0.04896058170485884 label = ), Value(data=-0.3537146289798996 label = ), Value(data=-0.16201666980224672 label = ), Value(data=-0.29348238337139065 label = ), Value(data=-0.6187274865998384 label = ), Value(data=0.8077368370708737 label = ), Value(data=-0.21728297704235144 label = ), Value(data=0.9042018514072647 label = ), Value(data=0.5145299917901303 label = ), Value(data=-0.02041633816091193 label = ), Value(data=-0.3835322572513631 label = ), Value(data=-0.07926652838578385 label = ), Value(data=-0.7044218219251759 label = ), Value(data=-0.9276295995039856 label = ), Value(data=-0.15494600392519375 label = ), Value(data=-0.9157661941821738 label = ), Value(data=0.7363106340046859 label = ), Value(data=-0.13618822954582455 label = ), Value(data=0.22358703677363034 label = ), Value(data=0.813738862083548 label = ), Value(data=-0.00859618663292383 label = ), Value(data=0.03289933832742897 label = ), Value(data=-0.3886167289985054 label = ), Value(data=-0.7777326236995403 label = ), Value(data=-0.7024371039484885 label = ), Value(data=0.9260279137740046 label = ), Value(data=0.771483887351655 label = ), Value(data=0.7939294559624668 label = ), Value(data=0.31109952928325835 label = ), Value(data=0.4519145146128005 label = ), Value(data=-0.8084708476389451 label = ), Value(data=-0.8696566500016931 label = ), Value(data=-0.5540950222213785 label = ), Value(data=-0.5474851748966558 label = ), Value(data=0.2968422423388932 label = ), Value(data=0.8387793343550334 label = ), Value(data=-0.8941952246241065 label = ), Value(data=-0.6121681800151715 label = ), Value(data=0.8788197645032609 label = ), Value(data=0.08315122225007898 label = ), Value(data=0.8343105917874061 label = ), Value(data=-0.6658948539454048 label = ), Value(data=-0.8855731368041133 label = ), Value(data=-0.24223879527076142 label = ), Value(data=-0.1839430930279755 label = ), Value(data=-0.11936110863590743 label = ), Value(data=-0.26211359986572513 label = ), Value(data=-0.05903942744483914 label = ), Value(data=0.8811439105771204 label = ), Value(data=-0.2515826184542531 label = ), Value(data=0.2977899652044429 label = ), Value(data=0.5378428279786844 label = ), Value(data=-0.7967933537171064 label = ), Value(data=-0.9452998413190854 label = ), Value(data=-0.7686087841816627 label = ), Value(data=-0.066485052241255 label = ), Value(data=0.25798412938601767 label = ), Value(data=-0.8906539093294452 label = ), Value(data=-0.07070464299207835 label = ), Value(data=-0.47271349290490794 label = ), Value(data=-0.47591769296094877 label = ), Value(data=-0.7896667036379659 label = ), Value(data=0.317046580535586 label = ), Value(data=-0.4213281808723408 label = ), Value(data=-0.4566540779092163 label = ), Value(data=0.4819555479449471 label = ), Value(data=-0.04549407884626011 label = ), Value(data=-0.8330311357695916 label = ), Value(data=0.7803508242547934 label = ), Value(data=0.6793573475758379 label = ), Value(data=0.10707943369555917 label = ), Value(data=-0.11047412929951306 label = ), Value(data=-0.6063677274611095 label = ), Value(data=-0.6008518691068554 label = ), Value(data=0.6629753290547784 label = ), Value(data=0.07655869240278479 label = ), Value(data=0.226139282407263 label = ), Value(data=0.5745797858210469 label = ), Value(data=0.8616606052240128 label = ), Value(data=-0.6501963861298072 label = ), Value(data=-0.44620965600841345 label = ), Value(data=-0.9287900054967926 label = ), Value(data=0.387548288209451 label = ), Value(data=0.8580603557389723 label = ), Value(data=0.15505922615269419 label = ), Value(data=-0.0020701075176448036 label = ), Value(data=0.6770835053851969 label = ), Value(data=0.2525736421084155 label = ), Value(data=-0.5328257058622341 label = ), Value(data=0.7525899792283144 label = ), Value(data=-0.020088282296699678 label = ), Value(data=0.6113835904052274 label = ), Value(data=-0.6705110180267251 label = ), Value(data=-0.5069786448725246 label = ), Value(data=0.18298986321100386 label = ), Value(data=-0.09438913652030356 label = ), Value(data=-0.8706189476976247 label = ), Value(data=0.8149812964984013 label = ), Value(data=0.062086850058717946 label = ), Value(data=-0.03824355378223121 label = ), Value(data=0.5375127047246433 label = ), Value(data=0.7278294820235753 label = ), Value(data=0.16961325871056165 label = ), Value(data=-0.49917150564612256 label = ), Value(data=0.0700559464422672 label = ), Value(data=0.014674187063534738 label = ), Value(data=0.7909756073286094 label = ), Value(data=0.646016087579858 label = ), Value(data=0.5076948186439934 label = ), Value(data=0.1421525839194171 label = ), Value(data=0.8994711445137318 label = ), Value(data=0.7288152901914253 label = ), Value(data=-0.8514823902070374 label = ), Value(data=0.8666528806997205 label = ), Value(data=0.7516927302061671 label = ), Value(data=0.46926287107856335 label = ), Value(data=0.7426704782410012 label = ), Value(data=-0.276272649293525 label = ), Value(data=0.3358318674823144 label = ), Value(data=0.5374447000778917 label = ), Value(data=0.4817939063561596 label = ), Value(data=-0.42621395531239803 label = ), Value(data=0.4657144779476414 label = ), Value(data=-0.304777787406608 label = ), Value(data=0.8598041462068964 label = ), Value(data=-0.3563527572091505 label = ), Value(data=0.1809542174545813 label = ), Value(data=0.26252817090943226 label = ), Value(data=0.9731945512559346 label = ), Value(data=0.7807114930063614 label = ), Value(data=-0.8145952515018897 label = ), Value(data=0.15583754638899094 label = ), Value(data=-0.038020221684927025 label = ), Value(data=0.8617704780688391 label = ), Value(data=-0.8558311198619863 label = ), Value(data=-0.004988085029901113 label = ), Value(data=0.21540043023845956 label = ), Value(data=0.8963052709919876 label = ), Value(data=0.29544975285895014 label = ), Value(data=0.3386707654218617 label = ), Value(data=0.455404296266807 label = ), Value(data=0.4111816830106021 label = ), Value(data=-0.5703773612897227 label = ), Value(data=-0.14029201119307277 label = ), Value(data=-0.38027162157830907 label = ), Value(data=-0.5904483154358844 label = ), Value(data=0.5631646328770659 label = ), Value(data=0.5263333450995791 label = ), Value(data=-0.5971121887924651 label = ), Value(data=0.36667711385802404 label = ), Value(data=0.09719502258596213 label = ), Value(data=-0.7956342940478223 label = ), Value(data=0.8161422010397841 label = ), Value(data=-0.853357862568694 label = ), Value(data=0.005452222107495963 label = ), Value(data=0.8547570181362738 label = ), Value(data=0.7968909553107699 label = ), Value(data=-0.9470881483709774 label = ), Value(data=-0.891308924546399 label = ), Value(data=0.11894746919662635 label = ), Value(data=-0.8540321074109933 label = ), Value(data=-0.47938987929911514 label = ), Value(data=0.10942447902497254 label = ), Value(data=-0.9225138033943336 label = ), Value(data=0.8502109306449863 label = ), Value(data=0.4437800363800666 label = ), Value(data=0.8422562274597836 label = ), Value(data=-0.5826285307542707 label = ), Value(data=-0.8750936350255756 label = ), Value(data=-0.313841375066084 label = ), Value(data=-0.26491995193541285 label = ), Value(data=-0.6618327227081398 label = ), Value(data=0.17452807146002502 label = ), Value(data=0.5093073929364298 label = ), Value(data=-0.2892922984597779 label = ), Value(data=0.08352928545712923 label = ), Value(data=-0.9559041475545864 label = ), Value(data=0.025825599215830275 label = ), Value(data=0.5008064679426207 label = ), Value(data=0.26629150428753956 label = ), Value(data=-0.04512592814672001 label = ), Value(data=0.6336090759847515 label = ), Value(data=0.6175702513646639 label = ), Value(data=0.09707560040638996 label = ), Value(data=-0.561214201044657 label = ), Value(data=-0.40420015872716 label = ), Value(data=-0.908801247268834 label = ), Value(data=0.19417203161032326 label = ), Value(data=-0.4339429308740179 label = ), Value(data=0.8334756468364859 label = ), Value(data=0.3436968669737708 label = ), Value(data=-0.36165657425412423 label = ), Value(data=0.9010615461194842 label = ), Value(data=-0.9623143616351097 label = ), Value(data=0.12974168746966108 label = ), Value(data=0.45944280871271315 label = ), Value(data=0.2608883743051347 label = ), Value(data=0.4283843041167943 label = ), Value(data=-0.06345784789870157 label = ), Value(data=-0.3255939974712283 label = ), Value(data=0.5371299289762557 label = ), Value(data=0.11237703301168689 label = ), Value(data=-0.9593297429328003 label = ), Value(data=-0.8650239608841199 label = ), Value(data=0.6281780979518126 label = ), Value(data=0.6821006040853648 label = ), Value(data=0.7075611343268282 label = ), Value(data=-0.0328540418405292 label = ), Value(data=0.14191386984922705 label = ), Value(data=-0.33110545530211666 label = ), Value(data=-0.4639107784214309 label = ), Value(data=0.32128061718071166 label = ), Value(data=0.9484037309662683 label = ), Value(data=0.48166667888791403 label = ), Value(data=0.8291337330688853 label = ), Value(data=-0.8781517861150612 label = ), Value(data=0.57611115973017 label = ), Value(data=-0.6728116201092944 label = ), Value(data=-0.6195653040894775 label = ), Value(data=0.3807548852659879 label = ), Value(data=-0.9701179845825418 label = ), Value(data=-0.29631434105771204 label = ), Value(data=0.9671449402839021 label = ), Value(data=0.20004785058932595 label = ), Value(data=-0.4282354013261762 label = ), Value(data=-0.2998377445003111 label = ), Value(data=-0.49357461711496975 label = ), Value(data=-0.7024891656159076 label = ), Value(data=0.24005567341120804 label = ), Value(data=-0.5231967712871726 label = ), Value(data=-0.4050785797050156 label = ), Value(data=-0.8692817760069904 label = ), Value(data=-0.7480037297402 label = ), Value(data=0.1497006016146576 label = ), Value(data=-0.6659546400813636 label = ), Value(data=-0.7228350516711552 label = ), Value(data=0.9243548946415638 label = ), Value(data=0.2630375113897503 label = ), Value(data=-0.2278811010288948 label = ), Value(data=-0.9264284100176003 label = ), Value(data=0.9988390662305517 label = ), Value(data=-0.5355155525022803 label = ), Value(data=0.8113549119286727 label = ), Value(data=0.9234629362513145 label = ), Value(data=-0.37566573141716564 label = ), Value(data=0.2553564845193814 label = ), Value(data=0.7515493888815108 label = ), Value(data=0.9503317934560511 label = ), Value(data=0.43162277430131746 label = ), Value(data=0.643871455865757 label = ), Value(data=-0.6643001921791556 label = ), Value(data=0.25523320982768505 label = ), Value(data=-0.7915861409579072 label = ), Value(data=-0.5153965204847042 label = ), Value(data=0.43528396693491156 label = ), Value(data=-0.40838913996127557 label = ), Value(data=-0.5978009953311936 label = ), Value(data=-0.8072857284049508 label = ), Value(data=0.04668831941426621 label = ), Value(data=0.9645287508196161 label = ), Value(data=-0.5714138248088056 label = ), Value(data=-0.9215321722952443 label = ), Value(data=0.4177772230042629 label = ), Value(data=0.7276629526109091 label = ), Value(data=-0.020110976802821146 label = ), Value(data=0.23700794284710236 label = ), Value(data=0.2842822230079325 label = ), Value(data=-0.2881660161342947 label = ), Value(data=-0.362634460706051 label = ), Value(data=-0.6679761759712637 label = ), Value(data=-0.5899714234987599 label = ), Value(data=-0.7680743965402961 label = ), Value(data=-0.3942720564440212 label = ), Value(data=-0.9862251644996878 label = ), Value(data=-0.9438678099894284 label = ), Value(data=-0.1283858231664059 label = ), Value(data=0.2931660895000363 label = ), Value(data=-0.6747718325203285 label = ), Value(data=-0.6239678111144848 label = ), Value(data=-0.007815147332732808 label = ), Value(data=-0.6410906185643233 label = ), Value(data=0.851224781949317 label = ), Value(data=-0.2115180364593654 label = ), Value(data=-0.7867202856058046 label = ), Value(data=0.4758102700975344 label = ), Value(data=-0.9750059943522165 label = ), Value(data=-0.25106044564430174 label = ), Value(data=0.22170450846627632 label = ), Value(data=-0.20230412804102382 label = ), Value(data=0.6464615769482938 label = ), Value(data=0.5059069568695627 label = ), Value(data=-0.6273928871971854 label = ), Value(data=0.7990146331230081 label = ), Value(data=0.8909487772684319 label = ), Value(data=0.6149454946710622 label = ), Value(data=-0.8441493326833596 label = ), Value(data=0.507398292455435 label = ), Value(data=-0.7554484957864755 label = ), Value(data=-0.7098974169572472 label = ), Value(data=-0.6766641515004583 label = ), Value(data=0.9134882685147836 label = ), Value(data=0.5563047143261646 label = ), Value(data=0.9961338762302228 label = ), Value(data=0.914451456995689 label = ), Value(data=-0.11180927692107034 label = ), Value(data=0.8001554354217164 label = ), Value(data=0.623913431244103 label = ), Value(data=0.6190647042025452 label = ), Value(data=-0.03337648385714642 label = ), Value(data=-0.5725515139294182 label = ), Value(data=0.8296133859472676 label = ), Value(data=-0.5747261059471802 label = ), Value(data=0.9218323284618555 label = ), Value(data=-0.4079147098676503 label = ), Value(data=0.045779589606275595 label = ), Value(data=-0.5046587134979772 label = ), Value(data=-0.29514754683642264 label = ), Value(data=0.4545574069292393 label = ), Value(data=-0.9319090429213104 label = ), Value(data=-0.646377341636196 label = ), Value(data=0.7937202631187033 label = ), Value(data=-0.43288026063633955 label = ), Value(data=-0.7512443971334664 label = ), Value(data=-0.5937656912379834 label = ), Value(data=-0.67503360957112 label = ), Value(data=-0.8080083919946284 label = ), Value(data=0.8285222832874757 label = ), Value(data=0.23597149872951406 label = ), Value(data=-0.7540641036615938 label = ), Value(data=-0.18793502955736097 label = ), Value(data=-0.2961834985556411 label = ), Value(data=0.4432276451323376 label = ), Value(data=0.6521918637353037 label = ), Value(data=-0.5337414894442447 label = ), Value(data=0.8237480364623755 label = ), Value(data=0.1955842985337919 label = ), Value(data=-0.5018450837008182 label = ), Value(data=-0.5581635052788438 label = ), Value(data=0.836062663098629 label = ), Value(data=0.755341048616138 label = ), Value(data=-0.00057849718690961 label = ), Value(data=0.9432064811326195 label = ), Value(data=-0.1277348637186526 label = ), Value(data=0.9023631360605828 label = ), Value(data=-0.41381597847660867 label = ), Value(data=0.3833909369464481 label = ), Value(data=-0.9022701610528454 label = ), Value(data=-0.06597855853512002 label = ), Value(data=-0.6335193286221494 label = ), Value(data=-0.9315334902148484 label = ), Value(data=0.12640637795174348 label = ), Value(data=0.07682426983170876 label = ), Value(data=0.4154970145221619 label = ), Value(data=-0.5797347194829281 label = ), Value(data=-0.4280861620224128 label = ), Value(data=0.12423004830461992 label = ), Value(data=-0.3778358113039182 label = ), Value(data=0.1728807874531566 label = ), Value(data=0.65390459045199 label = ), Value(data=0.5274462545429746 label = ), Value(data=0.9246199347103916 label = ), Value(data=-0.48452648782983987 label = ), Value(data=-0.9921865367253271 label = ), Value(data=0.6543251819263047 label = ), Value(data=-0.47916669379350574 label = ), Value(data=-0.561220861188314 label = ), Value(data=0.5923957514861753 label = ), Value(data=-0.46262329933460267 label = ), Value(data=0.36839431707732206 label = ), Value(data=-0.3500326621211425 label = ), Value(data=-0.7695640577224916 label = ), Value(data=0.9939846335533238 label = ), Value(data=-0.18761694886387903 label = ), Value(data=-0.33349565204798215 label = ), Value(data=-0.11099249491199203 label = ), Value(data=0.8240413726958824 label = ), Value(data=-0.8610128956604397 label = ), Value(data=0.0171019215678605 label = ), Value(data=-0.5697678389859875 label = ), Value(data=0.8555426007828106 label = ), Value(data=-0.5566031947511454 label = ), Value(data=-0.5923297845178428 label = ), Value(data=0.38222191980948184 label = ), Value(data=-0.3174127498235588 label = ), Value(data=-0.5473669777946963 label = ), Value(data=0.6242132483405212 label = ), Value(data=-0.6307823246963513 label = ), Value(data=0.23662213992302128 label = ), Value(data=-0.2648148567810027 label = ), Value(data=-0.8942108676592695 label = ), Value(data=-0.718511705284258 label = ), Value(data=-0.3724056697617426 label = ), Value(data=-0.7692587044240458 label = ), Value(data=0.2537508768779879 label = ), Value(data=0.9680614516454527 label = ), Value(data=-0.13795688241344695 label = ), Value(data=-0.3151005653874184 label = ), Value(data=-0.44429053148420405 label = ), Value(data=0.8888776494151338 label = ), Value(data=-0.9516335152249118 label = ), Value(data=-0.47169103604876916 label = ), Value(data=0.10745317864739778 label = ), Value(data=-0.34650196317703674 label = ), Value(data=0.4306062153720265 label = ), Value(data=-0.7643682437779471 label = ), Value(data=0.4584660344711162 label = ), Value(data=-0.17593616753997687 label = ), Value(data=0.027032906284282898 label = ), Value(data=-0.9039051122707167 label = ), Value(data=-0.8134840690383838 label = ), Value(data=-0.4542187178487289 label = ), Value(data=0.8668904095139893 label = ), Value(data=0.22794194666981227 label = ), Value(data=0.43086190737174723 label = ), Value(data=-0.19321792837124296 label = ), Value(data=0.911324045091793 label = ), Value(data=0.44496299620457913 label = ), Value(data=-0.7052988686727886 label = ), Value(data=0.8205933337502116 label = ), Value(data=-0.3972349517945766 label = ), Value(data=0.6724523813521679 label = ), Value(data=-0.5336559134383496 label = ), Value(data=0.24653671701423563 label = ), Value(data=-0.8421929324560333 label = ), Value(data=0.5056859910379568 label = ), Value(data=-0.4960247966067888 label = ), Value(data=0.13079004142484774 label = ), Value(data=-0.1865752827936904 label = ), Value(data=0.11559880800977584 label = ), Value(data=-0.21774715591470128 label = ), Value(data=-0.2955487088425366 label = ), Value(data=0.1869767171722745 label = ), Value(data=0.47774043700049384 label = ), Value(data=-0.12419348071215142 label = ), Value(data=0.74005707567445 label = ), Value(data=0.3539979559191335 label = ), Value(data=-0.3969204974487257 label = ), Value(data=-0.20082113262433965 label = ), Value(data=-0.853535019631634 label = ), Value(data=-0.4691117817517003 label = ), Value(data=0.7136260592966412 label = ), Value(data=-0.9923457053820499 label = ), Value(data=-0.4746147273414598 label = ), Value(data=-0.11528780119303828 label = ), Value(data=0.18316651759185887 label = ), Value(data=0.8937894058744476 label = ), Value(data=0.2244497543432571 label = ), Value(data=0.023338884197710463 label = ), Value(data=-0.8684638252125934 label = ), Value(data=0.47385375141528563 label = ), Value(data=0.9668621775421855 label = ), Value(data=0.9960913206237627 label = ), Value(data=-0.47360965480379424 label = ), Value(data=-0.25726471362846226 label = ), Value(data=0.4577148824691031 label = ), Value(data=0.6913724694971499 label = ), Value(data=-0.45521366218672177 label = ), Value(data=-0.9697925724355343 label = ), Value(data=-0.260695927441831 label = ), Value(data=0.3967313674586399 label = ), Value(data=-0.23523157138423967 label = ), Value(data=0.2348298291682953 label = ), Value(data=0.7423438527038484 label = ), Value(data=-0.5922751807389375 label = ), Value(data=-0.6155309545079664 label = ), Value(data=-0.25042345526699905 label = ), Value(data=0.37732930942141674 label = ), Value(data=-0.5927121565905231 label = ), Value(data=0.4556289561390603 label = ), Value(data=0.45641303538292544 label = ), Value(data=0.21365834254582694 label = ), Value(data=0.3173036888798002 label = ), Value(data=0.8127948551841531 label = ), Value(data=-0.4552614849346679 label = ), Value(data=-0.3979123266580602 label = ), Value(data=0.28994908974244904 label = ), Value(data=-0.9336140880393682 label = ), Value(data=-0.8262246830890281 label = ), Value(data=0.8995308399444557 label = ), Value(data=-0.23672941825778282 label = ), Value(data=-0.3162183603312245 label = ), Value(data=-0.013344988106693378 label = ), Value(data=0.17877129287064353 label = ), Value(data=0.6063691852135571 label = ), Value(data=-0.3662248481836341 label = ), Value(data=-0.24475097477395424 label = ), Value(data=0.16057639955435632 label = ), Value(data=-0.29726134443926755 label = ), Value(data=0.2766444591297872 label = ), Value(data=0.8387296459729405 label = ), Value(data=-0.29327506611621845 label = ), Value(data=-0.04949452741546434 label = ), Value(data=-0.44082570866918 label = ), Value(data=0.10704221111882584 label = ), Value(data=0.7301890784813663 label = ), Value(data=-0.7297919783795013 label = ), Value(data=-0.7928485629258173 label = ), Value(data=0.9427836376946725 label = ), Value(data=0.42202149411351386 label = ), Value(data=0.9224330708518549 label = ), Value(data=0.8222393999746969 label = ), Value(data=0.5288752044937959 label = ), Value(data=-0.7519153577202178 label = ), Value(data=-0.33649298558069374 label = ), Value(data=0.023263104499816833 label = ), Value(data=0.38051468514308273 label = ), Value(data=0.7381340223432202 label = ), Value(data=0.23060124884019917 label = ), Value(data=0.4967406064009987 label = ), Value(data=0.9681687786724531 label = ), Value(data=-0.6087776404181333 label = ), Value(data=-0.9963792329619336 label = ), Value(data=0.5112321509421953 label = ), Value(data=0.6008098866658935 label = ), Value(data=0.022186407659762653 label = ), Value(data=0.5991829623898095 label = ), Value(data=-0.5118132321845703 label = ), Value(data=-0.8909438347517824 label = ), Value(data=0.22921560905397587 label = ), Value(data=0.5859236935199033 label = ), Value(data=0.6491683261641146 label = ), Value(data=0.9920839743945002 label = ), Value(data=-0.848814592930371 label = ), Value(data=-0.6136549131114757 label = ), Value(data=0.5331478543120278 label = ), Value(data=-0.0059818506574840224 label = ), Value(data=-0.9965947475363268 label = ), Value(data=-0.2789310169485737 label = ), Value(data=0.17815617536678063 label = ), Value(data=0.7234662499297972 label = ), Value(data=0.9856307599022227 label = ), Value(data=0.22883404037079202 label = ), Value(data=0.16907951573711566 label = ), Value(data=0.6182748706593828 label = ), Value(data=-0.4581588787831461 label = ), Value(data=0.8860940249548686 label = ), Value(data=-0.8354371414474524 label = ), Value(data=0.5756459094688657 label = ), Value(data=-0.3875632144977841 label = ), Value(data=-0.9015229947178913 label = ), Value(data=0.3948675445247787 label = ), Value(data=-0.623397171254354 label = ), Value(data=-0.8628253076678536 label = ), Value(data=-0.5224862506790233 label = ), Value(data=-0.06965109872311648 label = ), Value(data=-0.4672635275251624 label = ), Value(data=0.10279955569522703 label = ), Value(data=-0.24004228386594972 label = ), Value(data=0.847906140356504 label = ), Value(data=-0.08231939058373516 label = ), Value(data=-0.3451556854394391 label = ), Value(data=-0.5277155076756834 label = ), Value(data=-0.1633339546621022 label = ), Value(data=0.2866252905732265 label = ), Value(data=0.3859198416117706 label = ), Value(data=0.09390600141504635 label = ), Value(data=0.008630905450350612 label = ), Value(data=0.06890695759100951 label = ), Value(data=0.5849725561744092 label = ), Value(data=0.1334646102543724 label = ), Value(data=-0.06761164004945108 label = )]\n"
     ]
    }
   ],
   "source": [
    "print(network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4\n",
      "2 5\n"
     ]
    }
   ],
   "source": [
    "a = [1,2]\n",
    "b = [4,5,6]\n",
    "for x1, w1 in zip(a, b):\n",
    "    print(x1, w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
